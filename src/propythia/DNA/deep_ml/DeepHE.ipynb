{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accurately predicting human essential genes based on deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will present a comparative analysis to demonstrate the application and performance of PyTorch models for addressing sequence-based prediction problems.\n",
    "\n",
    "We'll try to replicate the [DeepHE: Accurately predicting human essential genes based on deep learning](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008229) deep learning model and evaluate its performance. Other models will be compared to the DeepHE model.\n",
    "\n",
    "DeepHE's model is based on the multilayer perceptron structure. It includes one input layer, three hidden layers, and one output layer. All the hidden layers utilize the ReLU activation function. The output layer uses sigmoid activation function to perform discrete classification. The loss function in DeepHE is binary cross-entropy. A dropout layer is used after each hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, there is already 2 cleaned datasets which will be used in this notebook.\n",
    "- `essential_genes.csv`: 16 datasets grouped that contain essential genes of the human genome. Each sequence has an EMBL id associated, the original dataset it came from, among other information. [Link](http://origin.tubic.org/deg/public/index.php)\n",
    "- `essential_genes_negative.csv`: contains the genome DNA sequences of humans for all annotated genes from Ensembl. Each sequence has an EMBL id associated. [Link](http://www.ensembl.org/Homo_sapiens/Info/Index)\n",
    "\n",
    "The process of cleaning each dataset is described below:\n",
    "- `essential_genes.csv`:\n",
    "    - removed rows with unavailable sequences.\n",
    "- `essential_genes_negative.csv`:\n",
    "    - removed all rows which sequences belonged to the `essential_genes.csv` dataset.\n",
    "    - removed all rows which EMBL id was in the `essential_genes.csv` dataset.\n",
    "    - grouped all sequences with the same EMBL id, and kept only the first two.\n",
    "\n",
    "One of the tasks in this notebook is to also build the positive dataset (`essential_genes_positve.csv`), which will contain only the sequences that are in at least 5 different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26791, 15)\n",
      "(27684, 2)\n"
     ]
    }
   ],
   "source": [
    "deg_dataset = pd.read_csv(\"datasets/essential_genes.csv\", sep=';')\n",
    "print(deg_dataset.shape)\n",
    "\n",
    "eg_negative = pd.read_csv(\"datasets/essential_genes_negative.csv\", sep=',')\n",
    "print(eg_negative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating positive essential genes dataset. Each sequence needs to be in at least 5 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                           sequence\n",
      "0  GI:-  ATGGTGCTGTCCCAGAGACAACGAGATGAACTAAATCGAGCTATAG...\n",
      "1  GI:-  ATGGCTGCAGCTTCATATGATCAGTTGTTAAAGCAAGTTGAGGCAC...\n",
      "2  GI:-  ATGAGCCGCCTGCTCTGGAGGAAGGTGGCCGGCGCCACCGTCGGGC...\n",
      "3  GI:-  ATGCAGAGCTGGAGTCGTGTGTACTGCTCCTTGGCCAAGAGAGGCC...\n",
      "4  GI:-  ATGGTTGGCTATGACCCCAAACCAGATGGCAGGAATAACACCAAGT...\n",
      "(2010, 2)\n"
     ]
    }
   ],
   "source": [
    "# for each sequence, get all the datasets that contain it\n",
    "d = {}\n",
    "for _, row in deg_dataset.iterrows():\n",
    "    if(row[\"sequence\"] in d):\n",
    "        d[row[\"sequence\"]].append((row[\"id1\"], row[\"id4\"]))\n",
    "    else:\n",
    "        d[row[\"sequence\"]] = [(row[\"id1\"], row[\"id4\"])]\n",
    "\n",
    "\n",
    "# get a list of sequences that are in more than 5 datasets\n",
    "essential_sequences = []\n",
    "for key, val in d.items():\n",
    "    if(len(val) >= 5):\n",
    "        essential_sequences.append((val[0][1], key))\n",
    "        \n",
    "# create dataframe with essential sequences\n",
    "eg_positive = pd.DataFrame(essential_sequences, columns=[\"id\", \"sequence\"])\n",
    "print(eg_positive.head())\n",
    "print(eg_positive.shape)\n",
    "\n",
    "# write to csv\n",
    "eg_positive.to_csv(\"datasets/essential_genes_positive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique positive sequences: 2010\n",
      "unique negative sequences: 23443\n"
     ]
    }
   ],
   "source": [
    "print(\"unique positive sequences:\", len(set(eg_positive[\"sequence\"])))\n",
    "print(\"unique negative sequences:\", len(set(eg_negative[\"sequence\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the negative dataset has 27684 sequences, not all of them are unique. So, we need to remove the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23443, 2)\n"
     ]
    }
   ],
   "source": [
    "eg_negative = eg_negative.drop_duplicates(subset=\"sequence\")\n",
    "print(eg_negative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have both positive and negative datasets:\n",
    "* eg_positive (2010,  2) -> positive dataset with essential genes \n",
    "* eg_negative (23443, 2) -> negative dataset with non essential genes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating length of each sequence and cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg_positive[\"length\"] = eg_positive[\"sequence\"].str.len()\n",
    "eg_negative[\"length\"] = eg_negative[\"sequence\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before removing\n",
      "(2010, 3)\n",
      "(23443, 3)\n",
      "after removing\n",
      "(2010, 3) 0 were removed\n",
      "(23439, 3) 4 were removed\n"
     ]
    }
   ],
   "source": [
    "print(\"before removing\")\n",
    "print(eg_positive.shape)\n",
    "print(eg_negative.shape)\n",
    "\n",
    "old_eg_positive = eg_positive.shape[0]\n",
    "old_eg_negative = eg_negative.shape[0]\n",
    "\n",
    "eg_positive = eg_positive[eg_positive[\"length\"] <= 20000]\n",
    "eg_negative = eg_negative[eg_negative[\"length\"] <= 20000]\n",
    "print(\"after removing\")\n",
    "print(eg_positive.shape, old_eg_positive - eg_positive.shape[0], \"were removed\")\n",
    "print(eg_negative.shape, old_eg_negative - eg_negative.shape[0], \"were removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics about the data, including:\n",
    "* Total sequences\n",
    "* Top 5 longest and shortest sequences\n",
    "* Average length of sequences\n",
    "* Top 5 most and least common sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(dataset):\n",
    "    dataset[\"length\"].hist(bins=100)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Total sequences:\", dataset.shape[0])\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Top 5 longest sequences:\")\n",
    "    print(\"id       length\")\n",
    "    print(dataset[\"length\"].nlargest(5).to_string())\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Top 5 shortest sequences:\")\n",
    "    print(\"id       length\")\n",
    "    print(dataset[\"length\"].nsmallest(5).to_string())\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    average_length = dataset[\"length\"].mean()\n",
    "    print(\"Average length:\", average_length)\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Top 5 most common lengths:\")\n",
    "    print(\"length   count\")\n",
    "    print(dataset[\"length\"].value_counts().nlargest(5).to_string())\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"Top 5 least common lengths:\")\n",
    "    print(\"length   count\")\n",
    "    print(dataset[\"length\"].value_counts().nsmallest(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Total sequences: 2010\n",
      "----------------------------------------\n",
      "Top 5 longest sequences:\n",
      "id       length\n",
      "676    16791\n",
      "248    15615\n",
      "204    14574\n",
      "491    13941\n",
      "31     13167\n",
      "----------------------------------------\n",
      "Top 5 shortest sequences:\n",
      "id       length\n",
      "1112    192\n",
      "1427    195\n",
      "1500    204\n",
      "1611    204\n",
      "1346    210\n",
      "----------------------------------------\n",
      "Average length: 1903.6034825870647\n",
      "----------------------------------------\n",
      "Top 5 most common lengths:\n",
      "length   count\n",
      "1083    9\n",
      "1041    8\n",
      "618     7\n",
      "585     7\n",
      "1314    7\n",
      "----------------------------------------\n",
      "Top 5 least common lengths:\n",
      "length   count\n",
      "4311    1\n",
      "2289    1\n",
      "2958    1\n",
      "513     1\n",
      "2799    1\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Total sequences: 23439\n",
      "----------------------------------------\n",
      "Top 5 longest sequences:\n",
      "id       length\n",
      "20105    18921\n",
      "2852     17673\n",
      "12774    17388\n",
      "23013    17289\n",
      "25523    16965\n",
      "----------------------------------------\n",
      "Top 5 shortest sequences:\n",
      "id       length\n",
      "6728      3\n",
      "14762     5\n",
      "13586    10\n",
      "23228    10\n",
      "25635    12\n",
      "----------------------------------------\n",
      "Average length: 1351.6297196979394\n",
      "----------------------------------------\n",
      "Top 5 most common lengths:\n",
      "length   count\n",
      "939    98\n",
      "945    76\n",
      "930    72\n",
      "444    66\n",
      "948    63\n",
      "----------------------------------------\n",
      "Top 5 least common lengths:\n",
      "length   count\n",
      "644      1\n",
      "997      1\n",
      "11724    1\n",
      "607      1\n",
      "10896    1\n"
     ]
    }
   ],
   "source": [
    "stats(eg_positive)\n",
    "print(\"*\" * 100)\n",
    "stats(eg_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the positive and negative datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25449, 3)\n",
      "     id                                           sequence  label\n",
      "0  GI:-  ATGGTGCTGTCCCAGAGACAACGAGATGAACTAAATCGAGCTATAG...      1\n",
      "1  GI:-  ATGGCTGCAGCTTCATATGATCAGTTGTTAAAGCAAGTTGAGGCAC...      1\n",
      "2  GI:-  ATGAGCCGCCTGCTCTGGAGGAAGGTGGCCGGCGCCACCGTCGGGC...      1\n",
      "3  GI:-  ATGCAGAGCTGGAGTCGTGTGTACTGCTCCTTGGCCAAGAGAGGCC...      1\n",
      "4  GI:-  ATGGTTGGCTATGACCCCAAACCAGATGGCAGGAATAACACCAAGT...      1\n"
     ]
    }
   ],
   "source": [
    "# adding labels to the dataset\n",
    "eg_positive[\"label\"] = 1\n",
    "eg_negative[\"label\"] = 0\n",
    "\n",
    "# removing length column\n",
    "eg_positive = eg_positive.drop(columns=[\"length\"])\n",
    "eg_negative = eg_negative.drop(columns=[\"length\"])\n",
    "\n",
    "# joining the two datasets\n",
    "dataset = pd.concat([eg_positive, eg_negative])\n",
    "print(dataset.shape)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25449, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of each class\n",
    "dataset.groupby('label').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using DNA descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "\n",
    "sys.path.append('../../../../src/')\n",
    "from propythia.DNA.descriptors.descriptors import DNADescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of descriptors to be calculed. If empty, all descriptors will be calculated.\n",
    "specifics = []\n",
    "\n",
    "def calculate_feature(data):\n",
    "    list_feature = []\n",
    "    count = 0\n",
    "    for seq in data['sequence']:\n",
    "        res = {'sequence': seq}\n",
    "        dna = DNADescriptor(seq)\n",
    "        feature = dna.get_descriptors(specifics=specifics)\n",
    "        res.update(feature)\n",
    "        list_feature.append(res)\n",
    "        # print progress every 100 sequences\n",
    "        if count % 100 == 0:\n",
    "            print(count, '/', len(data))\n",
    "\n",
    "        count += 1\n",
    "    print(\"Done!\")\n",
    "    df = pd.DataFrame(list_feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the calculation of descriptors if `essential_genes_features.pkl` exists which already has them calculated. Skip all of this if `fps_x.pkl` exists because it already has the features calculated and **normalized**. The need of data normalization is explained in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features already calculated and normalized\n"
     ]
    }
   ],
   "source": [
    "if exists(\"datasets/fps_x.pkl\") == False:\n",
    "    if exists(\"datasets/essential_genes_features.pkl\"):\n",
    "        with open(\"datasets/essential_genes_features.pkl\", \"rb\") as f:\n",
    "            features = pickle.load(f)\n",
    "        print(\"Features loaded from pickle file\")\n",
    "    else:\n",
    "        features = calculate_feature(dataset)\n",
    "        with open(\"datasets/essential_genes_features.pkl\", \"wb\") as f:\n",
    "            pickle.dump(features, f)\n",
    "else:\n",
    "    print(\"Features already calculated and normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to help normalize the data.\n",
    "\n",
    "Without being normalized, we have a dataset with 20 columns. Each column is a result of a DNA descriptor, and some of these columns are numbers, dicts and even lists.\n",
    "\n",
    "We still need to normalize those who have dictionaries and lists because the model can't handle data in these types.\n",
    "\n",
    "To normalize the data, dicts and lists need to \"explode\" into more columns. \n",
    "\n",
    "E.g. dicts:\n",
    "\n",
    "| descriptor_hello |\n",
    "| ---------------- |\n",
    "| {'a': 1, 'b': 2} |\n",
    "\n",
    "will be transformed into:\n",
    "\n",
    "| descriptor_hello_a | descriptor_hello_b |\n",
    "| ------------------ | ------------------ |\n",
    "| 1                  | 2                  |\n",
    "\n",
    "E.g. lists:\n",
    "\n",
    "| descriptor_hello |\n",
    "| ---------------- |\n",
    "| [1, 2, 3]        |\n",
    "\n",
    "will be transformed into:\n",
    "\n",
    "| descriptor_hello_0 | descriptor_hello_1 | descriptor_hello_2 |\n",
    "| ------------------ | ------------------ | ------------------ |\n",
    "| 1                  | 2                  | 3                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lists(fps_x, field):\n",
    "    l = fps_x[field].to_list()\n",
    "    new_df = pd.DataFrame(l)\n",
    "    new_df.columns = [str(field) + \"_\" + str(i) for i in new_df.columns]\n",
    "    fps_x.drop(field, axis=1, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "def process_lists_of_lists(fps_x, field):\n",
    "    l = fps_x[field].to_list()\n",
    "    new_df = pd.DataFrame(l)\n",
    "    new_df.columns = [str(field) + \"_\" + str(i) for i in new_df.columns]\n",
    "    empty_val = {} if field == \"enhanced_nucleic_acid_composition\" else []\n",
    "    small_processed = []\n",
    "    count = 0\n",
    "    for f in new_df.columns:\n",
    "        col = [empty_val if i is None else i for i in new_df[f].to_list()]\n",
    "        sub = pd.DataFrame(col)\n",
    "        sub.columns = [str(f) + \"_\" + str(i) for i in sub.columns]\n",
    "        small_processed.append(sub)\n",
    "        if(count % 1000 == 0):\n",
    "            print(count, '/', len(new_df.columns))\n",
    "        count += 1\n",
    "    fps_x.drop(field, axis=1, inplace=True)\n",
    "    return small_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features():\n",
    "    fps_y = dataset['label']\n",
    "    fps_x = features.loc[:, features.columns != 'label']\n",
    "    fps_x = fps_x.loc[:, fps_x.columns != 'sequence']\n",
    "    print(fps_x.shape)\n",
    "    \n",
    "    lists = [\"nucleic_acid_composition\",\"dinucleotide_composition\",\"trinucleotide_composition\",\"k_spaced_nucleic_acid_pairs\",\"kmer\",\"PseDNC\", \"PseKNC\", \"DAC\", \"DCC\", \"DACC\", \"TAC\",\"TCC\",\"TACC\", \"accumulated_nucleotide_frequency\"]\n",
    "    lists_of_lists = [\n",
    "        \"enhanced_nucleic_acid_composition\",\n",
    "        \"nucleotide_chemical_property\", \n",
    "        \"binary\"\n",
    "    ]\n",
    "\n",
    "    small_processed = []\n",
    "    for i in lists:\n",
    "        print(\"Starting:\", i)\n",
    "        new_df = process_lists(fps_x, i)\n",
    "        small_processed.append(new_df)\n",
    "        \n",
    "    for i in lists_of_lists:\n",
    "        print(\"Starting:\", i)\n",
    "        smaller_processed = process_lists_of_lists(fps_x, i)\n",
    "        small_processed += smaller_processed\n",
    "\n",
    "    # concat final with original\n",
    "    fps_x = pd.concat([fps_x, *small_processed], axis=1)\n",
    "\n",
    "    with open(\"datasets/fps_x.pkl\", \"wb\") as f:\n",
    "        pickle.dump(fps_x, f)\n",
    "        \n",
    "    with open(\"datasets/fps_y.pkl\", \"wb\") as f:\n",
    "        pickle.dump(fps_y, f)\n",
    "    \n",
    "    return fps_x, fps_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the data normalization if it was already performed (`fps_x.pkl` exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from pickle file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>gc_content</th>\n",
       "      <th>at_content</th>\n",
       "      <th>nucleic_acid_composition_A</th>\n",
       "      <th>nucleic_acid_composition_C</th>\n",
       "      <th>nucleic_acid_composition_G</th>\n",
       "      <th>nucleic_acid_composition_T</th>\n",
       "      <th>dinucleotide_composition_AA</th>\n",
       "      <th>dinucleotide_composition_AC</th>\n",
       "      <th>dinucleotide_composition_AG</th>\n",
       "      <th>...</th>\n",
       "      <th>binary_18918_2</th>\n",
       "      <th>binary_18918_3</th>\n",
       "      <th>binary_18919_0</th>\n",
       "      <th>binary_18919_1</th>\n",
       "      <th>binary_18919_2</th>\n",
       "      <th>binary_18919_3</th>\n",
       "      <th>binary_18920_0</th>\n",
       "      <th>binary_18920_1</th>\n",
       "      <th>binary_18920_2</th>\n",
       "      <th>binary_18920_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1233</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.075</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8532</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.089</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3720</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.089</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1530</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>963</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25444</th>\n",
       "      <td>576</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.068</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25445</th>\n",
       "      <td>576</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.066</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25446</th>\n",
       "      <td>3363</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.076</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25447</th>\n",
       "      <td>1101</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.105</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25448</th>\n",
       "      <td>96</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25449 rows × 227271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       length  gc_content  at_content  nucleic_acid_composition_A  \\\n",
       "0        1233       0.440       0.560                       0.303   \n",
       "1        8532       0.412       0.588                       0.344   \n",
       "2        3720       0.604       0.396                       0.215   \n",
       "3        1530       0.414       0.586                       0.303   \n",
       "4         963       0.559       0.441                       0.212   \n",
       "...       ...         ...         ...                         ...   \n",
       "25444     576       0.439       0.561                       0.288   \n",
       "25445     576       0.434       0.566                       0.286   \n",
       "25446    3363       0.394       0.606                       0.338   \n",
       "25447    1101       0.633       0.367                       0.227   \n",
       "25448      96       0.635       0.365                       0.146   \n",
       "\n",
       "       nucleic_acid_composition_C  nucleic_acid_composition_G  \\\n",
       "0                           0.193                       0.247   \n",
       "1                           0.208                       0.205   \n",
       "2                           0.290                       0.314   \n",
       "3                           0.169                       0.246   \n",
       "4                           0.286                       0.273   \n",
       "...                           ...                         ...   \n",
       "25444                       0.210                       0.229   \n",
       "25445                       0.212                       0.222   \n",
       "25446                       0.192                       0.202   \n",
       "25447                       0.292                       0.341   \n",
       "25448                       0.302                       0.333   \n",
       "\n",
       "       nucleic_acid_composition_T  dinucleotide_composition_AA  \\\n",
       "0                           0.256                        0.096   \n",
       "1                           0.244                        0.126   \n",
       "2                           0.181                        0.041   \n",
       "3                           0.282                        0.099   \n",
       "4                           0.229                        0.048   \n",
       "...                           ...                          ...   \n",
       "25444                       0.273                        0.089   \n",
       "25445                       0.280                        0.089   \n",
       "25446                       0.268                        0.122   \n",
       "25447                       0.140                        0.037   \n",
       "25448                       0.219                        0.011   \n",
       "\n",
       "       dinucleotide_composition_AC  dinucleotide_composition_AG  ...  \\\n",
       "0                            0.052                        0.075  ...   \n",
       "1                            0.054                        0.089  ...   \n",
       "2                            0.050                        0.089  ...   \n",
       "3                            0.044                        0.080  ...   \n",
       "4                            0.045                        0.076  ...   \n",
       "...                            ...                          ...  ...   \n",
       "25444                        0.068                        0.068  ...   \n",
       "25445                        0.068                        0.066  ...   \n",
       "25446                        0.055                        0.076  ...   \n",
       "25447                        0.056                        0.105  ...   \n",
       "25448                        0.042                        0.042  ...   \n",
       "\n",
       "       binary_18918_2  binary_18918_3  binary_18919_0  binary_18919_1  \\\n",
       "0                 NaN             NaN             NaN             NaN   \n",
       "1                 NaN             NaN             NaN             NaN   \n",
       "2                 NaN             NaN             NaN             NaN   \n",
       "3                 NaN             NaN             NaN             NaN   \n",
       "4                 NaN             NaN             NaN             NaN   \n",
       "...               ...             ...             ...             ...   \n",
       "25444             NaN             NaN             NaN             NaN   \n",
       "25445             NaN             NaN             NaN             NaN   \n",
       "25446             NaN             NaN             NaN             NaN   \n",
       "25447             NaN             NaN             NaN             NaN   \n",
       "25448             NaN             NaN             NaN             NaN   \n",
       "\n",
       "       binary_18919_2  binary_18919_3  binary_18920_0  binary_18920_1  \\\n",
       "0                 NaN             NaN             NaN             NaN   \n",
       "1                 NaN             NaN             NaN             NaN   \n",
       "2                 NaN             NaN             NaN             NaN   \n",
       "3                 NaN             NaN             NaN             NaN   \n",
       "4                 NaN             NaN             NaN             NaN   \n",
       "...               ...             ...             ...             ...   \n",
       "25444             NaN             NaN             NaN             NaN   \n",
       "25445             NaN             NaN             NaN             NaN   \n",
       "25446             NaN             NaN             NaN             NaN   \n",
       "25447             NaN             NaN             NaN             NaN   \n",
       "25448             NaN             NaN             NaN             NaN   \n",
       "\n",
       "       binary_18920_2  binary_18920_3  \n",
       "0                 NaN             NaN  \n",
       "1                 NaN             NaN  \n",
       "2                 NaN             NaN  \n",
       "3                 NaN             NaN  \n",
       "4                 NaN             NaN  \n",
       "...               ...             ...  \n",
       "25444             NaN             NaN  \n",
       "25445             NaN             NaN  \n",
       "25446             NaN             NaN  \n",
       "25447             NaN             NaN  \n",
       "25448             NaN             NaN  \n",
       "\n",
       "[25449 rows x 227271 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if exists(\"datasets/fps_x.pkl\"):\n",
    "    with open(\"datasets/fps_x.pkl\", \"rb\") as f:\n",
    "        fps_x = pickle.load(f)\n",
    "    with open(\"datasets/fps_y.pkl\", \"rb\") as f:\n",
    "        fps_y = pickle.load(f)\n",
    "    print(\"Features loaded from pickle file\")\n",
    "else:\n",
    "    fps_x, fps_y = normalize_features()\n",
    "fps_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need now to split the dataset into training, test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(\n",
    "    fps_x, fps_y,\n",
    "    test_size=0.2,\n",
    "    train_size=0.8,\n",
    "    stratify=fps_y\n",
    ")\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.25,\n",
    "    train_size=0.75,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_cv = scaler.transform(x_cv)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_cv.shape)\n",
    "print(y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramDict = {\n",
    "    'epoch': 100,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.2,\n",
    "    'loss': nn.CrossEntropyLoss(),\n",
    "    'input_size': x_train.shape[1],\n",
    "    'hidden_size': 128,\n",
    "    'output_size': 2,\n",
    "    'patience': 15\n",
    "}\n",
    "\n",
    "class_weight = {0: 1.0, 1: 4.0}\n",
    "\n",
    "# convert to torch.tensor\n",
    "train_data = data_utils.TensorDataset(\n",
    "    torch.tensor(x_train, dtype=torch.float),\n",
    "    torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    ")\n",
    "test_data = data_utils.TensorDataset(\n",
    "    torch.tensor(x_test, dtype=torch.float),\n",
    "    torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    ")\n",
    "valid_data = data_utils.TensorDataset(\n",
    "    torch.tensor(x_cv, dtype=torch.float),\n",
    "    torch.tensor(y_cv.to_numpy(), dtype=torch.long)\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "trainloader = data_utils.DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=paramDict['batch_size']\n",
    ")\n",
    "testloader = data_utils.DataLoader(\n",
    "    test_data,\n",
    "    shuffle=True,\n",
    "    batch_size=paramDict['batch_size']\n",
    ")\n",
    "validloader = data_utils.DataLoader(\n",
    "    valid_data,\n",
    "    shuffle=True,\n",
    "    batch_size=paramDict['batch_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.models import MLP\n",
    "from src.train import traindata\n",
    "from src.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2022)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4,5'\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.004\n",
    "model = MLP(\n",
    "    paramDict['input_size'],\n",
    "    paramDict['hidden_size'],\n",
    "    paramDict['output_size'],\n",
    "    paramDict['dropout']\n",
    ").to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model = traindata(device, model, epochs, optimizer, paramDict['loss'], trainloader, validloader, paramDict['patience'])\n",
    "\n",
    "# Test\n",
    "acc, mcc, report = test(device, model, testloader)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('MCC: %.3f' % mcc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.utils.data as data_utils\n",
    "# import src.encoding as enc\n",
    "# import os\n",
    "# from torch import nn\n",
    "# from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using descriptors and using one hot encoding, all sequences need to have the same length. So, some sequences will be truncated or padded with Ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fps_x = dataset['sequence'].values\n",
    "# fps_y = dataset['label'].values\n",
    "\n",
    "# average_length = int(average_length)\n",
    "\n",
    "# cut sequences to the average length\n",
    "# seqs_dataset = seqs_dataset.str.slice(0, average_length)\n",
    "\n",
    "# fill with \"N\" the sequences that are shorter than average length\n",
    "# seqs_dataset = seqs_dataset.str.pad(average_length, side='right', fillchar='N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need now to split the dataset into training, test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, x_test, y, y_test = train_test_split(\n",
    "#     fps_x, fps_y,\n",
    "#     test_size=0.2,\n",
    "#     train_size=0.8,\n",
    "#     stratify=fps_y\n",
    "# )\n",
    "# x_train, x_cv, y_train, y_cv = train_test_split(\n",
    "#     x, y,\n",
    "#     test_size=0.25,\n",
    "#     train_size=0.75,\n",
    "#     stratify=y\n",
    "# )\n",
    "\n",
    "# print(fps_x.shape)\n",
    "# print(fps_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to one hot encode the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_enc = enc.DNAEncoding(x_train)\n",
    "# x_train = x_train_enc.one_hot_encode()\n",
    "\n",
    "# x_test_enc = enc.DNAEncoding(x_test)\n",
    "# x_test = x_test_enc.one_hot_encode()\n",
    "\n",
    "# x_cv_enc = enc.DNAEncoding(x_cv)\n",
    "# x_cv = x_cv_enc.one_hot_encode()\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "# print(x_cv.shape)\n",
    "# print(y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to torch.tensor\n",
    "# train_data = data_utils.TensorDataset(\n",
    "#     torch.tensor(x_train, dtype=torch.float),\n",
    "#     torch.tensor(y_train, dtype=torch.long)\n",
    "# )\n",
    "# test_data = data_utils.TensorDataset(\n",
    "#     torch.tensor(x_test, dtype=torch.float),\n",
    "#     torch.tensor(y_test, dtype=torch.long)\n",
    "# )\n",
    "# valid_data = data_utils.TensorDataset(\n",
    "#     torch.tensor(x_cv, dtype=torch.float),\n",
    "#     torch.tensor(y_cv, dtype=torch.long)\n",
    "# )\n",
    "\n",
    "# batch_size = 16\n",
    "\n",
    "# # Data loader\n",
    "# trainloader = data_utils.DataLoader(\n",
    "#     train_data,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "# testloader = data_utils.DataLoader(\n",
    "#     test_data,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "# validloader = data_utils.DataLoader(\n",
    "#     valid_data,\n",
    "#     shuffle=True,\n",
    "#     batch_size=batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model equivalent to the one in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.models import MLP\n",
    "# from src.train import traindata\n",
    "# from src.test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(2022)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4,5'\n",
    "# device = torch.device('cuda:0')\n",
    "\n",
    "# model = MLP().to(device)\n",
    "\n",
    "# paramDict = {\n",
    "#     'epoch': 200,\n",
    "#     'batchSize': 32,\n",
    "#     'dropOut': 0.2,\n",
    "#     'learning_rate': 0.004,\n",
    "#     'loss': nn.CrossEntropyLoss(),\n",
    "#     'metrics': ['accuracy'],\n",
    "#     'activation1': 'relu',\n",
    "#     'activation2': 'sigmoid',\n",
    "#     'monitor': 'val_accuracy',\n",
    "#     'save_best_only': True,\n",
    "#     'mode': 'max'\n",
    "# }\n",
    "\n",
    "# class_weight = {0: 1.0, 1: 4.0}\n",
    "\n",
    "# optimizerDict = {\n",
    "#     'adam': Adam(model.parameters(), learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # epochs = 100\n",
    "# # lr = 0.004\n",
    "# # loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# #optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# model = traindata(device, model, paramDict['epochs'], optimizerDict['adam'], paramDict['loss'], trainloader, validloader)\n",
    "\n",
    "# acc, mcc, report = test(device, model, testloader)\n",
    "# print('Accuracy: %.3f' % acc)\n",
    "# print('MCC: %.3f' % mcc)\n",
    "# print(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba449ea13c29f64a91968d8f927cecceedd6e605eda30388903386e6cd94168d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dna-conda': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
