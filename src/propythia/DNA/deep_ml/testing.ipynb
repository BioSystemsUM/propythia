{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of human sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to replicate the [Classifying human DNA sequence and random ATCG sequences, using keras CNN](https://github.com/onceupon/deep_learning_DNA) problem, but using PyTorch instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import DataParallel\n",
    "from torch import Tensor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n",
      "                                            sequence  label\n",
      "0  CTACTCGGGAGGCTGAGGCAGGAGAATCACTTGAACCAGGGAGTCA...      1\n",
      "1  CACCTTATCCAGAGAAGCTTCTTCTTTTAGAAAATCAAGCAAAACA...      1\n",
      "2  AAAGGGGCTGATAGAAAAATAAAGAGATTTGGCCAGGTACGGTGGC...      1\n",
      "3  AAGTGGATATTCAGACCTCCTTGAGGCCTTCGTTGGAAACGGGATT...      1\n",
      "4  ATACCATGACAAAGATATTATTAGCCAATTTTTAGAGAGAAGGAAA...      1\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"datasets/human-exercise/dataset.csv\")\n",
    "print(dataset.shape)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this dataset contains the sequence and the corresponding positive/negative class labels, with positive class labels corresponding to the human DNA. The amount of positive and negative examples is evenly distributed across the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10000\n",
      "0    10000\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of each class\n",
    "dataset.groupby('label').size().plot(kind='bar')\n",
    "\n",
    "print(dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to one hot encode the sequences and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [1,...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[[0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sequence   label\n",
       "0      [[0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...  [1, 0]\n",
       "1      [[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...  [1, 0]\n",
       "2      [[1, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0,...  [1, 0]\n",
       "3      [[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [0,...  [1, 0]\n",
       "4      [[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [0,...  [1, 0]\n",
       "...                                                  ...     ...\n",
       "19995  [[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...  [0, 1]\n",
       "19996  [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...  [0, 1]\n",
       "19997  [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0,...  [0, 1]\n",
       "19998  [[1, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0], [1,...  [0, 1]\n",
       "19999  [[0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 0, 1], [0,...  [0, 1]\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import encoding as enc\n",
    "\n",
    "dna_enc = enc.DNAEncoding(dataset)\n",
    "one_hot_dataset = dna_enc.one_hot_encode(enconde_target=True) # returns a dataframe\n",
    "one_hot_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000008vscode-remote?line=1'>2</a>\u001b[0m fps_y \u001b[39m=\u001b[39m one_hot_dataset[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# split dataset into train and test\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(fps_x, fps_y, stratify\u001b[39m=\u001b[39;49mfps_y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X_train\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_train\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2441\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2436'>2437</a>\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2438'>2439</a>\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m-> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2440'>2441</a>\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2442'>2443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2443'>2444</a>\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2444'>2445</a>\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2445'>2446</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2446'>2447</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2022\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=1987'>1988</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=1988'>1989</a>\u001b[0m     \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=1989'>1990</a>\u001b[0m \n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=1990'>1991</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2019'>2020</a>\u001b[0m \u001b[39m    to an integer.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2020'>2021</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2021'>2022</a>\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/model_selection/_split.py?line=2022'>2023</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=798'>799</a>\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=799'>800</a>\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=801'>802</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=802'>803</a>\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=118'>119</a>\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=119'>120</a>\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n\u001b[0;32m--> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=120'>121</a>\u001b[0m     \u001b[39mif\u001b[39;00m _object_dtype_isnan(X)\u001b[39m.\u001b[39;49many():\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/sklearn/utils/validation.py?line=121'>122</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput contains NaN\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "fps_x = one_hot_dataset['sequence'].values\n",
    "fps_y = one_hot_dataset['label'].values\n",
    "\n",
    "# split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(fps_x, fps_y, stratify=fps_y)\n",
    "\n",
    "X_train = np.array(X_train.tolist())\n",
    "y_train = np.array(y_train.tolist())\n",
    "X_test = np.array(X_test.tolist())\n",
    "y_test = np.array(y_test.tolist())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, everything is working fine because the Keras model achieved the same accuracy as comparative study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float), torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader = data_utils.DataLoader(train_data, shuffle=True, batch_size=16)\n",
    "test_data = data_utils.TensorDataset(torch.tensor(X_test, dtype=torch.float), torch.tensor(y_test, dtype=torch.long))\n",
    "test_loader = data_utils.DataLoader(test_data, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(4, 20, 10, stride=1, padding=0)\n",
    "        self.fc1 = nn.Linear(47, 10)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "\n",
    "        self.max_pool = nn.MaxPool1d(10, stride=5)\n",
    "    \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.act3 = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act1(x)\n",
    "        print(\"xasd:\", x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % 1000 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "\n",
    "def train_model(train_loader, model, epochs, device):\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(epochs):\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(inputs)\n",
    "            # print(\"yhat: \", yhat)\n",
    "            # print(\"yhat.shape: \", yhat.shape)\n",
    "            loss = criterion(yhat, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch: {epoch}, Loss: {loss}')\n",
    "            \n",
    "\n",
    "# def test(model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability            \n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "from numpy import vstack\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, device, test_loader):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        yhat = model(inputs)\n",
    "        yhat = yhat.cpu().detach().numpy()\n",
    "        actual = targets.cpu().numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yhat = yhat.reshape((len(yhat), 1))\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    mcc = matthews_corrcoef(actuals, predictions)\n",
    "    report = confusion_matrix(actuals, predictions)\n",
    "    return acc, mcc, report\n",
    "\n",
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yhat = model(row)\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xasd: tensor([[[0.3367, 0.0000],\n",
      "         [0.3600, 0.0000],\n",
      "         [0.1574, 0.0000],\n",
      "         [0.1903, 0.0000],\n",
      "         [0.1264, 0.0000],\n",
      "         [0.2979, 0.0000],\n",
      "         [0.0348, 0.0000],\n",
      "         [0.2195, 0.0000],\n",
      "         [0.3621, 0.0000],\n",
      "         [0.1593, 0.0000],\n",
      "         [0.0745, 0.0000],\n",
      "         [0.0000, 0.0046],\n",
      "         [0.0956, 0.0000],\n",
      "         [0.1793, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.3047, 0.0000],\n",
      "         [0.2527, 0.0000],\n",
      "         [0.2547, 0.0000],\n",
      "         [0.0999, 0.0000],\n",
      "         [0.0306, 0.0000]],\n",
      "\n",
      "        [[0.1947, 0.0000],\n",
      "         [0.5725, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0798, 0.0000],\n",
      "         [0.0000, 0.0069],\n",
      "         [0.1191, 0.0000],\n",
      "         [0.3996, 0.0000],\n",
      "         [0.1152, 0.0000],\n",
      "         [0.3394, 0.0000],\n",
      "         [0.0255, 0.0359],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0000, 0.0280],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.2836, 0.0000],\n",
      "         [0.1624, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.1150, 0.0000],\n",
      "         [0.1336, 0.0000],\n",
      "         [0.1269, 0.0000]],\n",
      "\n",
      "        [[0.1396, 0.0532],\n",
      "         [0.1692, 0.0000],\n",
      "         [0.0341, 0.0428],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.1308, 0.0000],\n",
      "         [0.0985, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.1072, 0.0538],\n",
      "         [0.1320, 0.1156],\n",
      "         [0.0643, 0.0187],\n",
      "         [0.0381, 0.0000],\n",
      "         [0.0209, 0.0000],\n",
      "         [0.2225, 0.0000],\n",
      "         [0.1121, 0.0000],\n",
      "         [0.2287, 0.0000],\n",
      "         [0.4160, 0.0000],\n",
      "         [0.1144, 0.0000],\n",
      "         [0.0801, 0.0000],\n",
      "         [0.0353, 0.0000],\n",
      "         [0.0500, 0.0838]],\n",
      "\n",
      "        [[0.3759, 0.0000],\n",
      "         [0.0196, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0430, 0.0000],\n",
      "         [0.0722, 0.0735],\n",
      "         [0.0736, 0.0000],\n",
      "         [0.4452, 0.0000],\n",
      "         [0.1078, 0.0000],\n",
      "         [0.3277, 0.0000],\n",
      "         [0.1110, 0.0000],\n",
      "         [0.1318, 0.1176],\n",
      "         [0.2314, 0.0000],\n",
      "         [0.0336, 0.0519],\n",
      "         [0.1781, 0.0000],\n",
      "         [0.2672, 0.0000],\n",
      "         [0.3023, 0.0000],\n",
      "         [0.0214, 0.0000],\n",
      "         [0.3540, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.0850, 0.0000]],\n",
      "\n",
      "        [[0.2662, 0.0000],\n",
      "         [0.1530, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.2486, 0.0000],\n",
      "         [0.0847, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0791, 0.0000],\n",
      "         [0.0094, 0.0000],\n",
      "         [0.3778, 0.0000],\n",
      "         [0.0122, 0.0000],\n",
      "         [0.0701, 0.1186],\n",
      "         [0.0018, 0.1362],\n",
      "         [0.0413, 0.0090],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0601, 0.0000],\n",
      "         [0.2103, 0.0000],\n",
      "         [0.1196, 0.0000],\n",
      "         [0.1170, 0.1668],\n",
      "         [0.0776, 0.0000],\n",
      "         [0.1862, 0.0000]],\n",
      "\n",
      "        [[0.5484, 0.0000],\n",
      "         [0.3758, 0.0000],\n",
      "         [0.0000, 0.1054],\n",
      "         [0.1010, 0.0000],\n",
      "         [0.1918, 0.0000],\n",
      "         [0.1899, 0.0000],\n",
      "         [0.0903, 0.1448],\n",
      "         [0.0270, 0.0230],\n",
      "         [0.2804, 0.0000],\n",
      "         [0.1775, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.2267, 0.0300],\n",
      "         [0.1789, 0.0000],\n",
      "         [0.2024, 0.0000],\n",
      "         [0.1984, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.1358, 0.0000],\n",
      "         [0.1183, 0.0489],\n",
      "         [0.2062, 0.0000],\n",
      "         [0.0000, 0.0061]],\n",
      "\n",
      "        [[0.2112, 0.0000],\n",
      "         [0.0860, 0.1199],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0442, 0.0000],\n",
      "         [0.1410, 0.0000],\n",
      "         [0.3565, 0.0000],\n",
      "         [0.0307, 0.1062],\n",
      "         [0.2507, 0.0000],\n",
      "         [0.0768, 0.0000],\n",
      "         [0.0317, 0.0000],\n",
      "         [0.1584, 0.0000],\n",
      "         [0.0783, 0.0544],\n",
      "         [0.0913, 0.0000],\n",
      "         [0.1997, 0.0000],\n",
      "         [0.0850, 0.0000],\n",
      "         [0.5096, 0.0000],\n",
      "         [0.1187, 0.0000],\n",
      "         [0.2125, 0.0161],\n",
      "         [0.1616, 0.0000],\n",
      "         [0.0000, 0.0000]],\n",
      "\n",
      "        [[0.3361, 0.0000],\n",
      "         [0.0805, 0.0653],\n",
      "         [0.3528, 0.0000],\n",
      "         [0.2261, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.0721, 0.0000],\n",
      "         [0.2006, 0.0000],\n",
      "         [0.3372, 0.0000],\n",
      "         [0.0000, 0.0234],\n",
      "         [0.0588, 0.0000],\n",
      "         [0.1209, 0.0000],\n",
      "         [0.2914, 0.0000],\n",
      "         [0.1791, 0.0000],\n",
      "         [0.3520, 0.0000],\n",
      "         [0.3442, 0.0000],\n",
      "         [0.2878, 0.0895],\n",
      "         [0.1936, 0.0000],\n",
      "         [0.0000, 0.0000],\n",
      "         [0.1528, 0.0000],\n",
      "         [0.0000, 0.1474]]], device='cuda:1', grad_fn=<ReluBackward0>)\n",
      "xasd: tensor([[[3.6984e-01, 0.0000e+00],\n",
      "         [3.7890e-01, 0.0000e+00],\n",
      "         [1.5293e-01, 0.0000e+00],\n",
      "         [1.9509e-01, 0.0000e+00],\n",
      "         [5.1042e-02, 0.0000e+00],\n",
      "         [2.2666e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [2.9629e-01, 0.0000e+00],\n",
      "         [2.7098e-01, 0.0000e+00],\n",
      "         [1.1178e-01, 0.0000e+00],\n",
      "         [8.4584e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [6.2871e-02, 0.0000e+00],\n",
      "         [2.6836e-01, 0.0000e+00],\n",
      "         [4.8392e-02, 0.0000e+00],\n",
      "         [3.2562e-01, 0.0000e+00],\n",
      "         [1.8820e-01, 0.0000e+00],\n",
      "         [1.8461e-01, 0.0000e+00],\n",
      "         [1.1099e-01, 0.0000e+00],\n",
      "         [5.1754e-02, 0.0000e+00]],\n",
      "\n",
      "        [[2.4519e-01, 0.0000e+00],\n",
      "         [4.3140e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 8.8530e-03],\n",
      "         [1.1155e-01, 0.0000e+00],\n",
      "         [2.5479e-04, 0.0000e+00],\n",
      "         [3.7937e-01, 0.0000e+00],\n",
      "         [5.5423e-01, 0.0000e+00],\n",
      "         [1.8983e-01, 0.0000e+00],\n",
      "         [3.5642e-01, 0.0000e+00],\n",
      "         [5.7357e-02, 2.9805e-03],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [1.2405e-03, 0.0000e+00],\n",
      "         [2.9724e-01, 0.0000e+00],\n",
      "         [2.3897e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [2.0563e-01, 0.0000e+00],\n",
      "         [1.9553e-01, 0.0000e+00],\n",
      "         [1.3122e-01, 0.0000e+00]],\n",
      "\n",
      "        [[1.1390e-01, 6.5223e-02],\n",
      "         [1.1194e-01, 0.0000e+00],\n",
      "         [1.2433e-02, 3.4452e-02],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [2.4252e-01, 0.0000e+00],\n",
      "         [3.9502e-02, 8.0372e-02],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [5.3136e-02, 3.3956e-02],\n",
      "         [8.4217e-02, 2.0226e-02],\n",
      "         [2.7720e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [1.9846e-01, 0.0000e+00],\n",
      "         [1.1563e-01, 0.0000e+00],\n",
      "         [1.6502e-01, 0.0000e+00],\n",
      "         [3.6228e-01, 0.0000e+00],\n",
      "         [1.0763e-01, 0.0000e+00],\n",
      "         [2.3374e-01, 0.0000e+00],\n",
      "         [5.2311e-02, 0.0000e+00],\n",
      "         [4.4371e-02, 9.6017e-02]],\n",
      "\n",
      "        [[2.4366e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [4.9385e-02, 0.0000e+00],\n",
      "         [1.0162e-01, 5.5810e-02],\n",
      "         [3.7599e-02, 2.2263e-02],\n",
      "         [4.9084e-01, 0.0000e+00],\n",
      "         [3.3395e-02, 0.0000e+00],\n",
      "         [2.9198e-01, 0.0000e+00],\n",
      "         [2.2319e-01, 0.0000e+00],\n",
      "         [2.5215e-02, 0.0000e+00],\n",
      "         [3.3544e-01, 0.0000e+00],\n",
      "         [5.5900e-02, 3.5898e-02],\n",
      "         [1.4259e-01, 0.0000e+00],\n",
      "         [1.8602e-01, 0.0000e+00],\n",
      "         [4.0752e-01, 0.0000e+00],\n",
      "         [9.7032e-02, 0.0000e+00],\n",
      "         [2.8054e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00]],\n",
      "\n",
      "        [[2.6938e-01, 0.0000e+00],\n",
      "         [2.4129e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [2.2474e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [8.5410e-03, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [2.5639e-01, 4.7056e-02],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [7.4262e-02, 2.9018e-02],\n",
      "         [1.0382e-02, 9.1966e-02],\n",
      "         [7.1564e-02, 1.3895e-02],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [8.0311e-02, 0.0000e+00],\n",
      "         [2.7463e-01, 0.0000e+00],\n",
      "         [2.5257e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 2.2340e-01],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [2.7584e-01, 0.0000e+00]],\n",
      "\n",
      "        [[4.4426e-01, 0.0000e+00],\n",
      "         [3.0781e-01, 6.3938e-03],\n",
      "         [2.0304e-02, 1.3625e-01],\n",
      "         [1.2357e-01, 0.0000e+00],\n",
      "         [5.3961e-02, 0.0000e+00],\n",
      "         [1.3858e-01, 0.0000e+00],\n",
      "         [1.1943e-01, 1.0865e-01],\n",
      "         [5.1756e-02, 0.0000e+00],\n",
      "         [2.6336e-01, 0.0000e+00],\n",
      "         [2.4585e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [1.7363e-01, 0.0000e+00],\n",
      "         [1.7482e-01, 0.0000e+00],\n",
      "         [1.3812e-01, 0.0000e+00],\n",
      "         [1.8187e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [1.0763e-01, 0.0000e+00],\n",
      "         [1.9000e-01, 7.1712e-02],\n",
      "         [3.0314e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 2.1293e-02]],\n",
      "\n",
      "        [[2.1915e-01, 0.0000e+00],\n",
      "         [1.1511e-02, 1.2117e-01],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [2.1211e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [3.3277e-01, 0.0000e+00],\n",
      "         [8.3893e-02, 4.9792e-02],\n",
      "         [2.0109e-01, 0.0000e+00],\n",
      "         [2.1202e-01, 0.0000e+00],\n",
      "         [3.4994e-02, 0.0000e+00],\n",
      "         [1.9242e-01, 0.0000e+00],\n",
      "         [1.0189e-01, 5.7225e-02],\n",
      "         [4.3546e-02, 0.0000e+00],\n",
      "         [2.5610e-01, 0.0000e+00],\n",
      "         [8.5014e-02, 0.0000e+00],\n",
      "         [5.9113e-01, 0.0000e+00],\n",
      "         [1.0427e-01, 0.0000e+00],\n",
      "         [2.2737e-01, 3.0612e-02],\n",
      "         [1.5125e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 4.8316e-03]],\n",
      "\n",
      "        [[4.1387e-01, 0.0000e+00],\n",
      "         [1.2662e-01, 1.4493e-01],\n",
      "         [3.6029e-01, 0.0000e+00],\n",
      "         [8.0585e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [6.9115e-02, 0.0000e+00],\n",
      "         [2.4983e-01, 0.0000e+00],\n",
      "         [2.9026e-01, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00],\n",
      "         [3.3990e-02, 0.0000e+00],\n",
      "         [1.0940e-01, 0.0000e+00],\n",
      "         [2.8857e-01, 0.0000e+00],\n",
      "         [1.0337e-01, 0.0000e+00],\n",
      "         [2.5156e-01, 0.0000e+00],\n",
      "         [3.4525e-01, 0.0000e+00],\n",
      "         [2.8470e-01, 8.6479e-02],\n",
      "         [7.5425e-02, 0.0000e+00],\n",
      "         [6.9468e-02, 0.0000e+00],\n",
      "         [1.2751e-01, 0.0000e+00],\n",
      "         [3.2949e-02, 1.6488e-01]]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 20, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=9'>10</a>\u001b[0m \u001b[39m# optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=10'>11</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=14'>15</a>\u001b[0m \u001b[39m#     test(model, device, test_loader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m#     scheduler.step()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=18'>19</a>\u001b[0m train_model(train_loader, model, epochs, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=19'>20</a>\u001b[0m acc, mcc, report \u001b[39m=\u001b[39m evaluate_model(test_loader, model, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000013vscode-remote?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m acc)\n",
      "\u001b[1;32m/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb Cell 13'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, epochs, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=22'>23</a>\u001b[0m yhat \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=23'>24</a>\u001b[0m \u001b[39m# print(\"yhat: \", yhat)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=24'>25</a>\u001b[0m \u001b[39m# print(\"yhat.shape: \", yhat.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(yhat, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=26'>27</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bturing.di.uminho.pt/home/jabreu/propythia/src/propythia/DNA/deep_ml/testing.ipynb#ch0000012vscode-remote?line=27'>28</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=610'>611</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/modules/loss.py?line=611'>612</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py:3056\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3053'>3054</a>\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3054'>3055</a>\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3055'>3056</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3056'>3057</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3057'>3058</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3058'>3059</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3060'>3061</a>\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/jabreu/miniconda3/envs/dna-conda/lib/python3.8/site-packages/torch/nn/functional.py?line=3061'>3062</a>\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 20, 2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2022)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4,5'\n",
    "device = torch.device('cuda:0')\n",
    "epochs = 5\n",
    "\n",
    "model = Net()\n",
    "model = DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "# for epoch in range(1,epochs+1):\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     test(model, device, test_loader)\n",
    "#     scheduler.step()\n",
    "\n",
    "\n",
    "train_model(train_loader, model, epochs, device)\n",
    "acc, mcc, report = evaluate_model(test_loader, model, device)\n",
    "\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('MCC: %.3f' % mcc)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba449ea13c29f64a91968d8f927cecceedd6e605eda30388903386e6cd94168d"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
