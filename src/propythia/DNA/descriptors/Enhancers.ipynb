{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of enhancers case study "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will present a comparative analysis to demonstrate the application and performance of proPythia for addressing sequence-based prediction problems.\n",
    "\n",
    "We'll try to replicate one of the [BioSeq-Analysis](https://academic.oup.com/nar/article/47/20/e127/5559689?login=true) case studies for identifying [enhancers](https://academic.oup.com/bioinformatics/article/32/3/362/1744331?login=true#btv604-M1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append('../../../../src/')\n",
    "from propythia.shallow_ml import ShallowML\n",
    "\n",
    "from descriptors import DNADescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_dict_to_csv(d: dict, filename: str):\n",
    "    \"\"\"\n",
    "    Writes a dictionary to a csv file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        headers = [\"id\", \"sequence\"]\n",
    "        writer.writerow(headers)\n",
    "        for key, val in d.items():\n",
    "            writer.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence import ReadDNA\n",
    "\n",
    "dna = ReadDNA()\n",
    "dna.read_fasta_in_folder('enhancer_dataset')\n",
    "for i in dna.d:\n",
    "    write_dict_to_csv(dna.d[i], f'enhancer_dataset/{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has **742** weak enhancers, **742** strong enhancers, and **1484** non-enhancers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strong (742, 2)\n",
      "weak (742, 2)\n",
      "non (1484, 2)\n"
     ]
    }
   ],
   "source": [
    "strong_file =  r'enhancer_dataset/strong.csv'\n",
    "weak_file =  r'enhancer_dataset/weak.csv'\n",
    "non_file =  r'enhancer_dataset/non-enhancers.csv'\n",
    "\n",
    "strong = pd.read_csv(strong_file)\n",
    "weak = pd.read_csv(weak_file)\n",
    "non = pd.read_csv(non_file)\n",
    "\n",
    "print('strong', strong.shape)\n",
    "print('weak', weak.shape)\n",
    "print('non', non.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate features, and to be more easy, we create a function to calculate features, calculating all available DNA features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 742\n",
      "100 / 742\n",
      "200 / 742\n",
      "300 / 742\n",
      "400 / 742\n",
      "500 / 742\n",
      "600 / 742\n",
      "700 / 742\n",
      "Done!\n",
      "0 / 742\n",
      "100 / 742\n",
      "200 / 742\n",
      "300 / 742\n",
      "400 / 742\n",
      "500 / 742\n",
      "600 / 742\n",
      "700 / 742\n",
      "Done!\n",
      "0 / 1484\n",
      "100 / 1484\n",
      "200 / 1484\n",
      "300 / 1484\n",
      "400 / 1484\n",
      "500 / 1484\n",
      "600 / 1484\n",
      "700 / 1484\n",
      "800 / 1484\n",
      "900 / 1484\n",
      "1000 / 1484\n",
      "1100 / 1484\n",
      "1200 / 1484\n",
      "1300 / 1484\n",
      "1400 / 1484\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def calculate_feature(data):\n",
    "    list_feature = []\n",
    "    count = 0\n",
    "    for seq in data['sequence']:\n",
    "        res = {'sequence': seq}\n",
    "        dna = DNADescriptor(seq)\n",
    "        feature = dna.get_all_descriptors()\n",
    "        res.update(feature)\n",
    "        list_feature.append(res)\n",
    "        \n",
    "        # print progress every 100 sequences\n",
    "        if count % 100 == 0:\n",
    "            print(count, '/', len(data))\n",
    "\n",
    "        count += 1\n",
    "    print(\"Done!\")\n",
    "    df = pd.DataFrame(list_feature)\n",
    "    return df\n",
    "\n",
    "strong_feature = calculate_feature(strong)\n",
    "weak_feature = calculate_feature(weak)\n",
    "non_feature = calculate_feature(non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the dataframe, each row is a sequence and each column is a feature.\n",
    "- There are 19 different features for each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(742, 21)\n",
      "(742, 21)\n",
      "(1484, 21)\n"
     ]
    }
   ],
   "source": [
    "# put labels for each dataset   \n",
    "strong_feature['label'] = 2\n",
    "weak_feature['label'] = 1\n",
    "non_feature['label'] = 0\n",
    "\n",
    "print(strong_feature.shape)\n",
    "print(weak_feature.shape)\n",
    "print(non_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2968, 19)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.concat([strong_feature, weak_feature, non_feature])\n",
    "\n",
    "fps_y = dataset['label']\n",
    "fps_x = dataset.loc[:, dataset.columns != 'label']\n",
    "fps_x = fps_x.loc[:, fps_x.columns != 'sequence']\n",
    "\n",
    "print(fps_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_need_normalization = [\"length\", \"at_content\", \"gc_content\"]\n",
    "\n",
    "need_dict_normalization = [\"nucleic_acid_composition\", \"enhanced_nucleic_acid_composition\",\"dinucleotide_composition\",\"trinucleotide_composition\",\"k_spaced_nucleic_acid_pairs\",\"kmer\",\"PseDNC\", \"PseKNC\"]\n",
    "\n",
    "need_list_normalization = [\"nucleotide_chemical_property\", \"accumulated_nucleotide_frequency\", \"DAC\", \"DCC\", \"DACC\", \"TAC\",\"TCC\",\"TACC\"]\n",
    "\n",
    "def normalize_dict(d, field):\n",
    "    df = pd.json_normalize(d)\n",
    "    df.columns = [str(field) + \"_\" + str(i) for i in df.columns]\n",
    "    \n",
    "    for f in df.columns:\n",
    "        if isinstance(df[f][0], dict):\n",
    "            df = pd.concat([df, normalize_dict(df[f], f)], axis=1)\n",
    "            df.drop(f, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize_list(l, field):\n",
    "    df = pd.DataFrame(l.to_list())\n",
    "    df.columns = [str(field) + \"_\" + str(i) for i in df.columns]\n",
    "    \n",
    "    for f in df.columns:\n",
    "        if isinstance(df[f][0], list):\n",
    "            df = pd.concat([df, normalize_list(df[f], f)], axis=1)\n",
    "            df.drop(f, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "new_fps_x = pd.DataFrame()\n",
    "\n",
    "for col in fps_x.columns:\n",
    "    if col in need_dict_normalization:\n",
    "        new_fps_x = pd.concat([new_fps_x, normalize_dict(fps_x[col], col)], axis=1)\n",
    "    elif col in need_list_normalization:\n",
    "        new_fps_x = pd.concat([new_fps_x, normalize_list(fps_x[col], col)], axis=1)\n",
    "    else:\n",
    "        new_fps_x[col] = fps_x[col].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing gridSearch...\n",
      "GridSearchCV took 21.15 seconds for 3 candidate parameter settings.\n",
      "GridSearchCV(cv=10,\n",
      "             estimator=Pipeline(steps=[('scl', None),\n",
      "                                       ('clf',\n",
      "                                        RandomForestClassifier(random_state=1))]),\n",
      "             n_jobs=10,\n",
      "             param_grid=[{'clf__max_features': ['sqrt'],\n",
      "                          'clf__n_estimators': [100, 200, 500]}],\n",
      "             scoring=make_scorer(matthews_corrcoef))\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.404 (std: 0.047)\n",
      " Parameters: {'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      " \n",
      "\n",
      "Model with rank: 2\n",
      " Mean validation score: 0.389 (std: 0.043)\n",
      " Parameters: {'clf__max_features': 'sqrt', 'clf__n_estimators': 200}\n",
      " \n",
      "\n",
      "Model with rank: 3\n",
      " Mean validation score: 0.386 (std: 0.043)\n",
      " Parameters: {'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      " \n",
      "\n",
      "make_scorer(matthews_corrcoef)\n",
      "10\n",
      "Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 10-fold cross validation:\n",
      " MCC score:\t0.404\n",
      " Parameters:\t{'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      "\n",
      "0.385594 (0.042814) with: {'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      "0.388819 (0.043232) with: {'clf__max_features': 'sqrt', 'clf__n_estimators': 200}\n",
      "0.403937 (0.047045) with: {'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      "  clf__max_features  clf__n_estimators     means      stds\n",
      "0              sqrt                100  0.385594  0.042814\n",
      "1              sqrt                200  0.388819  0.043232\n",
      "2              sqrt                500  0.403937  0.047045\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_fps_x, fps_y, stratify=fps_y)\n",
    "\n",
    "# standard scaler article does not refer scaling and do not validate in x_test, however, we do it anyway\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# open a ShallowML object\n",
    "ml = ShallowML(X_train, X_test, y_train, y_test, report_name=None, columns_names=new_fps_x.columns)\n",
    "\n",
    "# define param grid as article, here we will search in 100, 200 and 500 estimators\n",
    "param_grid = [{'clf__n_estimators': [100, 200, 500], 'clf__max_features': ['sqrt']}]\n",
    "\n",
    "# rain_best_model will perform a GRIDSEARCHCV optimizing MCC with a cv = 10\n",
    "best_rf_model_enhancers = ml.train_best_model(model_name=None, model='rf', score=make_scorer(matthews_corrcoef), param_grid=param_grid, cv=10)\n",
    "\n",
    "# best_rf_model_enhancers = ml.train_best_model(model_name=None,model='svm', scaler=None,\n",
    "#                  score=make_scorer(matthews_corrcoef),\n",
    "#                  cv=10, optType='gridSearch', param_grid=None,\n",
    "#                  n_jobs=10,\n",
    "#                  random_state=1, n_iter=15, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.88      0.77       371\n",
      "           1       0.47      0.08      0.13       186\n",
      "           2       0.51      0.65      0.57       185\n",
      "\n",
      "    accuracy                           0.62       742\n",
      "   macro avg       0.55      0.54      0.49       742\n",
      "weighted avg       0.59      0.62      0.56       742\n",
      "\n",
      "[[327   9  35]\n",
      " [ 93  14  79]\n",
      " [ 58   7 120]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6212938005390836,\n",
       " 'MCC': 0.38263153702435365,\n",
       " 'log_loss': 0.8246692689341141,\n",
       " 'f1 score weighted': 0.5604658815215733,\n",
       " 'f1 score macro': 0.4909133378665132,\n",
       " 'f1 score micro': 0.6212938005390836,\n",
       " 'roc_auc ovr': 0.7878413910283668,\n",
       " 'roc_auc ovo': 0.7624862110963813,\n",
       " 'precision': 0.5868909031023186,\n",
       " 'recall': 0.6212938005390836}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, report, cm, cm2 = ml.score_testset(best_rf_model_enhancers)\n",
    "print(report)\n",
    "print(cm)  \n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eccc737e2ce2db9aa50ea00a61eebd654f595be3688de5a9cd756821a0256d89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
