{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProPythia DNA Deep Learning module quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook that explains how to perform every step of the developed Deep Learning modules. They include all the necessary steps to complete an entire Deep Learning pipeline. The steps are:\n",
    "\n",
    "- Data reading and validation\n",
    "- Encoders\n",
    "- DNA Descriptors\n",
    "- Data splitting\n",
    "- Model building and training\n",
    "- Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data reading and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The machine learning pipeline uses the same module to read and validate the sequences.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module comprehends functions to read and to validate DNA sequences. First is necessary to create the object ReadDNA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_sequence import ReadDNA\n",
    "reader = ReadDNA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to create sequence objects using a single DNA sequence, a *CSV* and a *FASTA* file. The single sequence is going to be validated (check if all letters belong to the DNA alphabet) and the output will be the sequence in upper case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACGTACGAGCATGCAT\n"
     ]
    }
   ],
   "source": [
    "data = reader.read_sequence(\"ACGTACGAGCATGCAT\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With *CSV* there must be at least a column named 'sequence' in the file. The labels may also be retrieved and validated if the user wants them, but he must specify the `with_label` parameter as **True** and the column with the labels must be named 'label'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence\n",
      "0  CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGA...\n",
      "1  GAGTTTATATGGCGCGAGCCTAGTGGTTTTTGTACTTGTTTGTCGC...\n",
      "2  GATCAGTAGGGAAACAAACAGAGGGCCCAGCCACATCTAGCAGGTA...\n",
      "3  GTCCACGACCGAACTCCCACCTTGACCGCAGAGGTACCACCAGAGC...\n",
      "4  GGCGACCGAACTCCAACTAGAACCTGCATAACTGGCCTGGGAGATA...\n",
      "(2000, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                            sequence  label\n",
      "0  CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGA...      0\n",
      "1  GAGTTTATATGGCGCGAGCCTAGTGGTTTTTGTACTTGTTTGTCGC...      0\n",
      "2  GATCAGTAGGGAAACAAACAGAGGGCCCAGCCACATCTAGCAGGTA...      0\n",
      "3  GTCCACGACCGAACTCCCACCTTGACCGCAGAGGTACCACCAGAGC...      1\n",
      "4  GGCGACCGAACTCCAACTAGAACCTGCATAACTGGCCTGGGAGATA...      1\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"../datasets/primer/dataset.csv\"\n",
    "data = reader.read_csv(filename, with_labels=False)\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "\n",
    "data = reader.read_csv(filename, with_labels=True)\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *FASTA* format is similar to the *CSV* format. It always reads the sequence, and the labels only if the user wants them. The *FASTA* format must be one of the following examples:\n",
    "\n",
    "```\n",
    ">sequence_id1\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTGACTG...\n",
    ">sequence_id2\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTGACTG...\n",
    "``` \n",
    "\n",
    "```\n",
    ">sequence_id1,label1\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTGACTG...\n",
    ">sequence_id2,label2\n",
    "ACTGACTGACTGACTGACTGACTGACTGACTGACTGACTG...\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sequence\n",
      "0  CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGA...\n",
      "1  GAGTTTATATGGCGCGAGCCTAGTGGTTTTTGTACTTGTTTGTCGC...\n",
      "2  GATCAGTAGGGAAACAAACAGAGGGCCCAGCCACATCTAGCAGGTA...\n",
      "3  GTCCACGACCGAACTCCCACCTTGACCGCAGAGGTACCACCAGAGC...\n",
      "4  GGCGACCGAACTCCAACTAGAACCTGCATAACTGGCCTGGGAGATA...\n",
      "(2000, 1)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                            sequence  label\n",
      "0  CCGAGGGCTATGGTTTGGAAGTTAGAACCCTGGGGCTTCTCGCGGA...      0\n",
      "1  GAGTTTATATGGCGCGAGCCTAGTGGTTTTTGTACTTGTTTGTCGC...      0\n",
      "2  GATCAGTAGGGAAACAAACAGAGGGCCCAGCCACATCTAGCAGGTA...      0\n",
      "3  GTCCACGACCGAACTCCCACCTTGACCGCAGAGGTACCACCAGAGC...      1\n",
      "4  GGCGACCGAACTCCAACTAGAACCTGCATAACTGGCCTGGGAGATA...      1\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "filename = \"../datasets/primer/dataset.fasta\"\n",
    "data = reader.read_fasta(filename, with_labels=False)\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "\n",
    "print(\"-\" * 100)\n",
    "\n",
    "data = reader.read_fasta(filename, with_labels=True)\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models automatically extract features from the sequences, but it is necessary to build a representation of the sequences first due to the fact that models can't handle anything other than numerical values. Encoders are easily calculated and can serve as numerical representations of sequences, which can subsequently be used as model input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module comprehends functions to encode the DNA sequences. The encoding step is important because sequences need to be converted into a numerical value in order to create an input matrix for the model. The encoders that have been implemented are:\n",
    "\n",
    "- One-hot encoding\n",
    "- Chemical encoding\n",
    "- K-mer One-hot encoding\n",
    "\n",
    "Below there's an example for each of them.\n",
    "\n",
    "| Encoder             | Sequence | Encoded sequence                             |\n",
    "| ------------------- | -------- | -------------------------------------------- |\n",
    "| One-Hot             | ACGT     | [[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]] |\n",
    "| Chemical            | ACGT     | [[1,1,1], [0,1,0], [1,0,0], [0,0,1]]         |\n",
    "| K-mer One-Hot (k=2) | ACGT     | [[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding is extensively used in deep learning models and is well suited for most models. It is a simple encoding that converts the DNA alphabet into a binary vector. \n",
    "\n",
    "- A -> [1,0,0,0]\n",
    "- C -> [0,1,0,0]\n",
    "- G -> [0,0,1,0]\n",
    "- T -> [0,0,0,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To encode a sequence, we need first to create the object DNAEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.encoding import DNAEncoder\n",
    "encoder = DNAEncoder('ACGTACGAGCATGCAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we only need to specify the encoder method (one-hot, chemical, k-mer one-hot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sequence = encoder.one_hot_encode()\n",
    "print(encoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Chemical encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chemical encoding is a more complex encoding that uses the chemical properties of the DNA alphabet. Each letter is assigned a chemical property and the chemical properties are combined to create a vector. In a nutshell, the chemical properties are:\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Chemical property</th>\n",
    "      <th>Class</th>\n",
    "      <th>Nucleotides</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">Ring structure</td>\n",
    "      <td>Purine</td>\n",
    "      <td>A, G</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Pyrimidine</td>\n",
    "      <td>C, T</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">Hydrogen bond</td>\n",
    "      <td>Weak</td>\n",
    "      <td>A, T</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Strong</td>\n",
    "      <td>C, G</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td rowspan=\"2\">Functional group</td>\n",
    "      <td>Amino</td>\n",
    "      <td>A, C</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Keto</td>\n",
    "      <td>G, T</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "If the letter is in the list of the first nucleotides, it is assigned the value 1 and if it is in the list of the second nucleotides, it is assigned the value 0. \n",
    "\n",
    "- A -> [1, 1, 1]\n",
    "- C -> [0, 0, 1]\n",
    "- G -> [1, 0, 0]\n",
    "- T -> [0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder object is already created so we just need to specify the encoder method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sequence = encoder.chemical_encode()\n",
    "print(encoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. K-mer One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one-hot encoding on DNA sequences solely preserves the positional information of each nucleotide. Recent investigations, however, have shown that including high-order dependencies among nucleotides may enhance the efficacy of DNA models. The K-mer One-hot encoding is a method that aims to overcome this problem.\n",
    "\n",
    "If k = 1,the encoder will create the same vector as the one-hot encoding.\n",
    "\n",
    "If k = 2, 16 dinucleotides will be created, and the encoder will create a vector with the following values:\n",
    "\n",
    "- AA = [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "- AC = [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "- AG = [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "- ...\n",
    "- TT = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "If k = 3, 64 trinucleotides will be created, and the encoder will create a vector with the following values:\n",
    "\n",
    "- AAA = [1,0,0,0,...,0,0,0,0]\n",
    "- AAC = [0,1,0,0,...,0,0,0,0]\n",
    "- ...\n",
    "- TTT = [0,0,0,0,...,0,0,0,1]\n",
    "\n",
    "The value of K can be any integer greater than 1 and less than or equal to the length of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoded_sequence = encoder.kmer_one_hot_encode(k=2)\n",
    "print(encoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module also allows the user to encode multiple sequences at once. The encoder can receive a column of a dataframe full of sequences and return an array of all encoded sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 0 0]\n",
      "  [0 0 1 0]\n",
      "  [1 0 0 0]\n",
      "  [0 1 0 0]\n",
      "  [0 0 1 0]\n",
      "  [1 0 0 0]\n",
      "  [0 0 0 1]\n",
      "  [0 0 1 0]\n",
      "  [0 1 0 0]\n",
      "  [1 0 0 0]\n",
      "  [0 0 0 1]]\n",
      "\n",
      " [[0 1 0 0]\n",
      "  [0 0 1 0]\n",
      "  [1 0 0 0]\n",
      "  [1 0 0 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 0 1]\n",
      "  [0 0 1 0]\n",
      "  [0 0 0 1]\n",
      "  [1 0 0 0]\n",
      "  [0 1 0 0]]\n",
      "\n",
      " [[1 0 0 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 0 1]\n",
      "  [1 0 0 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 1 0]\n",
      "  [0 0 0 1]\n",
      "  [1 0 0 0]\n",
      "  [1 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        ['CGACGATGCAT', 1], \n",
    "        ['CGAAGGTGTAC', 0], \n",
    "        ['AGTAGGGGTAA', 1]\n",
    "    ], \n",
    "    columns=['sequence', 'labels']\n",
    ")\n",
    "\n",
    "column = df['sequence'].values\n",
    "encoder = DNAEncoder(column)\n",
    "encoded_sequences = encoder.one_hot_encode()\n",
    "print(encoded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DNA Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the `quick-start-DL.ipynb` notebook, descriptors are manually calculated and are an attempt to serve as features for the classification model. However, deep learning models cannot use descriptors as features because their purpose is to extract features on their own instead of manually calculating beforehand. The DNA descriptors are being mentioned here because there are some deep learning models that can use them as features, such as deep neural networks, but models like CNNs and RNNs are not able to use them as features.\n",
    "\n",
    "So, at this point, the user can either choose to use encoders or descriptors to proceed to the next step. Using encodings it would be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "reader = ReadDNA()\n",
    "data = reader.read_csv(filename='../datasets/primer/dataset.csv', with_labels=True)\n",
    "\n",
    "fps_x = data['sequence'].values\n",
    "fps_y = data['label'].values\n",
    "\n",
    "# choosing one hot encoding\n",
    "encoder = DNAEncoder(fps_x)\n",
    "fps_x = encoder.one_hot_encode()\n",
    "print(fps_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using descriptors it would be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2000\n",
      "100 / 2000\n",
      "200 / 2000\n",
      "300 / 2000\n",
      "400 / 2000\n",
      "500 / 2000\n",
      "600 / 2000\n",
      "700 / 2000\n",
      "800 / 2000\n",
      "900 / 2000\n",
      "1000 / 2000\n",
      "1100 / 2000\n",
      "1200 / 2000\n",
      "1300 / 2000\n",
      "1400 / 2000\n",
      "1500 / 2000\n",
      "1600 / 2000\n",
      "1700 / 2000\n",
      "1800 / 2000\n",
      "1900 / 2000\n",
      "Done!\n",
      "(2000, 247)\n"
     ]
    }
   ],
   "source": [
    "reader = ReadDNA()\n",
    "data = reader.read_csv(filename='../datasets/primer/dataset.csv', with_labels=True)\n",
    "\n",
    "from calculate_features import calculate_and_normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "fps_x, fps_y = calculate_and_normalize(data)\n",
    "\n",
    "scaler = StandardScaler().fit(fps_x)\n",
    "fps_x = scaler.transform(fps_x)\n",
    "fps_y = fps_y.to_numpy()\n",
    "print(fps_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequences are at this point converted into numerical representations and are ready to be split into training, validation, and test sets. After that, each set needs also to be represented as the *PyTorch* object called *DataLoader*, which is a *Python* iterable over a dataset. All of this can be achieved using the function `data_splitting` from the `prepare_data.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_data import data_splitting\n",
    "batch_size = 32\n",
    "train_size = 0.6\n",
    "validation_size = 0.2\n",
    "test_size = 0.2\n",
    "\n",
    "trainloader, testloader, validloader, _ = data_splitting(fps_x, fps_y, batch_size, train_size, test_size, validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model building and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:** Before continuing, it is worth noting that all of the previous steps, from the data reading, calculation of encoder/descriptors, and even the data splitting step, were compiled into a single function called `prepare_data` that can be called from the `prepare_data.py` file. An example of how to use this function will be shown later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the data is now ready to be used by a model. The user can choose to use one of the 6 implemented *PyTorch* models. They are:\n",
    "\n",
    "| Models                | Features    |\n",
    "| --------------------- | ----------- |\n",
    "| MLP                   | Descriptors |\n",
    "| CNN                   | Encoders    |\n",
    "| LSTM / BiLSTM         | Encoders    |\n",
    "| GRU / BiGRU           | Encoders    |\n",
    "| CNN-LSTM / CNN-BiLSTM | Encoders    |\n",
    "| CNN-GRU / CNN-BiGRU   | Encoders    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some models require the use of encoders and some require descriptors. Also, some models have the bidirectional option, resulting in 2 + 4*2 = 10 different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagining the scenario that we want to use descriptors as features, we need to choose the *MLP* model. We also need to specify some parameters for the training function. To make it easier for the user, a config file was created to provide an overview of all the parameters that will be used from now on. An example of a `config.json` file is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"combination\":{\n",
    "        \"model_label\": \"mlp\",\n",
    "        \"mode\": \"descriptor\",\n",
    "        \"data_dir\": \"primer\"\n",
    "    },\n",
    "    \"do_tuning\": false,\n",
    "    \"fixed_vals\":{\n",
    "        \"epochs\": 500,\n",
    "        \"optimizer_label\": \"adam\",\n",
    "        \"loss_function\": \"cross_entropy\",\n",
    "        \"patience\": 8,\n",
    "        \"output_size\": 2,\n",
    "        \"cpus_per_trial\":1, \n",
    "        \"gpus_per_trial\":0,\n",
    "        \"num_samples\": 15,\n",
    "        \"num_layers\": 2,\n",
    "        \"kmer_one_hot\": 3\n",
    "    },\n",
    "    \"hyperparameters\": {\n",
    "        \"hidden_size\": 32,\n",
    "        \"lr\": 1e-3,\n",
    "        \"batch_size\": 32,\n",
    "        \"dropout\": 0.35\n",
    "    },\n",
    "    \"hyperparameter_search_space\": {\n",
    "        \"hidden_size\": [32, 64, 128, 256],\n",
    "        \"lr\": [1e-5, 1e-2],\n",
    "        \"batch_size\": [8, 16, 32],\n",
    "        \"dropout\": [0.3, 0.5]\n",
    "    },\n",
    "    \"train_all_combinations\": false\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the values from the configuraton file, we can use the function `read_config` from the `deep_ml.py` file. This functions also validates the configuration file and returns a dictionary with the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda:0\n",
      "combination {\n",
      "\t model_label : cnn\n",
      "\t mode : one_hot\n",
      "\t data_dir : /home/jabreu/propythia/src/propythia/DNA/datasets/primer\n",
      "}\n",
      "do_tuning : False\n",
      "fixed_vals {\n",
      "\t epochs : 500\n",
      "\t optimizer_label : adam\n",
      "\t loss_function : CrossEntropyLoss()\n",
      "\t patience : 7\n",
      "\t output_size : 2\n",
      "\t cpus_per_trial : 2\n",
      "\t gpus_per_trial : 2\n",
      "\t num_samples : 15\n",
      "\t num_layers : 2\n",
      "\t kmer_one_hot : 3\n",
      "}\n",
      "hyperparameters {\n",
      "\t hidden_size : 32\n",
      "\t lr : 0.001\n",
      "\t batch_size : 32\n",
      "\t dropout : 0.35\n",
      "}\n",
      "hyperparameter_search_space {\n",
      "\t hidden_size : <ray.tune.sample.Categorical object at 0x7f7c10558d10>\n",
      "\t lr : <ray.tune.sample.Float object at 0x7f7c10558a90>\n",
      "\t batch_size : <ray.tune.sample.Categorical object at 0x7f7c105583d0>\n",
      "\t dropout : <ray.tune.sample.Float object at 0x7f7c10558dd0>\n",
      "}\n",
      "train_all_combinations : False\n"
     ]
    }
   ],
   "source": [
    "from deep_ml import read_config\n",
    "config = read_config(filename='../config.json')\n",
    "\n",
    "for key, val in config.items():\n",
    "    if(key == \"do_tuning\" or key == 'train_all_combinations'):\n",
    "        print(key, \":\", val)\n",
    "    else:\n",
    "        print(key, \"{\")\n",
    "        for k, v in val.items():\n",
    "            print(\"\\t\", k,\":\", v)\n",
    "        print(\"}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a dict called 'hyperparameters' for the training. These values were arbitrarily chosen, which can lead to poor performance, and that's why we need hyperparameter tuning to find the best values. But so far let's keep it simple and use the default values. Hyperparameter tuning will be discussed later in the tutorial (the dict called 'hyperparameter_search_space' will be used later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to call the training function with all of these values and we will obtain a trained model. But before this, it important to specify which device we want the model to be trained on. Generally, it is a good idea to use the GPU if it is available. It is also a good practice to set a seed to ensure that the results are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "\n",
    "numpy.random.seed(2022)\n",
    "torch.manual_seed(2022)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2,3,4,5'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to call the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/500, 0/38] loss: 0.70695961\n",
      "The Current Loss: 0.6356495572970464\n",
      "trigger times: 0\n",
      "[2/500, 0/38] loss: 0.64424402\n",
      "The Current Loss: 0.49543410539627075\n",
      "trigger times: 0\n",
      "[3/500, 0/38] loss: 0.50877994\n",
      "The Current Loss: 0.42889038645304167\n",
      "trigger times: 0\n",
      "[4/500, 0/38] loss: 0.36436936\n",
      "The Current Loss: 0.3913511771422166\n",
      "trigger times: 0\n",
      "[5/500, 0/38] loss: 0.44344398\n",
      "The Current Loss: 0.3759752168105199\n",
      "trigger times: 0\n",
      "[6/500, 0/38] loss: 0.33551249\n",
      "The Current Loss: 0.37056772525493914\n",
      "trigger times: 0\n",
      "[7/500, 0/38] loss: 0.32777476\n",
      "The Current Loss: 0.36761671763200027\n",
      "trigger times: 0\n",
      "[8/500, 0/38] loss: 0.32554531\n",
      "The Current Loss: 0.3595673373112312\n",
      "trigger times: 0\n",
      "[9/500, 0/38] loss: 0.36578175\n",
      "The Current Loss: 0.35537290343871486\n",
      "trigger times: 0\n",
      "[10/500, 0/38] loss: 0.32901487\n",
      "The Current Loss: 0.3488809076639322\n",
      "trigger times: 0\n",
      "[11/500, 0/38] loss: 0.31945065\n",
      "The Current Loss: 0.3502378830542931\n",
      "trigger Times: 1\n",
      "[12/500, 0/38] loss: 0.3177934\n",
      "The Current Loss: 0.342059836937831\n",
      "trigger times: 0\n",
      "[13/500, 0/38] loss: 0.32371533\n",
      "The Current Loss: 0.3431735336780548\n",
      "trigger Times: 1\n",
      "[14/500, 0/38] loss: 0.31896546\n",
      "The Current Loss: 0.34466134355618405\n",
      "trigger Times: 2\n",
      "[15/500, 0/38] loss: 0.31500083\n",
      "The Current Loss: 0.33908220437856823\n",
      "trigger times: 0\n",
      "[16/500, 0/38] loss: 0.34192631\n",
      "The Current Loss: 0.3376885996415065\n",
      "trigger times: 0\n",
      "[17/500, 0/38] loss: 0.31796718\n",
      "The Current Loss: 0.3385013937950134\n",
      "trigger Times: 1\n",
      "[18/500, 0/38] loss: 0.31551638\n",
      "The Current Loss: 0.33797308802604675\n",
      "trigger times: 0\n",
      "[19/500, 0/38] loss: 0.31429073\n",
      "The Current Loss: 0.3362450141173143\n",
      "trigger times: 0\n",
      "[20/500, 0/38] loss: 0.31527719\n",
      "The Current Loss: 0.3348177786056812\n",
      "trigger times: 0\n",
      "[21/500, 0/38] loss: 0.31469947\n",
      "The Current Loss: 0.3390410634187552\n",
      "trigger Times: 1\n",
      "[22/500, 0/38] loss: 0.31564972\n",
      "The Current Loss: 0.3388374952169565\n",
      "trigger times: 0\n",
      "[23/500, 0/38] loss: 0.31563392\n",
      "The Current Loss: 0.3346803761445559\n",
      "trigger times: 0\n",
      "[24/500, 0/38] loss: 0.31435257\n",
      "The Current Loss: 0.3342469518001263\n",
      "trigger times: 0\n",
      "[25/500, 0/38] loss: 0.31409562\n",
      "The Current Loss: 0.3374206836407001\n",
      "trigger Times: 1\n",
      "[26/500, 0/38] loss: 0.31405213\n",
      "The Current Loss: 0.3349521847871634\n",
      "trigger times: 0\n",
      "[27/500, 0/38] loss: 0.31414026\n",
      "The Current Loss: 0.3334119709638449\n",
      "trigger times: 0\n",
      "[28/500, 0/38] loss: 0.31364042\n",
      "The Current Loss: 0.33603978615540725\n",
      "trigger Times: 1\n",
      "[29/500, 0/38] loss: 0.31380904\n",
      "The Current Loss: 0.3353504492686345\n",
      "trigger times: 0\n",
      "[30/500, 0/38] loss: 0.31409103\n",
      "The Current Loss: 0.3333322314115671\n",
      "trigger times: 0\n",
      "[31/500, 0/38] loss: 0.31382421\n",
      "The Current Loss: 0.3325759447537936\n",
      "trigger times: 0\n",
      "[32/500, 0/38] loss: 0.31356463\n",
      "The Current Loss: 0.33268067928460926\n",
      "trigger Times: 1\n",
      "[33/500, 0/38] loss: 0.31377432\n",
      "The Current Loss: 0.3323714228776785\n",
      "trigger times: 0\n",
      "[34/500, 0/38] loss: 0.31406724\n",
      "The Current Loss: 0.33292080347354597\n",
      "trigger Times: 1\n",
      "[35/500, 0/38] loss: 0.31367534\n",
      "The Current Loss: 0.3336834655358241\n",
      "trigger Times: 2\n",
      "[36/500, 0/38] loss: 0.31353033\n",
      "The Current Loss: 0.3339348297852736\n",
      "trigger Times: 3\n",
      "[37/500, 0/38] loss: 0.31348953\n",
      "The Current Loss: 0.3324765058664175\n",
      "trigger times: 0\n",
      "[38/500, 0/38] loss: 0.3137677\n",
      "The Current Loss: 0.33189022770294774\n",
      "trigger times: 0\n",
      "[39/500, 0/38] loss: 0.3133997\n",
      "The Current Loss: 0.3338412092282222\n",
      "trigger Times: 1\n",
      "[40/500, 0/38] loss: 0.31371829\n",
      "The Current Loss: 0.33217631165797895\n",
      "trigger times: 0\n",
      "[41/500, 0/38] loss: 0.31346869\n",
      "The Current Loss: 0.3327196125800793\n",
      "trigger Times: 1\n",
      "[42/500, 0/38] loss: 0.31361112\n",
      "The Current Loss: 0.3319312655008756\n",
      "trigger times: 0\n",
      "[43/500, 0/38] loss: 0.31336373\n",
      "The Current Loss: 0.33177637366148144\n",
      "trigger times: 0\n",
      "[44/500, 0/38] loss: 0.31341678\n",
      "The Current Loss: 0.33522831247403073\n",
      "trigger Times: 1\n",
      "[45/500, 0/38] loss: 0.31340209\n",
      "The Current Loss: 0.3321813413730034\n",
      "trigger times: 0\n",
      "[46/500, 0/38] loss: 0.31340483\n",
      "The Current Loss: 0.3350568092786349\n",
      "trigger Times: 1\n",
      "[47/500, 0/38] loss: 0.31336692\n",
      "The Current Loss: 0.33212945552972645\n",
      "trigger times: 0\n",
      "[48/500, 0/38] loss: 0.31331846\n",
      "The Current Loss: 0.3332089208639585\n",
      "trigger Times: 1\n",
      "[49/500, 0/38] loss: 0.31335628\n",
      "The Current Loss: 0.3335557052722344\n",
      "trigger Times: 2\n",
      "[50/500, 0/38] loss: 0.31332123\n",
      "The Current Loss: 0.3320192809288318\n",
      "trigger times: 0\n",
      "[51/500, 0/38] loss: 0.31329992\n",
      "The Current Loss: 0.3316896626582512\n",
      "trigger times: 0\n",
      "[52/500, 0/38] loss: 0.31329581\n",
      "The Current Loss: 0.33164436312822193\n",
      "trigger times: 0\n",
      "[53/500, 0/38] loss: 0.3133302\n",
      "The Current Loss: 0.3338074340270116\n",
      "trigger Times: 1\n",
      "[54/500, 0/38] loss: 0.31333911\n",
      "The Current Loss: 0.33210166371785677\n",
      "trigger times: 0\n",
      "[55/500, 0/38] loss: 0.31331253\n",
      "The Current Loss: 0.3319276594198667\n",
      "trigger times: 0\n",
      "[56/500, 0/38] loss: 0.31331038\n",
      "The Current Loss: 0.3322177529335022\n",
      "trigger Times: 1\n",
      "[57/500, 0/38] loss: 0.31329879\n",
      "The Current Loss: 0.3319431864298307\n",
      "trigger times: 0\n",
      "[58/500, 0/38] loss: 0.31328976\n",
      "The Current Loss: 0.3341810451104091\n",
      "trigger Times: 1\n",
      "[59/500, 0/38] loss: 0.31332207\n",
      "The Current Loss: 0.3318466544151306\n",
      "trigger times: 0\n",
      "[60/500, 0/38] loss: 0.31327102\n",
      "The Current Loss: 0.33229721738741946\n",
      "trigger Times: 1\n",
      "[61/500, 0/38] loss: 0.31327847\n",
      "The Current Loss: 0.332081329364043\n",
      "trigger times: 0\n",
      "[62/500, 0/38] loss: 0.31330189\n",
      "The Current Loss: 0.3318099838036757\n",
      "trigger times: 0\n",
      "[63/500, 0/38] loss: 0.31328678\n",
      "The Current Loss: 0.33488412545277524\n",
      "trigger Times: 1\n",
      "[64/500, 0/38] loss: 0.31331736\n",
      "The Current Loss: 0.3323269532277034\n",
      "trigger times: 0\n",
      "[65/500, 0/38] loss: 0.31328696\n",
      "The Current Loss: 0.3321110010147095\n",
      "trigger times: 0\n",
      "[66/500, 0/38] loss: 0.3133032\n",
      "The Current Loss: 0.33251670461434585\n",
      "trigger Times: 1\n",
      "[67/500, 0/38] loss: 0.31328124\n",
      "The Current Loss: 0.3343178629875183\n",
      "trigger Times: 2\n",
      "[68/500, 0/38] loss: 0.31326586\n",
      "The Current Loss: 0.3343017811958606\n",
      "trigger times: 0\n",
      "[69/500, 0/38] loss: 0.31327543\n",
      "The Current Loss: 0.33205594237034136\n",
      "trigger times: 0\n",
      "[70/500, 0/38] loss: 0.31332093\n",
      "The Current Loss: 0.3324971061486464\n",
      "trigger Times: 1\n",
      "[71/500, 0/38] loss: 0.31327659\n",
      "The Current Loss: 0.33210762647482067\n",
      "trigger times: 0\n",
      "[72/500, 0/38] loss: 0.31326991\n",
      "The Current Loss: 0.33262359408231884\n",
      "trigger Times: 1\n",
      "[73/500, 0/38] loss: 0.31328139\n",
      "The Current Loss: 0.3320640508945172\n",
      "trigger times: 0\n",
      "[74/500, 0/38] loss: 0.31327879\n",
      "The Current Loss: 0.3344904321890611\n",
      "trigger Times: 1\n",
      "[75/500, 0/38] loss: 0.31328756\n",
      "The Current Loss: 0.3342970128242786\n",
      "trigger times: 0\n",
      "[76/500, 0/38] loss: 0.31329632\n",
      "The Current Loss: 0.3334831091073843\n",
      "trigger times: 0\n",
      "[77/500, 0/38] loss: 0.31327999\n",
      "The Current Loss: 0.3325768548708696\n",
      "trigger times: 0\n",
      "[78/500, 0/38] loss: 0.31328946\n",
      "The Current Loss: 0.3320799355323498\n",
      "trigger times: 0\n",
      "[79/500, 0/38] loss: 0.31329805\n",
      "The Current Loss: 0.3328295900271489\n",
      "trigger Times: 1\n",
      "[80/500, 0/38] loss: 0.31327525\n",
      "The Current Loss: 0.3343419638963846\n",
      "trigger Times: 2\n",
      "[81/500, 0/38] loss: 0.31329086\n",
      "The Current Loss: 0.3349299362072578\n",
      "trigger Times: 3\n",
      "[82/500, 0/38] loss: 0.31329671\n",
      "The Current Loss: 0.33216070899596584\n",
      "trigger times: 0\n",
      "[83/500, 0/38] loss: 0.31327114\n",
      "The Current Loss: 0.3320835530757904\n",
      "trigger times: 0\n",
      "[84/500, 0/38] loss: 0.31327981\n",
      "The Current Loss: 0.3346842917112204\n",
      "trigger Times: 1\n",
      "[85/500, 0/38] loss: 0.31327587\n",
      "The Current Loss: 0.3320966064929962\n",
      "trigger times: 0\n",
      "[86/500, 0/38] loss: 0.31331539\n",
      "The Current Loss: 0.33249825697678786\n",
      "trigger Times: 1\n",
      "[87/500, 0/38] loss: 0.31327447\n",
      "The Current Loss: 0.3322327435016632\n",
      "trigger times: 0\n",
      "[88/500, 0/38] loss: 0.31328958\n",
      "The Current Loss: 0.3326404576118176\n",
      "trigger Times: 1\n",
      "[89/500, 0/38] loss: 0.31328699\n",
      "The Current Loss: 0.3344948131304521\n",
      "trigger Times: 2\n",
      "[90/500, 0/38] loss: 0.31326783\n",
      "The Current Loss: 0.33434570064911473\n",
      "trigger times: 0\n",
      "[91/500, 0/38] loss: 0.31328884\n",
      "The Current Loss: 0.3332656209285443\n",
      "trigger times: 0\n",
      "[92/500, 0/38] loss: 0.31327617\n",
      "The Current Loss: 0.33209900443370527\n",
      "trigger times: 0\n",
      "[93/500, 0/38] loss: 0.31326956\n",
      "The Current Loss: 0.3328542892749493\n",
      "trigger Times: 1\n",
      "[94/500, 0/38] loss: 0.31329218\n",
      "The Current Loss: 0.3343385343368237\n",
      "trigger Times: 2\n",
      "[95/500, 0/38] loss: 0.31327963\n",
      "The Current Loss: 0.3344809069083287\n",
      "trigger Times: 3\n",
      "[96/500, 0/38] loss: 0.3132779\n",
      "The Current Loss: 0.33427763214478123\n",
      "trigger times: 0\n",
      "[97/500, 0/38] loss: 0.31328189\n",
      "The Current Loss: 0.3343068521756392\n",
      "trigger Times: 1\n",
      "[98/500, 0/38] loss: 0.31327161\n",
      "The Current Loss: 0.3320807952147264\n",
      "trigger times: 0\n",
      "[99/500, 0/38] loss: 0.31329539\n",
      "The Current Loss: 0.33427932399969834\n",
      "trigger Times: 1\n",
      "[100/500, 0/38] loss: 0.31327978\n",
      "The Current Loss: 0.3320989448290605\n",
      "trigger times: 0\n",
      "[101/500, 0/38] loss: 0.31329414\n",
      "The Current Loss: 0.3342809562499707\n",
      "trigger Times: 1\n",
      "[102/500, 0/38] loss: 0.31329885\n",
      "The Current Loss: 0.332550422503398\n",
      "trigger times: 0\n",
      "[103/500, 0/38] loss: 0.31328699\n",
      "The Current Loss: 0.33210156284845793\n",
      "trigger times: 0\n",
      "[104/500, 0/38] loss: 0.31329125\n",
      "The Current Loss: 0.3325106203556061\n",
      "trigger Times: 1\n",
      "[105/500, 0/38] loss: 0.3133224\n",
      "The Current Loss: 0.3320875076147226\n",
      "trigger times: 0\n",
      "[106/500, 0/38] loss: 0.31329563\n",
      "The Current Loss: 0.33285805812248814\n",
      "trigger Times: 1\n",
      "[107/500, 0/38] loss: 0.31328279\n",
      "The Current Loss: 0.3321165763414823\n",
      "trigger times: 0\n",
      "[108/500, 0/38] loss: 0.31326774\n",
      "The Current Loss: 0.33215247897001415\n",
      "trigger Times: 1\n",
      "[109/500, 0/38] loss: 0.31327736\n",
      "The Current Loss: 0.33209710396253145\n",
      "trigger times: 0\n",
      "[110/500, 0/38] loss: 0.31327593\n",
      "The Current Loss: 0.33208059347592866\n",
      "trigger times: 0\n",
      "[111/500, 0/38] loss: 0.31328115\n",
      "The Current Loss: 0.3328210986577548\n",
      "trigger Times: 1\n",
      "[112/500, 0/38] loss: 0.31328404\n",
      "The Current Loss: 0.33581556723668027\n",
      "trigger Times: 2\n",
      "[113/500, 0/38] loss: 0.31328386\n",
      "The Current Loss: 0.33436374939405\n",
      "trigger times: 0\n",
      "[114/500, 0/38] loss: 0.31328163\n",
      "The Current Loss: 0.33208714998685396\n",
      "trigger times: 0\n",
      "[115/500, 0/38] loss: 0.31328669\n",
      "The Current Loss: 0.3320883879294762\n",
      "trigger Times: 1\n",
      "[116/500, 0/38] loss: 0.31329906\n",
      "The Current Loss: 0.3343860117288736\n",
      "trigger Times: 2\n",
      "[117/500, 0/38] loss: 0.31330904\n",
      "The Current Loss: 0.33214738735785854\n",
      "trigger times: 0\n",
      "[118/500, 0/38] loss: 0.31328216\n",
      "The Current Loss: 0.3320804719741528\n",
      "trigger times: 0\n",
      "[119/500, 0/38] loss: 0.31327444\n",
      "The Current Loss: 0.33208428208644575\n",
      "trigger Times: 1\n",
      "[120/500, 0/38] loss: 0.31328756\n",
      "The Current Loss: 0.3320831541831677\n",
      "trigger times: 0\n",
      "[121/500, 0/38] loss: 0.31328321\n",
      "The Current Loss: 0.3342731434565324\n",
      "trigger Times: 1\n",
      "[122/500, 0/38] loss: 0.31328246\n",
      "The Current Loss: 0.3345170823427347\n",
      "trigger Times: 2\n",
      "[123/500, 0/38] loss: 0.3132838\n",
      "The Current Loss: 0.3320809304714203\n",
      "trigger times: 0\n",
      "[124/500, 0/38] loss: 0.31327024\n",
      "The Current Loss: 0.3320814050160922\n",
      "trigger Times: 1\n",
      "[125/500, 0/38] loss: 0.31329435\n",
      "The Current Loss: 0.33217339561535764\n",
      "trigger Times: 2\n",
      "[126/500, 0/38] loss: 0.31327268\n",
      "The Current Loss: 0.33726779314187855\n",
      "trigger Times: 3\n",
      "[127/500, 0/38] loss: 0.31331453\n",
      "The Current Loss: 0.332499412389902\n",
      "trigger times: 0\n",
      "[128/500, 0/38] loss: 0.31326628\n",
      "The Current Loss: 0.33249975397036624\n",
      "trigger Times: 1\n",
      "[129/500, 0/38] loss: 0.31330267\n",
      "The Current Loss: 0.3325649912540729\n",
      "trigger Times: 2\n",
      "[130/500, 0/38] loss: 0.31330085\n",
      "The Current Loss: 0.3321834963101607\n",
      "trigger times: 0\n",
      "[131/500, 0/38] loss: 0.31326917\n",
      "The Current Loss: 0.3321109459950374\n",
      "trigger times: 0\n",
      "[132/500, 0/38] loss: 0.31327403\n",
      "The Current Loss: 0.33435596181796146\n",
      "trigger Times: 1\n",
      "[133/500, 0/38] loss: 0.31327897\n",
      "The Current Loss: 0.33208705140994144\n",
      "trigger times: 0\n",
      "[134/500, 0/38] loss: 0.31331435\n",
      "The Current Loss: 0.33211212433301485\n",
      "trigger Times: 1\n",
      "[135/500, 0/38] loss: 0.31329137\n",
      "The Current Loss: 0.3320867419242859\n",
      "trigger times: 0\n",
      "[136/500, 0/38] loss: 0.31328094\n",
      "The Current Loss: 0.3346398908358354\n",
      "trigger Times: 1\n",
      "[137/500, 0/38] loss: 0.31330168\n",
      "The Current Loss: 0.33550121234013486\n",
      "trigger Times: 2\n",
      "[138/500, 0/38] loss: 0.31327775\n",
      "The Current Loss: 0.3342825770378113\n",
      "trigger times: 0\n",
      "[139/500, 0/38] loss: 0.31330445\n",
      "The Current Loss: 0.3320819139480591\n",
      "trigger times: 0\n",
      "[140/500, 0/38] loss: 0.3132866\n",
      "The Current Loss: 0.33209198025556713\n",
      "trigger Times: 1\n",
      "[141/500, 0/38] loss: 0.31328785\n",
      "The Current Loss: 0.33438223600387573\n",
      "trigger Times: 2\n",
      "[142/500, 0/38] loss: 0.31327921\n",
      "The Current Loss: 0.3345325061908135\n",
      "trigger Times: 3\n",
      "[143/500, 0/38] loss: 0.31329483\n",
      "The Current Loss: 0.33216391389186567\n",
      "trigger times: 0\n",
      "[144/500, 0/38] loss: 0.3132759\n",
      "The Current Loss: 0.332499419267361\n",
      "trigger Times: 1\n",
      "[145/500, 0/38] loss: 0.31329593\n",
      "The Current Loss: 0.3337028462153215\n",
      "trigger Times: 2\n",
      "[146/500, 0/38] loss: 0.31329775\n",
      "The Current Loss: 0.33435033376400286\n",
      "trigger Times: 3\n",
      "[147/500, 0/38] loss: 0.31330845\n",
      "The Current Loss: 0.33283586456225467\n",
      "trigger times: 0\n",
      "[148/500, 0/38] loss: 0.31330112\n",
      "The Current Loss: 0.3320921567770151\n",
      "trigger times: 0\n",
      "[149/500, 0/38] loss: 0.313308\n",
      "The Current Loss: 0.33210182648438674\n",
      "trigger Times: 1\n",
      "[150/500, 0/38] loss: 0.3132672\n",
      "The Current Loss: 0.33419514619387114\n",
      "trigger Times: 2\n",
      "[151/500, 0/38] loss: 0.31329206\n",
      "The Current Loss: 0.33208713164696324\n",
      "trigger times: 0\n",
      "[152/500, 0/38] loss: 0.31329417\n",
      "The Current Loss: 0.33270991994784427\n",
      "trigger Times: 1\n",
      "[153/500, 0/38] loss: 0.31330204\n",
      "The Current Loss: 0.33210274347892177\n",
      "trigger times: 0\n",
      "[154/500, 0/38] loss: 0.31327897\n",
      "The Current Loss: 0.33431833523970383\n",
      "trigger Times: 1\n",
      "[155/500, 0/38] loss: 0.31334129\n",
      "The Current Loss: 0.33208762682401216\n",
      "trigger times: 0\n",
      "[156/500, 0/38] loss: 0.31330493\n",
      "The Current Loss: 0.33208491710516125\n",
      "trigger times: 0\n",
      "[157/500, 0/38] loss: 0.31327847\n",
      "The Current Loss: 0.3320896533819345\n",
      "trigger Times: 1\n",
      "[158/500, 0/38] loss: 0.31326783\n",
      "The Current Loss: 0.33211687436470616\n",
      "trigger Times: 2\n",
      "[159/500, 0/38] loss: 0.31327373\n",
      "The Current Loss: 0.33213600057822007\n",
      "trigger Times: 3\n",
      "[160/500, 0/38] loss: 0.31329566\n",
      "The Current Loss: 0.332100489964852\n",
      "trigger times: 0\n",
      "[161/500, 0/38] loss: 0.31329203\n",
      "The Current Loss: 0.3320884704589844\n",
      "trigger times: 0\n",
      "[162/500, 0/38] loss: 0.31326964\n",
      "The Current Loss: 0.33208203544983494\n",
      "trigger times: 0\n",
      "[163/500, 0/38] loss: 0.31328446\n",
      "The Current Loss: 0.3328355413216811\n",
      "trigger Times: 1\n",
      "[164/500, 0/38] loss: 0.31328982\n",
      "The Current Loss: 0.3328213393688202\n",
      "trigger times: 0\n",
      "[165/500, 0/38] loss: 0.31328046\n",
      "The Current Loss: 0.33208133853398836\n",
      "trigger times: 0\n",
      "[166/500, 0/38] loss: 0.31327745\n",
      "The Current Loss: 0.33478997074640715\n",
      "trigger Times: 1\n",
      "[167/500, 0/38] loss: 0.31332746\n",
      "The Current Loss: 0.33311742773422826\n",
      "trigger times: 0\n",
      "[168/500, 0/38] loss: 0.31329611\n",
      "The Current Loss: 0.3321591799075787\n",
      "trigger times: 0\n",
      "[169/500, 0/38] loss: 0.31326714\n",
      "The Current Loss: 0.3321161063817831\n",
      "trigger times: 0\n",
      "[170/500, 0/38] loss: 0.31328437\n",
      "The Current Loss: 0.33450332283973694\n",
      "trigger Times: 1\n",
      "[171/500, 0/38] loss: 0.31328809\n",
      "The Current Loss: 0.33431269572331357\n",
      "trigger times: 0\n",
      "[172/500, 0/38] loss: 0.31328723\n",
      "The Current Loss: 0.3336617969549619\n",
      "trigger times: 0\n",
      "[173/500, 0/38] loss: 0.31327596\n",
      "The Current Loss: 0.3321142059106093\n",
      "trigger times: 0\n",
      "[174/500, 0/38] loss: 0.31327629\n",
      "The Current Loss: 0.3343534790552579\n",
      "trigger Times: 1\n",
      "[175/500, 0/38] loss: 0.3132849\n",
      "The Current Loss: 0.3353465314094837\n",
      "trigger Times: 2\n",
      "[176/500, 0/38] loss: 0.31326741\n",
      "The Current Loss: 0.33213526698259205\n",
      "trigger times: 0\n",
      "[177/500, 0/38] loss: 0.31327841\n",
      "The Current Loss: 0.3321560002290286\n",
      "trigger Times: 1\n",
      "[178/500, 0/38] loss: 0.31329438\n",
      "The Current Loss: 0.33219422514622027\n",
      "trigger Times: 2\n",
      "[179/500, 0/38] loss: 0.31330326\n",
      "The Current Loss: 0.3364259898662567\n",
      "trigger Times: 3\n",
      "[180/500, 0/38] loss: 0.3132737\n",
      "The Current Loss: 0.33260980248451233\n",
      "trigger times: 0\n",
      "[181/500, 0/38] loss: 0.31327772\n",
      "The Current Loss: 0.334350769336407\n",
      "trigger Times: 1\n",
      "[182/500, 0/38] loss: 0.31327751\n",
      "The Current Loss: 0.3329101617519672\n",
      "trigger times: 0\n",
      "[183/500, 0/38] loss: 0.31328699\n",
      "The Current Loss: 0.33312673752124494\n",
      "trigger Times: 1\n",
      "[184/500, 0/38] loss: 0.31329203\n",
      "The Current Loss: 0.33208826872018665\n",
      "trigger times: 0\n",
      "[185/500, 0/38] loss: 0.31328782\n",
      "The Current Loss: 0.33208095798125636\n",
      "trigger times: 0\n",
      "[186/500, 0/38] loss: 0.31328648\n",
      "The Current Loss: 0.33219724205824047\n",
      "trigger Times: 1\n",
      "[187/500, 0/38] loss: 0.31330112\n",
      "The Current Loss: 0.3325744179578928\n",
      "trigger Times: 2\n",
      "[188/500, 0/38] loss: 0.31331876\n",
      "The Current Loss: 0.33211289231593794\n",
      "trigger times: 0\n",
      "[189/500, 0/38] loss: 0.31327319\n",
      "The Current Loss: 0.33413291435975295\n",
      "trigger Times: 1\n",
      "[190/500, 0/38] loss: 0.31328893\n",
      "The Current Loss: 0.334275660606531\n",
      "trigger Times: 2\n",
      "[191/500, 0/38] loss: 0.31329495\n",
      "The Current Loss: 0.33209147590857285\n",
      "trigger times: 0\n",
      "[192/500, 0/38] loss: 0.31328881\n",
      "The Current Loss: 0.33208772310843837\n",
      "trigger times: 0\n",
      "[193/500, 0/38] loss: 0.31329799\n",
      "The Current Loss: 0.3321128258338341\n",
      "trigger Times: 1\n",
      "[194/500, 0/38] loss: 0.31328592\n",
      "The Current Loss: 0.33209338784217834\n",
      "trigger times: 0\n",
      "[195/500, 0/38] loss: 0.31327742\n",
      "The Current Loss: 0.3344974540747129\n",
      "trigger Times: 1\n",
      "[196/500, 0/38] loss: 0.31328681\n",
      "The Current Loss: 0.3334937072717227\n",
      "trigger times: 0\n",
      "[197/500, 0/38] loss: 0.31329143\n",
      "The Current Loss: 0.3320810611431415\n",
      "trigger times: 0\n",
      "[198/500, 0/38] loss: 0.31326759\n",
      "The Current Loss: 0.3320901164641747\n",
      "trigger Times: 1\n",
      "[199/500, 0/38] loss: 0.31328407\n",
      "The Current Loss: 0.3342716716803037\n",
      "trigger Times: 2\n",
      "[200/500, 0/38] loss: 0.31327602\n",
      "The Current Loss: 0.3326299740717961\n",
      "trigger times: 0\n",
      "[201/500, 0/38] loss: 0.3132911\n",
      "The Current Loss: 0.33431313588069034\n",
      "trigger Times: 1\n",
      "[202/500, 0/38] loss: 0.3133029\n",
      "The Current Loss: 0.33208073331759524\n",
      "trigger times: 0\n",
      "[203/500, 0/38] loss: 0.31329522\n",
      "The Current Loss: 0.332080419246967\n",
      "trigger times: 0\n",
      "[204/500, 0/38] loss: 0.31329384\n",
      "The Current Loss: 0.33419488026545596\n",
      "trigger Times: 1\n",
      "[205/500, 0/38] loss: 0.3132863\n",
      "The Current Loss: 0.3320812009848081\n",
      "trigger times: 0\n",
      "[206/500, 0/38] loss: 0.31329423\n",
      "The Current Loss: 0.3321061203112969\n",
      "trigger Times: 1\n",
      "[207/500, 0/38] loss: 0.31329393\n",
      "The Current Loss: 0.33209184958384586\n",
      "trigger times: 0\n",
      "[208/500, 0/38] loss: 0.31328109\n",
      "The Current Loss: 0.33208168011445266\n",
      "trigger times: 0\n",
      "[209/500, 0/38] loss: 0.31327161\n",
      "The Current Loss: 0.3320845411374019\n",
      "trigger Times: 1\n",
      "[210/500, 0/38] loss: 0.3132748\n",
      "The Current Loss: 0.3342572611111861\n",
      "trigger Times: 2\n",
      "[211/500, 0/38] loss: 0.31328657\n",
      "The Current Loss: 0.33209723692673904\n",
      "trigger times: 0\n",
      "[212/500, 0/38] loss: 0.31329906\n",
      "The Current Loss: 0.3320818474659553\n",
      "trigger times: 0\n",
      "[213/500, 0/38] loss: 0.31327868\n",
      "The Current Loss: 0.33372750649085414\n",
      "trigger Times: 1\n",
      "[214/500, 0/38] loss: 0.313288\n",
      "The Current Loss: 0.3320826177413647\n",
      "trigger times: 0\n",
      "[215/500, 0/38] loss: 0.3133038\n",
      "The Current Loss: 0.33252667692991406\n",
      "trigger Times: 1\n",
      "[216/500, 0/38] loss: 0.31328905\n",
      "The Current Loss: 0.3321318213756268\n",
      "trigger times: 0\n",
      "[217/500, 0/38] loss: 0.31327853\n",
      "The Current Loss: 0.3321065604686737\n",
      "trigger times: 0\n",
      "[218/500, 0/38] loss: 0.31329873\n",
      "The Current Loss: 0.3320879867443672\n",
      "trigger times: 0\n",
      "[219/500, 0/38] loss: 0.31327778\n",
      "The Current Loss: 0.33447689505723804\n",
      "trigger Times: 1\n",
      "[220/500, 0/38] loss: 0.31326655\n",
      "The Current Loss: 0.3321789365548354\n",
      "trigger times: 0\n",
      "[221/500, 0/38] loss: 0.31328231\n",
      "The Current Loss: 0.33209360104340774\n",
      "trigger times: 0\n",
      "[222/500, 0/38] loss: 0.31328079\n",
      "The Current Loss: 0.3320823678603539\n",
      "trigger times: 0\n",
      "[223/500, 0/38] loss: 0.31327844\n",
      "The Current Loss: 0.3320857286453247\n",
      "trigger Times: 1\n",
      "[224/500, 0/38] loss: 0.31329501\n",
      "The Current Loss: 0.33210959572058457\n",
      "trigger Times: 2\n",
      "[225/500, 0/38] loss: 0.31328782\n",
      "The Current Loss: 0.33209216136198777\n",
      "trigger times: 0\n",
      "[226/500, 0/38] loss: 0.31327462\n",
      "The Current Loss: 0.3337042194146376\n",
      "trigger Times: 1\n",
      "[227/500, 0/38] loss: 0.31328136\n",
      "The Current Loss: 0.3320854718868549\n",
      "trigger times: 0\n",
      "[228/500, 0/38] loss: 0.31327704\n",
      "The Current Loss: 0.3343578760440533\n",
      "trigger Times: 1\n",
      "[229/500, 0/38] loss: 0.31328428\n",
      "The Current Loss: 0.3337380656829247\n",
      "trigger times: 0\n",
      "[230/500, 0/38] loss: 0.31328797\n",
      "The Current Loss: 0.3328673289372371\n",
      "trigger times: 0\n",
      "[231/500, 0/38] loss: 0.31328884\n",
      "The Current Loss: 0.3321151389525487\n",
      "trigger times: 0\n",
      "[232/500, 0/38] loss: 0.31330052\n",
      "The Current Loss: 0.3321506908306709\n",
      "trigger Times: 1\n",
      "[233/500, 0/38] loss: 0.31328002\n",
      "The Current Loss: 0.3357235399576334\n",
      "trigger Times: 2\n",
      "[234/500, 0/38] loss: 0.31327382\n",
      "The Current Loss: 0.3331192754782163\n",
      "trigger times: 0\n",
      "[235/500, 0/38] loss: 0.31327319\n",
      "The Current Loss: 0.33211249113082886\n",
      "trigger times: 0\n",
      "[236/500, 0/38] loss: 0.31327179\n",
      "The Current Loss: 0.33349753801639265\n",
      "trigger Times: 1\n",
      "[237/500, 0/38] loss: 0.31327322\n",
      "The Current Loss: 0.33210639311717105\n",
      "trigger times: 0\n",
      "[238/500, 0/38] loss: 0.31326661\n",
      "The Current Loss: 0.3320896533819345\n",
      "trigger times: 0\n",
      "[239/500, 0/38] loss: 0.3132759\n",
      "The Current Loss: 0.3361219328183394\n",
      "trigger Times: 1\n",
      "[240/500, 0/38] loss: 0.3132911\n",
      "The Current Loss: 0.3323075083585886\n",
      "trigger times: 0\n",
      "[241/500, 0/38] loss: 0.31327724\n",
      "The Current Loss: 0.3321133187183967\n",
      "trigger times: 0\n",
      "[242/500, 0/38] loss: 0.3132692\n",
      "The Current Loss: 0.33208272090324986\n",
      "trigger times: 0\n",
      "[243/500, 0/38] loss: 0.31327492\n",
      "The Current Loss: 0.33419408477269685\n",
      "trigger Times: 1\n",
      "[244/500, 0/38] loss: 0.31328556\n",
      "The Current Loss: 0.3331363361615401\n",
      "trigger times: 0\n",
      "[245/500, 0/38] loss: 0.31327763\n",
      "The Current Loss: 0.33505606880554784\n",
      "trigger Times: 1\n",
      "[246/500, 0/38] loss: 0.31329489\n",
      "The Current Loss: 0.3321066269507775\n",
      "trigger times: 0\n",
      "[247/500, 0/38] loss: 0.31327206\n",
      "The Current Loss: 0.33352190026870143\n",
      "trigger Times: 1\n",
      "[248/500, 0/38] loss: 0.31326917\n",
      "The Current Loss: 0.33209758079968965\n",
      "trigger times: 0\n",
      "[249/500, 0/38] loss: 0.31327718\n",
      "The Current Loss: 0.3321039332793309\n",
      "trigger Times: 1\n",
      "[250/500, 0/38] loss: 0.31327382\n",
      "The Current Loss: 0.33320162617243254\n",
      "trigger Times: 2\n",
      "[251/500, 0/38] loss: 0.31327263\n",
      "The Current Loss: 0.3335534013234652\n",
      "trigger Times: 3\n",
      "[252/500, 0/38] loss: 0.31326732\n",
      "The Current Loss: 0.33208518761854905\n",
      "trigger times: 0\n",
      "[253/500, 0/38] loss: 0.31331542\n",
      "The Current Loss: 0.3320941627025604\n",
      "trigger Times: 1\n",
      "[254/500, 0/38] loss: 0.31328902\n",
      "The Current Loss: 0.3321815545742328\n",
      "trigger Times: 2\n",
      "[255/500, 0/38] loss: 0.31328416\n",
      "The Current Loss: 0.33431867452768177\n",
      "trigger Times: 3\n",
      "[256/500, 0/38] loss: 0.31329012\n",
      "The Current Loss: 0.3321145658309643\n",
      "trigger times: 0\n",
      "[257/500, 0/38] loss: 0.31329045\n",
      "The Current Loss: 0.3326410765831287\n",
      "trigger Times: 1\n",
      "[258/500, 0/38] loss: 0.3133004\n",
      "The Current Loss: 0.3343524864086738\n",
      "trigger Times: 2\n",
      "[259/500, 0/38] loss: 0.313292\n",
      "The Current Loss: 0.33251991409521836\n",
      "trigger times: 0\n",
      "[260/500, 0/38] loss: 0.31327757\n",
      "The Current Loss: 0.33214736443299514\n",
      "trigger times: 0\n",
      "[261/500, 0/38] loss: 0.3132765\n",
      "The Current Loss: 0.3321078098737277\n",
      "trigger times: 0\n",
      "[262/500, 0/38] loss: 0.31326592\n",
      "The Current Loss: 0.33435423099077666\n",
      "trigger Times: 1\n",
      "[263/500, 0/38] loss: 0.31327489\n",
      "The Current Loss: 0.3320958935297452\n",
      "trigger times: 0\n",
      "[264/500, 0/38] loss: 0.31329566\n",
      "The Current Loss: 0.3320886194705963\n",
      "trigger times: 0\n",
      "[265/500, 0/38] loss: 0.31327724\n",
      "The Current Loss: 0.33447885513305664\n",
      "trigger Times: 1\n",
      "[266/500, 0/38] loss: 0.31326857\n",
      "The Current Loss: 0.33209440341362584\n",
      "trigger times: 0\n",
      "[267/500, 0/38] loss: 0.31330791\n",
      "The Current Loss: 0.33658732588474566\n",
      "trigger Times: 1\n",
      "[268/500, 0/38] loss: 0.3132771\n",
      "The Current Loss: 0.33455286346949065\n",
      "trigger times: 0\n",
      "[269/500, 0/38] loss: 0.3132709\n",
      "The Current Loss: 0.33208152651786804\n",
      "trigger times: 0\n",
      "[270/500, 0/38] loss: 0.31328574\n",
      "The Current Loss: 0.3320971131324768\n",
      "trigger Times: 1\n",
      "[271/500, 0/38] loss: 0.31329337\n",
      "The Current Loss: 0.332098500086711\n",
      "trigger Times: 2\n",
      "[272/500, 0/38] loss: 0.3132799\n",
      "The Current Loss: 0.3332439340077914\n",
      "trigger Times: 3\n",
      "[273/500, 0/38] loss: 0.31328934\n",
      "The Current Loss: 0.33208606564081633\n",
      "trigger times: 0\n",
      "[274/500, 0/38] loss: 0.31329274\n",
      "The Current Loss: 0.3320834774237413\n",
      "trigger times: 0\n",
      "[275/500, 0/38] loss: 0.3132866\n",
      "The Current Loss: 0.3321199921461252\n",
      "trigger Times: 1\n",
      "[276/500, 0/38] loss: 0.31327799\n",
      "The Current Loss: 0.33212587466606724\n",
      "trigger Times: 2\n",
      "[277/500, 0/38] loss: 0.31327102\n",
      "The Current Loss: 0.332085357262538\n",
      "trigger times: 0\n",
      "[278/500, 0/38] loss: 0.31326929\n",
      "The Current Loss: 0.33213456318928647\n",
      "trigger Times: 1\n",
      "[279/500, 0/38] loss: 0.31329948\n",
      "The Current Loss: 0.3321517797616812\n",
      "trigger Times: 2\n",
      "[280/500, 0/38] loss: 0.31327745\n",
      "The Current Loss: 0.33420750269523036\n",
      "trigger Times: 3\n",
      "[281/500, 0/38] loss: 0.31327581\n",
      "The Current Loss: 0.3320891329875359\n",
      "trigger times: 0\n",
      "[282/500, 0/38] loss: 0.31327292\n",
      "The Current Loss: 0.33267560601234436\n",
      "trigger Times: 1\n",
      "[283/500, 0/38] loss: 0.31328273\n",
      "The Current Loss: 0.3321011272760538\n",
      "trigger times: 0\n",
      "[284/500, 0/38] loss: 0.31328139\n",
      "The Current Loss: 0.3320813545813927\n",
      "trigger times: 0\n",
      "[285/500, 0/38] loss: 0.31328359\n",
      "The Current Loss: 0.3322111734977135\n",
      "trigger Times: 1\n",
      "[286/500, 0/38] loss: 0.31328431\n",
      "The Current Loss: 0.3321417776437906\n",
      "trigger times: 0\n",
      "[287/500, 0/38] loss: 0.31327996\n",
      "The Current Loss: 0.3321299598767207\n",
      "trigger times: 0\n",
      "[288/500, 0/38] loss: 0.31330544\n",
      "The Current Loss: 0.3328254245794736\n",
      "trigger Times: 1\n",
      "[289/500, 0/38] loss: 0.31328765\n",
      "The Current Loss: 0.33637301050699675\n",
      "trigger Times: 2\n",
      "[290/500, 0/38] loss: 0.31331986\n",
      "The Current Loss: 0.333108147749534\n",
      "trigger times: 0\n",
      "[291/500, 0/38] loss: 0.31329975\n",
      "The Current Loss: 0.3321406084757585\n",
      "trigger times: 0\n",
      "[292/500, 0/38] loss: 0.31328163\n",
      "The Current Loss: 0.33208311750338626\n",
      "trigger times: 0\n",
      "[293/500, 0/38] loss: 0.31327996\n",
      "The Current Loss: 0.3321003524156717\n",
      "trigger Times: 1\n",
      "[294/500, 0/38] loss: 0.31327787\n",
      "The Current Loss: 0.3337047489789816\n",
      "trigger Times: 2\n",
      "[295/500, 0/38] loss: 0.3132956\n",
      "The Current Loss: 0.33219361992982716\n",
      "trigger times: 0\n",
      "[296/500, 0/38] loss: 0.31328508\n",
      "The Current Loss: 0.33483755588531494\n",
      "trigger Times: 1\n",
      "[297/500, 0/38] loss: 0.31328353\n",
      "The Current Loss: 0.3356610101002913\n",
      "trigger Times: 2\n",
      "[298/500, 0/38] loss: 0.31327674\n",
      "The Current Loss: 0.33208247331472546\n",
      "trigger times: 0\n",
      "[299/500, 0/38] loss: 0.31327263\n",
      "The Current Loss: 0.3320884887988751\n",
      "trigger Times: 1\n",
      "[300/500, 0/38] loss: 0.31329638\n",
      "The Current Loss: 0.33215408141796404\n",
      "trigger Times: 2\n",
      "[301/500, 0/38] loss: 0.31327671\n",
      "The Current Loss: 0.33208316335311305\n",
      "trigger times: 0\n",
      "[302/500, 0/38] loss: 0.31329042\n",
      "The Current Loss: 0.3320837685695061\n",
      "trigger Times: 1\n",
      "[303/500, 0/38] loss: 0.31329781\n",
      "The Current Loss: 0.3328264607832982\n",
      "trigger Times: 2\n",
      "[304/500, 0/38] loss: 0.31329459\n",
      "The Current Loss: 0.3326380413312178\n",
      "trigger times: 0\n",
      "[305/500, 0/38] loss: 0.31327721\n",
      "The Current Loss: 0.3353001819207118\n",
      "trigger Times: 1\n",
      "[306/500, 0/38] loss: 0.31329587\n",
      "The Current Loss: 0.3342735033768874\n",
      "trigger times: 0\n",
      "[307/500, 0/38] loss: 0.313301\n",
      "The Current Loss: 0.33350058243824887\n",
      "trigger times: 0\n",
      "[308/500, 0/38] loss: 0.31328261\n",
      "The Current Loss: 0.33210123960788435\n",
      "trigger times: 0\n",
      "[309/500, 0/38] loss: 0.31327835\n",
      "The Current Loss: 0.33210520102427554\n",
      "trigger Times: 1\n",
      "[310/500, 0/38] loss: 0.31326735\n",
      "The Current Loss: 0.3331066897282234\n",
      "trigger Times: 2\n",
      "[311/500, 0/38] loss: 0.31327268\n",
      "The Current Loss: 0.33252447614303005\n",
      "trigger times: 0\n",
      "[312/500, 0/38] loss: 0.31329054\n",
      "The Current Loss: 0.3325200447669396\n",
      "trigger times: 0\n",
      "[313/500, 0/38] loss: 0.3132762\n",
      "The Current Loss: 0.3320895181252406\n",
      "trigger times: 0\n",
      "[314/500, 0/38] loss: 0.31328267\n",
      "The Current Loss: 0.3320934841266045\n",
      "trigger Times: 1\n",
      "[315/500, 0/38] loss: 0.31327611\n",
      "The Current Loss: 0.3343285643137418\n",
      "trigger Times: 2\n",
      "[316/500, 0/38] loss: 0.31327033\n",
      "The Current Loss: 0.3320972988238701\n",
      "trigger times: 0\n",
      "[317/500, 0/38] loss: 0.31327856\n",
      "The Current Loss: 0.332089534172645\n",
      "trigger times: 0\n",
      "[318/500, 0/38] loss: 0.31328484\n",
      "The Current Loss: 0.3325212850020482\n",
      "trigger Times: 1\n",
      "[319/500, 0/38] loss: 0.3132886\n",
      "The Current Loss: 0.3344789399550511\n",
      "trigger Times: 2\n",
      "[320/500, 0/38] loss: 0.31327885\n",
      "The Current Loss: 0.33442200834934527\n",
      "trigger times: 0\n",
      "[321/500, 0/38] loss: 0.3133193\n",
      "The Current Loss: 0.3320925854719602\n",
      "trigger times: 0\n",
      "[322/500, 0/38] loss: 0.31328773\n",
      "The Current Loss: 0.33210848386471087\n",
      "trigger Times: 1\n",
      "[323/500, 0/38] loss: 0.31328744\n",
      "The Current Loss: 0.3320830166339874\n",
      "trigger times: 0\n",
      "[324/500, 0/38] loss: 0.31330469\n",
      "The Current Loss: 0.33208970381663394\n",
      "trigger Times: 1\n",
      "[325/500, 0/38] loss: 0.31328884\n",
      "The Current Loss: 0.3334952386525961\n",
      "trigger Times: 2\n",
      "[326/500, 0/38] loss: 0.31327629\n",
      "The Current Loss: 0.3320939105290633\n",
      "trigger times: 0\n",
      "[327/500, 0/38] loss: 0.31330222\n",
      "The Current Loss: 0.33216914993066055\n",
      "trigger Times: 1\n",
      "[328/500, 0/38] loss: 0.31328043\n",
      "The Current Loss: 0.33210123960788435\n",
      "trigger times: 0\n",
      "[329/500, 0/38] loss: 0.31328467\n",
      "The Current Loss: 0.3342341115841499\n",
      "trigger Times: 1\n",
      "[330/500, 0/38] loss: 0.31327993\n",
      "The Current Loss: 0.33216118124815136\n",
      "trigger times: 0\n",
      "[331/500, 0/38] loss: 0.31328297\n",
      "The Current Loss: 0.3321559520868155\n",
      "trigger times: 0\n",
      "[332/500, 0/38] loss: 0.31330582\n",
      "The Current Loss: 0.33269432416329014\n",
      "trigger Times: 1\n",
      "[333/500, 0/38] loss: 0.31327349\n",
      "The Current Loss: 0.33215023691837603\n",
      "trigger times: 0\n",
      "[334/500, 0/38] loss: 0.31328174\n",
      "The Current Loss: 0.3329032292732826\n",
      "trigger Times: 1\n",
      "[335/500, 0/38] loss: 0.31329453\n",
      "The Current Loss: 0.33214260523135847\n",
      "trigger times: 0\n",
      "[336/500, 0/38] loss: 0.31327528\n",
      "The Current Loss: 0.3320920192278348\n",
      "trigger times: 0\n",
      "[337/500, 0/38] loss: 0.31328994\n",
      "The Current Loss: 0.3335221020074991\n",
      "trigger Times: 1\n",
      "[338/500, 0/38] loss: 0.31327513\n",
      "The Current Loss: 0.33263885974884033\n",
      "trigger times: 0\n",
      "[339/500, 0/38] loss: 0.31328806\n",
      "The Current Loss: 0.33209163638261646\n",
      "trigger times: 0\n",
      "[340/500, 0/38] loss: 0.31328785\n",
      "The Current Loss: 0.33492074792201704\n",
      "trigger Times: 1\n",
      "[341/500, 0/38] loss: 0.31329644\n",
      "The Current Loss: 0.3320943277615767\n",
      "trigger times: 0\n",
      "[342/500, 0/38] loss: 0.313279\n",
      "The Current Loss: 0.3321204506433927\n",
      "trigger Times: 1\n",
      "[343/500, 0/38] loss: 0.31331268\n",
      "The Current Loss: 0.33208409410256606\n",
      "trigger times: 0\n",
      "[344/500, 0/38] loss: 0.31329918\n",
      "The Current Loss: 0.3344790431169363\n",
      "trigger Times: 1\n",
      "[345/500, 0/38] loss: 0.31327724\n",
      "The Current Loss: 0.3320904259498303\n",
      "trigger times: 0\n",
      "[346/500, 0/38] loss: 0.31328183\n",
      "The Current Loss: 0.3321270484190721\n",
      "trigger Times: 1\n",
      "[347/500, 0/38] loss: 0.31328455\n",
      "The Current Loss: 0.33210286727318394\n",
      "trigger times: 0\n",
      "[348/500, 0/38] loss: 0.31328231\n",
      "The Current Loss: 0.33208530912032497\n",
      "trigger times: 0\n",
      "[349/500, 0/38] loss: 0.3132807\n",
      "The Current Loss: 0.3351582632615016\n",
      "trigger Times: 1\n",
      "[350/500, 0/38] loss: 0.31330517\n",
      "The Current Loss: 0.33216848052465\n",
      "trigger times: 0\n",
      "[351/500, 0/38] loss: 0.3132821\n",
      "The Current Loss: 0.33208336050693804\n",
      "trigger times: 0\n",
      "[352/500, 0/38] loss: 0.31330717\n",
      "The Current Loss: 0.3321564724812141\n",
      "trigger Times: 1\n",
      "[353/500, 0/38] loss: 0.31329507\n",
      "The Current Loss: 0.3342035779586205\n",
      "trigger Times: 2\n",
      "[354/500, 0/38] loss: 0.3132908\n",
      "The Current Loss: 0.3345145078805777\n",
      "trigger Times: 3\n",
      "[355/500, 0/38] loss: 0.31327912\n",
      "The Current Loss: 0.3320872004215534\n",
      "trigger times: 0\n",
      "[356/500, 0/38] loss: 0.31328043\n",
      "The Current Loss: 0.3320953456255106\n",
      "trigger Times: 1\n",
      "[357/500, 0/38] loss: 0.31328756\n",
      "The Current Loss: 0.33431384655145496\n",
      "trigger Times: 2\n",
      "[358/500, 0/38] loss: 0.31328145\n",
      "The Current Loss: 0.3320832825624026\n",
      "trigger times: 0\n",
      "[359/500, 0/38] loss: 0.31327942\n",
      "The Current Loss: 0.33208417433958787\n",
      "trigger Times: 1\n",
      "[360/500, 0/38] loss: 0.31328908\n",
      "The Current Loss: 0.3320990273585686\n",
      "trigger Times: 2\n",
      "[361/500, 0/38] loss: 0.31327665\n",
      "The Current Loss: 0.33208274153562695\n",
      "trigger times: 0\n",
      "[362/500, 0/38] loss: 0.31330055\n",
      "The Current Loss: 0.33428560999723583\n",
      "trigger Times: 1\n",
      "[363/500, 0/38] loss: 0.31329703\n",
      "The Current Loss: 0.33210426339736354\n",
      "trigger times: 0\n",
      "[364/500, 0/38] loss: 0.31327316\n",
      "The Current Loss: 0.3337778884630937\n",
      "trigger Times: 1\n",
      "[365/500, 0/38] loss: 0.31329548\n",
      "The Current Loss: 0.33429308579518247\n",
      "trigger Times: 2\n",
      "[366/500, 0/38] loss: 0.31327644\n",
      "The Current Loss: 0.33216506701249343\n",
      "trigger times: 0\n",
      "[367/500, 0/38] loss: 0.31328666\n",
      "The Current Loss: 0.33210427256730884\n",
      "trigger times: 0\n",
      "[368/500, 0/38] loss: 0.31329122\n",
      "The Current Loss: 0.3320831839854901\n",
      "trigger times: 0\n",
      "[369/500, 0/38] loss: 0.31328025\n",
      "The Current Loss: 0.3335071802139282\n",
      "trigger Times: 1\n",
      "[370/500, 0/38] loss: 0.31329894\n",
      "The Current Loss: 0.33209899297127354\n",
      "trigger times: 0\n",
      "[371/500, 0/38] loss: 0.31326872\n",
      "The Current Loss: 0.3321659794220558\n",
      "trigger Times: 1\n",
      "[372/500, 0/38] loss: 0.31329122\n",
      "The Current Loss: 0.3320893461887653\n",
      "trigger times: 0\n",
      "[373/500, 0/38] loss: 0.31329361\n",
      "The Current Loss: 0.3320946739270137\n",
      "trigger Times: 1\n",
      "[374/500, 0/38] loss: 0.31331745\n",
      "The Current Loss: 0.33209020587114185\n",
      "trigger times: 0\n",
      "[375/500, 0/38] loss: 0.31328517\n",
      "The Current Loss: 0.3320858432696416\n",
      "trigger times: 0\n",
      "[376/500, 0/38] loss: 0.31327924\n",
      "The Current Loss: 0.33432170060964733\n",
      "trigger Times: 1\n",
      "[377/500, 0/38] loss: 0.31328329\n",
      "The Current Loss: 0.3320839198736044\n",
      "trigger times: 0\n",
      "[378/500, 0/38] loss: 0.31327578\n",
      "The Current Loss: 0.33210673240514904\n",
      "trigger Times: 1\n",
      "[379/500, 0/38] loss: 0.31329206\n",
      "The Current Loss: 0.33215515659405637\n",
      "trigger Times: 2\n",
      "[380/500, 0/38] loss: 0.31330431\n",
      "The Current Loss: 0.33215988828585696\n",
      "trigger Times: 3\n",
      "[381/500, 0/38] loss: 0.31327942\n",
      "The Current Loss: 0.33432631538464475\n",
      "trigger Times: 4\n",
      "[382/500, 0/38] loss: 0.31328863\n",
      "The Current Loss: 0.33216110330361587\n",
      "trigger times: 0\n",
      "[383/500, 0/38] loss: 0.31326634\n",
      "The Current Loss: 0.3335089637682988\n",
      "trigger Times: 1\n",
      "[384/500, 0/38] loss: 0.31328192\n",
      "The Current Loss: 0.3321338662734398\n",
      "trigger times: 0\n",
      "[385/500, 0/38] loss: 0.31327635\n",
      "The Current Loss: 0.3326535362463731\n",
      "trigger Times: 1\n",
      "[386/500, 0/38] loss: 0.31328556\n",
      "The Current Loss: 0.33208361038794887\n",
      "trigger times: 0\n",
      "[387/500, 0/38] loss: 0.31326917\n",
      "The Current Loss: 0.3321020488555615\n",
      "trigger Times: 1\n",
      "[388/500, 0/38] loss: 0.31328055\n",
      "The Current Loss: 0.3321044651361612\n",
      "trigger Times: 2\n",
      "[389/500, 0/38] loss: 0.31327367\n",
      "The Current Loss: 0.3320847818484673\n",
      "trigger times: 0\n",
      "[390/500, 0/38] loss: 0.31329697\n",
      "The Current Loss: 0.3325898051261902\n",
      "trigger Times: 1\n",
      "[391/500, 0/38] loss: 0.31328091\n",
      "The Current Loss: 0.33283506906949556\n",
      "trigger Times: 2\n",
      "[392/500, 0/38] loss: 0.31329253\n",
      "The Current Loss: 0.3320887799446399\n",
      "trigger times: 0\n",
      "[393/500, 0/38] loss: 0.31327739\n",
      "The Current Loss: 0.33312076100936305\n",
      "trigger Times: 1\n",
      "[394/500, 0/38] loss: 0.31329548\n",
      "The Current Loss: 0.33208380754177386\n",
      "trigger times: 0\n",
      "[395/500, 0/38] loss: 0.31329849\n",
      "The Current Loss: 0.3321445263349093\n",
      "trigger Times: 1\n",
      "[396/500, 0/38] loss: 0.31327853\n",
      "The Current Loss: 0.33209221638165987\n",
      "trigger times: 0\n",
      "[397/500, 0/38] loss: 0.31327969\n",
      "The Current Loss: 0.3321210673222175\n",
      "trigger Times: 1\n",
      "[398/500, 0/38] loss: 0.31328294\n",
      "The Current Loss: 0.3320940389082982\n",
      "trigger times: 0\n",
      "[399/500, 0/38] loss: 0.31327742\n",
      "The Current Loss: 0.33253203676297116\n",
      "trigger Times: 1\n",
      "[400/500, 0/38] loss: 0.31328693\n",
      "The Current Loss: 0.3321735675518329\n",
      "trigger times: 0\n",
      "[401/500, 0/38] loss: 0.31329581\n",
      "The Current Loss: 0.33265166328503537\n",
      "trigger Times: 1\n",
      "[402/500, 0/38] loss: 0.31328717\n",
      "The Current Loss: 0.33209550151458156\n",
      "trigger times: 0\n",
      "[403/500, 0/38] loss: 0.3132804\n",
      "The Current Loss: 0.33208420414191026\n",
      "trigger times: 0\n",
      "[404/500, 0/38] loss: 0.31326279\n",
      "The Current Loss: 0.333958428639632\n",
      "trigger Times: 1\n",
      "[405/500, 0/38] loss: 0.31329232\n",
      "The Current Loss: 0.3342763919096727\n",
      "trigger Times: 2\n",
      "[406/500, 0/38] loss: 0.31328002\n",
      "The Current Loss: 0.3352214441849635\n",
      "trigger Times: 3\n",
      "[407/500, 0/38] loss: 0.31326449\n",
      "The Current Loss: 0.3320847314137679\n",
      "trigger times: 0\n",
      "[408/500, 0/38] loss: 0.31328318\n",
      "The Current Loss: 0.3320917968566601\n",
      "trigger Times: 1\n",
      "[409/500, 0/38] loss: 0.31329846\n",
      "The Current Loss: 0.33809882402420044\n",
      "trigger Times: 2\n",
      "[410/500, 0/38] loss: 0.31327307\n",
      "The Current Loss: 0.33209729194641113\n",
      "trigger times: 0\n",
      "[411/500, 0/38] loss: 0.31329975\n",
      "The Current Loss: 0.3337105168746068\n",
      "trigger Times: 1\n",
      "[412/500, 0/38] loss: 0.31327519\n",
      "The Current Loss: 0.3342831570368547\n",
      "trigger Times: 2\n",
      "[413/500, 0/38] loss: 0.31328154\n",
      "The Current Loss: 0.333507973414201\n",
      "trigger times: 0\n",
      "[414/500, 0/38] loss: 0.31327096\n",
      "The Current Loss: 0.3321405282387367\n",
      "trigger times: 0\n",
      "[415/500, 0/38] loss: 0.31329638\n",
      "The Current Loss: 0.33208980010106015\n",
      "trigger times: 0\n",
      "[416/500, 0/38] loss: 0.31331006\n",
      "The Current Loss: 0.3320981997710008\n",
      "trigger Times: 1\n",
      "[417/500, 0/38] loss: 0.31328529\n",
      "The Current Loss: 0.33210468750733596\n",
      "trigger Times: 2\n",
      "[418/500, 0/38] loss: 0.31329808\n",
      "The Current Loss: 0.3320867648491493\n",
      "trigger times: 0\n",
      "[419/500, 0/38] loss: 0.31327987\n",
      "The Current Loss: 0.33250775933265686\n",
      "trigger Times: 1\n",
      "[420/500, 0/38] loss: 0.31329039\n",
      "The Current Loss: 0.3320846649316641\n",
      "trigger times: 0\n",
      "[421/500, 0/38] loss: 0.31330484\n",
      "The Current Loss: 0.3320972048319303\n",
      "trigger Times: 1\n",
      "[422/500, 0/38] loss: 0.31329983\n",
      "The Current Loss: 0.33252541376994205\n",
      "trigger Times: 2\n",
      "[423/500, 0/38] loss: 0.31327978\n",
      "The Current Loss: 0.3344781811420734\n",
      "trigger Times: 3\n",
      "[424/500, 0/38] loss: 0.31329519\n",
      "The Current Loss: 0.3329108655452728\n",
      "trigger times: 0\n",
      "[425/500, 0/38] loss: 0.31329441\n",
      "The Current Loss: 0.3320942245996915\n",
      "trigger times: 0\n",
      "[426/500, 0/38] loss: 0.31328619\n",
      "The Current Loss: 0.33431222576361436\n",
      "trigger Times: 1\n",
      "[427/500, 0/38] loss: 0.31328684\n",
      "The Current Loss: 0.3320904534596663\n",
      "trigger times: 0\n",
      "[428/500, 0/38] loss: 0.31327882\n",
      "The Current Loss: 0.3321331280928392\n",
      "trigger Times: 1\n",
      "[429/500, 0/38] loss: 0.31329805\n",
      "The Current Loss: 0.3321616076506101\n",
      "trigger Times: 2\n",
      "[430/500, 0/38] loss: 0.31329015\n",
      "The Current Loss: 0.3321144191118387\n",
      "trigger times: 0\n",
      "[431/500, 0/38] loss: 0.31328982\n",
      "The Current Loss: 0.33218354215988743\n",
      "trigger Times: 1\n",
      "[432/500, 0/38] loss: 0.31327584\n",
      "The Current Loss: 0.3326636873758756\n",
      "trigger Times: 2\n",
      "[433/500, 0/38] loss: 0.31329757\n",
      "The Current Loss: 0.33211090702276963\n",
      "trigger times: 0\n",
      "[434/500, 0/38] loss: 0.31329167\n",
      "The Current Loss: 0.33447908208920407\n",
      "trigger Times: 1\n",
      "[435/500, 0/38] loss: 0.31328297\n",
      "The Current Loss: 0.3320939586712764\n",
      "trigger times: 0\n",
      "[436/500, 0/38] loss: 0.31329921\n",
      "The Current Loss: 0.3328306789581592\n",
      "trigger Times: 1\n",
      "[437/500, 0/38] loss: 0.31327119\n",
      "The Current Loss: 0.3326501754614023\n",
      "trigger times: 0\n",
      "[438/500, 0/38] loss: 0.3132726\n",
      "The Current Loss: 0.3321173328619737\n",
      "trigger times: 0\n",
      "[439/500, 0/38] loss: 0.31328428\n",
      "The Current Loss: 0.3320867121219635\n",
      "trigger times: 0\n",
      "[440/500, 0/38] loss: 0.31328043\n",
      "The Current Loss: 0.3321031125692221\n",
      "trigger Times: 1\n",
      "[441/500, 0/38] loss: 0.31327543\n",
      "The Current Loss: 0.33210567098397475\n",
      "trigger Times: 2\n",
      "[442/500, 0/38] loss: 0.31327114\n",
      "The Current Loss: 0.33223199385863084\n",
      "trigger Times: 3\n",
      "[443/500, 0/38] loss: 0.31328449\n",
      "The Current Loss: 0.3320910884783818\n",
      "trigger times: 0\n",
      "[444/500, 0/38] loss: 0.31328881\n",
      "The Current Loss: 0.33370602360138524\n",
      "trigger Times: 1\n",
      "[445/500, 0/38] loss: 0.31327283\n",
      "The Current Loss: 0.3355798835937793\n",
      "trigger Times: 2\n",
      "[446/500, 0/38] loss: 0.3132759\n",
      "The Current Loss: 0.33208781022291917\n",
      "trigger times: 0\n",
      "[447/500, 0/38] loss: 0.31328517\n",
      "The Current Loss: 0.3320886011307056\n",
      "trigger Times: 1\n",
      "[448/500, 0/38] loss: 0.31329772\n",
      "The Current Loss: 0.33211458875582767\n",
      "trigger Times: 2\n",
      "[449/500, 0/38] loss: 0.3133094\n",
      "The Current Loss: 0.3325452391917889\n",
      "trigger Times: 3\n",
      "[450/500, 0/38] loss: 0.31329432\n",
      "The Current Loss: 0.3320956780360295\n",
      "trigger times: 0\n",
      "[451/500, 0/38] loss: 0.31327766\n",
      "The Current Loss: 0.3321729554579808\n",
      "trigger Times: 1\n",
      "[452/500, 0/38] loss: 0.31327736\n",
      "The Current Loss: 0.3320864484860347\n",
      "trigger times: 0\n",
      "[453/500, 0/38] loss: 0.31327486\n",
      "The Current Loss: 0.33209554048684925\n",
      "trigger Times: 1\n",
      "[454/500, 0/38] loss: 0.31326959\n",
      "The Current Loss: 0.33209014397401077\n",
      "trigger times: 0\n",
      "[455/500, 0/38] loss: 0.31328234\n",
      "The Current Loss: 0.33209576515051037\n",
      "trigger Times: 1\n",
      "[456/500, 0/38] loss: 0.31329098\n",
      "The Current Loss: 0.33221580661260164\n",
      "trigger Times: 2\n",
      "[457/500, 0/38] loss: 0.31328961\n",
      "The Current Loss: 0.33352397267635053\n",
      "trigger Times: 3\n",
      "[458/500, 0/38] loss: 0.31329122\n",
      "The Current Loss: 0.33209193440584034\n",
      "trigger times: 0\n",
      "[459/500, 0/38] loss: 0.31327894\n",
      "The Current Loss: 0.3320887295099405\n",
      "trigger times: 0\n",
      "[460/500, 0/38] loss: 0.31327403\n",
      "The Current Loss: 0.3326492584668673\n",
      "trigger Times: 1\n",
      "[461/500, 0/38] loss: 0.31330532\n",
      "The Current Loss: 0.332943673317249\n",
      "trigger Times: 2\n",
      "[462/500, 0/38] loss: 0.31327558\n",
      "The Current Loss: 0.33208959377728975\n",
      "trigger times: 0\n",
      "[463/500, 0/38] loss: 0.31328493\n",
      "The Current Loss: 0.33210623264312744\n",
      "trigger Times: 1\n",
      "[464/500, 0/38] loss: 0.31328472\n",
      "The Current Loss: 0.33283648124107945\n",
      "trigger Times: 2\n",
      "[465/500, 0/38] loss: 0.31332386\n",
      "The Current Loss: 0.3366303558533008\n",
      "trigger Times: 3\n",
      "[466/500, 0/38] loss: 0.31328803\n",
      "The Current Loss: 0.33208818619067854\n",
      "trigger times: 0\n",
      "[467/500, 0/38] loss: 0.3132709\n",
      "The Current Loss: 0.332830724807886\n",
      "trigger Times: 1\n",
      "[468/500, 0/38] loss: 0.31327164\n",
      "The Current Loss: 0.33209802783452547\n",
      "trigger times: 0\n",
      "[469/500, 0/38] loss: 0.31329086\n",
      "The Current Loss: 0.3341298217956836\n",
      "trigger Times: 1\n",
      "[470/500, 0/38] loss: 0.31327748\n",
      "The Current Loss: 0.3320913062645839\n",
      "trigger times: 0\n",
      "[471/500, 0/38] loss: 0.31327912\n",
      "The Current Loss: 0.3331207518394177\n",
      "trigger Times: 1\n",
      "[472/500, 0/38] loss: 0.31328347\n",
      "The Current Loss: 0.3320863751264719\n",
      "trigger times: 0\n",
      "[473/500, 0/38] loss: 0.31327507\n",
      "The Current Loss: 0.33208662271499634\n",
      "trigger Times: 1\n",
      "[474/500, 0/38] loss: 0.31328133\n",
      "The Current Loss: 0.3321059071100675\n",
      "trigger Times: 2\n",
      "[475/500, 0/38] loss: 0.31328472\n",
      "The Current Loss: 0.3342903714913588\n",
      "trigger Times: 3\n",
      "[476/500, 0/38] loss: 0.31329483\n",
      "The Current Loss: 0.33436327484937817\n",
      "trigger Times: 4\n",
      "[477/500, 0/38] loss: 0.31328884\n",
      "The Current Loss: 0.33428633442291844\n",
      "trigger times: 0\n",
      "[478/500, 0/38] loss: 0.31328282\n",
      "The Current Loss: 0.3320888510117164\n",
      "trigger times: 0\n",
      "[479/500, 0/38] loss: 0.31327477\n",
      "The Current Loss: 0.3320894195483281\n",
      "trigger Times: 1\n",
      "[480/500, 0/38] loss: 0.3132703\n",
      "The Current Loss: 0.33209399993603045\n",
      "trigger Times: 2\n",
      "[481/500, 0/38] loss: 0.31330225\n",
      "The Current Loss: 0.33209115954545826\n",
      "trigger times: 0\n",
      "[482/500, 0/38] loss: 0.3132734\n",
      "The Current Loss: 0.3320988164498256\n",
      "trigger Times: 1\n",
      "[483/500, 0/38] loss: 0.31328231\n",
      "The Current Loss: 0.3344799761588757\n",
      "trigger Times: 2\n",
      "[484/500, 0/38] loss: 0.31326988\n",
      "The Current Loss: 0.3371816392128284\n",
      "trigger Times: 3\n",
      "[485/500, 0/38] loss: 0.3133007\n",
      "The Current Loss: 0.3320891329875359\n",
      "trigger times: 0\n",
      "[486/500, 0/38] loss: 0.31328019\n",
      "The Current Loss: 0.33406174412140477\n",
      "trigger Times: 1\n",
      "[487/500, 0/38] loss: 0.31328058\n",
      "The Current Loss: 0.332096306177286\n",
      "trigger times: 0\n",
      "[488/500, 0/38] loss: 0.31328148\n",
      "The Current Loss: 0.3321588131097647\n",
      "trigger Times: 1\n",
      "[489/500, 0/38] loss: 0.31329188\n",
      "The Current Loss: 0.336760761646124\n",
      "trigger Times: 2\n",
      "[490/500, 0/38] loss: 0.31330523\n",
      "The Current Loss: 0.33211910266142625\n",
      "trigger times: 0\n",
      "[491/500, 0/38] loss: 0.3132903\n",
      "The Current Loss: 0.3337050240773421\n",
      "trigger Times: 1\n",
      "[492/500, 0/38] loss: 0.31329158\n",
      "The Current Loss: 0.33271218492434573\n",
      "trigger times: 0\n",
      "[493/500, 0/38] loss: 0.31329522\n",
      "The Current Loss: 0.33265785529063296\n",
      "trigger times: 0\n",
      "[494/500, 0/38] loss: 0.31329423\n",
      "The Current Loss: 0.3326175808906555\n",
      "trigger times: 0\n",
      "[495/500, 0/38] loss: 0.31327051\n",
      "The Current Loss: 0.33283034425515395\n",
      "trigger Times: 1\n",
      "[496/500, 0/38] loss: 0.31328884\n",
      "The Current Loss: 0.3321351936230293\n",
      "trigger times: 0\n",
      "[497/500, 0/38] loss: 0.31329125\n",
      "The Current Loss: 0.3349219216750218\n",
      "trigger Times: 1\n",
      "[498/500, 0/38] loss: 0.31327757\n",
      "The Current Loss: 0.3321089927966778\n",
      "trigger times: 0\n",
      "[499/500, 0/38] loss: 0.3133041\n",
      "The Current Loss: 0.3342926295904013\n",
      "trigger Times: 1\n",
      "[500/500, 0/38] loss: 0.31326774\n",
      "The Current Loss: 0.33209305772414577\n",
      "trigger times: 0\n"
     ]
    }
   ],
   "source": [
    "from src.train import traindata\n",
    "hyperparameters = config['hyperparameters']\n",
    "model = traindata(hyperparameters, device, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we didn't need to read any data or calculate the descriptors. This is because the training function already did all of those steps using the `prepare_data` function mentioned in the introduction of this chapter's important note. However, we will need to do it again now to obtain the test set to see if the model is working properly. This is inconvenient because we are reading and splitting the data twice, but this is required because later we will use 'batch_size' (which is used to read the data) as a varying hyperparameter. Because we can only vary the hyperparameters inside the train function, we have to read the data in that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_data import prepare_data\n",
    "mode = config['combination']['mode']\n",
    "data_dir = config['combination']['data_dir']\n",
    "kmer_one_hot = config['fixed_vals']['kmer_one_hot']\n",
    "model_label = config['combination']['model_label'] \n",
    "batch_size = config['hyperparameters']['batch_size']\n",
    "\n",
    "_, testloader, _, _, _ = prepare_data(\n",
    "    data_dir=data_dir,\n",
    "    mode=mode,\n",
    "    batch_size=batch_size,\n",
    "    k=kmer_one_hot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how well the model performs on the test set. The metrics chosen are the accuracy, the Matthews correlation coefficient, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in test set:\n",
      "--------------------\n",
      "- model:   cnn\n",
      "- mode:    one_hot\n",
      "- dataset: primer\n",
      "--------------------\n",
      "Accuracy: 0.990\n",
      "MCC: 0.980\n",
      "[[200   3]\n",
      " [  1 196]]\n"
     ]
    }
   ],
   "source": [
    "from src.test import test\n",
    "\n",
    "acc, mcc, report = test(device, model, testloader)\n",
    "print(\"Results in test set:\")\n",
    "print(\"--------------------\")\n",
    "print(\"- model:  \", model_label)\n",
    "print(\"- mode:   \", mode)\n",
    "print(\"- dataset:\", data_dir.split(\"/\")[-1])\n",
    "print(\"--------------------\")\n",
    "print('Accuracy: %.3f' % acc)\n",
    "print('MCC: %.3f' % mcc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, there was developed a method to find the best hyperparameters. This method is called *hyperparameter tuning*. It is a process of tuning the hyperparameters of a model to obtain the best performance. A function called `hyperparameter_tuning` was implemented that performs this process. It takes as input the config object (which must have the hyperparameters search space) and the device on which the model will be trained. It will create a scheduler called `ASHAScheduler` that will be used terminate the training if the model does not improve for a certain number of epochs. There will be created also a `CLIReporter` object that will report the metrics on the console (accuracy, Matthews correlation coefficient, and loss). Then, `num_samples` samples will be drawn from the hyperparameter search space and the model will be trained on each of them. The best model will be the one that has the highest Matthews correlation coefficient and will be then tested on the test set, outputting the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 15:59:25,306\tERROR syncer.py:147 -- Log sync requires rsync to be installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:25 (running for 00:00:00.21)\n",
      "Memory usage on this node: 88.7/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (14 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+------------------------+--------------+-----------+---------------+-------------+\n",
      "| Trial name            | status   | loc                    |   batch_size |   dropout |   hidden_size |          lr |\n",
      "|-----------------------+----------+------------------------+--------------+-----------+---------------+-------------|\n",
      "| traindata_2f206_00000 | RUNNING  | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 |\n",
      "| traindata_2f206_00001 | PENDING  |                        |           16 |  0.376144 |            32 | 2.13793e-05 |\n",
      "| traindata_2f206_00002 | PENDING  |                        |            8 |  0.331023 |           128 | 0.00030504  |\n",
      "| traindata_2f206_00003 | PENDING  |                        |            8 |  0.438603 |           128 | 0.000643721 |\n",
      "| traindata_2f206_00004 | PENDING  |                        |           16 |  0.499694 |           256 | 4.533e-05   |\n",
      "| traindata_2f206_00005 | PENDING  |                        |            8 |  0.332402 |            32 | 0.00010607  |\n",
      "| traindata_2f206_00006 | PENDING  |                        |           16 |  0.354435 |            64 | 0.00465713  |\n",
      "| traindata_2f206_00007 | PENDING  |                        |           32 |  0.461969 |            32 | 0.000114137 |\n",
      "| traindata_2f206_00008 | PENDING  |                        |           16 |  0.338075 |           128 | 6.63477e-05 |\n",
      "| traindata_2f206_00009 | PENDING  |                        |            8 |  0.337134 |           128 | 0.000387222 |\n",
      "| traindata_2f206_00010 | PENDING  |                        |           16 |  0.426184 |           256 | 1.65834e-05 |\n",
      "| traindata_2f206_00011 | PENDING  |                        |           16 |  0.432872 |           128 | 0.00862223  |\n",
      "| traindata_2f206_00012 | PENDING  |                        |            8 |  0.366441 |            64 | 8.55378e-05 |\n",
      "| traindata_2f206_00013 | PENDING  |                        |           16 |  0.394065 |           256 | 6.21042e-05 |\n",
      "| traindata_2f206_00014 | PENDING  |                        |            8 |  0.420891 |           256 | 0.000670263 |\n",
      "+-----------------------+----------+------------------------+--------------+-----------+---------------+-------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [1/500, 0/38] loss: 0.68471241\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.745\n",
      "  date: 2022-08-17_15-59-30\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6337895806019123\n",
      "  mcc: 0.5626864118225471\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5505173206329346\n",
      "  time_this_iter_s: 0.5505173206329346\n",
      "  time_total_s: 0.5505173206329346\n",
      "  timestamp: 1660748370\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.6337895806019123\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [2/500, 0/38] loss: 0.61727053\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.5529582683856671\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:30 (running for 00:00:05.24)\n",
      "Memory usage on this node: 90.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: -0.5529582683856671 | Iter 1.000: -0.6337895806019123\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (13 PENDING, 2 RUNNING)\n",
      "+-----------------------+----------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status   | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+----------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING  | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.552958 |      0.845 |                    2 | 0.706333 |\n",
      "| traindata_2f206_00001 | RUNNING  | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00002 | PENDING  |                        |            8 |  0.331023 |           128 | 0.00030504  |          |            |                      |          |\n",
      "| traindata_2f206_00003 | PENDING  |                        |            8 |  0.438603 |           128 | 0.000643721 |          |            |                      |          |\n",
      "| traindata_2f206_00004 | PENDING  |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING  |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING  |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING  |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING  |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING  |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING  |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING  |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING  |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING  |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING  |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "+-----------------------+----------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [3/500, 0/38] loss: 0.53485584\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.4841422415696658\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [4/500, 0/38] loss: 0.47030929\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.4332763438041394\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [5/500, 0/38] loss: 0.45691448\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.4068997800350189\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [6/500, 0/38] loss: 0.40804246\n",
      "\u001b[2m\u001b[36m(func pid=3931883)\u001b[0m [1/500, 0/75] loss: 0.6869092\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3930397858986488\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [7/500, 0/38] loss: 0.38453594\n",
      "Result for traindata_2f206_00001:\n",
      "  accuracy: 0.615\n",
      "  date: 2022-08-17_15-59-34\n",
      "  done: true\n",
      "  experiment_id: 5012f088373848cfbfd3d77c12988299\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6894357085227967\n",
      "  mcc: 0.2302575669827911\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931883\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5592665672302246\n",
      "  time_this_iter_s: 0.5592665672302246\n",
      "  time_total_s: 0.5592665672302246\n",
      "  timestamp: 1660748374\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00001\n",
      "  warmup_time: 0.0037910938262939453\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931883)\u001b[0m The Current Loss: 0.6894357085227967\n",
      "\u001b[2m\u001b[36m(func pid=3931883)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.37516661102955157\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [8/500, 0/38] loss: 0.34624705\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.36338866215485793\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [9/500, 0/38] loss: 0.35605714\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3542456879065587\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [10/500, 0/38] loss: 0.33700174\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.98\n",
      "  date: 2022-08-17_15-59-35\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.34957010929401106\n",
      "  mcc: 0.9600450104271285\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.596264839172363\n",
      "  time_this_iter_s: 0.10375142097473145\n",
      "  time_total_s: 5.596264839172363\n",
      "  timestamp: 1660748375\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.34957010929401106\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [11/500, 0/38] loss: 0.36956471\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:35 (running for 00:00:10.29)\n",
      "Memory usage on this node: 90.5/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: -0.36338866215485793 | Iter 4.000: -0.4332763438041394 | Iter 2.000: -0.5529582683856671 | Iter 1.000: -0.6616126445623545\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (13 PENDING, 1 RUNNING, 1 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.343653 |     0.9775 |                   11 | 0.954998 |\n",
      "| traindata_2f206_00002 | PENDING    |                        |            8 |  0.331023 |           128 | 0.00030504  |          |            |                      |          |\n",
      "| traindata_2f206_00003 | PENDING    |                        |            8 |  0.438603 |           128 | 0.000643721 |          |            |                      |          |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.34365270458734953\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [12/500, 0/38] loss: 0.34624851\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.35019751007740313\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [13/500, 0/38] loss: 0.32940936\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3396972371981694\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [14/500, 0/38] loss: 0.32418659\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.34356719943193287\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [15/500, 0/38] loss: 0.35129735\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.334697262598918\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [16/500, 0/38] loss: 0.32027173\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3352227004674765\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [17/500, 0/38] loss: 0.31902099\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3309404712456923\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [18/500, 0/38] loss: 0.32053539\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3354311126929063\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [19/500, 0/38] loss: 0.34166914\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.33056459060082066\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [20/500, 0/38] loss: 0.31996906\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32907588665301984\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [21/500, 0/38] loss: 0.31651026\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32884907722473145\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [22/500, 0/38] loss: 0.3262758\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.33040321561006397\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [23/500, 0/38] loss: 0.31505269\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32653780625416684\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [24/500, 0/38] loss: 0.3141472\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3288710369513585\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [25/500, 0/38] loss: 0.31920126\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3282004136305589\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [26/500, 0/38] loss: 0.3148157\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32788946766119736\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [27/500, 0/38] loss: 0.31428939\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32619596215394825\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [28/500, 0/38] loss: 0.31512189\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3248769136575552\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [29/500, 0/38] loss: 0.31588718\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3254501177714421\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [30/500, 0/38] loss: 0.3149043\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3256023617891165\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [31/500, 0/38] loss: 0.31447464\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3241488245817331\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [32/500, 0/38] loss: 0.31441537\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3240627921544589\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [33/500, 0/38] loss: 0.31363207\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32405426181279695\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [34/500, 0/38] loss: 0.31376481\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32439388449375445\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [35/500, 0/38] loss: 0.31444538\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32489726405877334\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [36/500, 0/38] loss: 0.31369683\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32446321845054626\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [37/500, 0/38] loss: 0.31425807\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32361015448203456\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [38/500, 0/38] loss: 0.31436536\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32299253115287196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [39/500, 0/38] loss: 0.31351131\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32355062319682193\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [40/500, 0/38] loss: 0.31397447\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3239628466276022\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [41/500, 0/38] loss: 0.31367519\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32274599029467654\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [42/500, 0/38] loss: 0.31348664\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.322858798962373\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [43/500, 0/38] loss: 0.31378105\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3245854698694669\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [44/500, 0/38] loss: 0.31334129\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.323161251269854\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [45/500, 0/38] loss: 0.31362095\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.322528580060372\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [46/500, 0/38] loss: 0.3134298\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.323676728285276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [47/500, 0/38] loss: 0.31376594\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3231870440336374\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [48/500, 0/38] loss: 0.31368157\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32418073828403765\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [49/500, 0/38] loss: 0.31369159\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3232341637978187\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [50/500, 0/38] loss: 0.31360012\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3223508344246791\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [51/500, 0/38] loss: 0.31390741\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32430509420541614\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [52/500, 0/38] loss: 0.3135877\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32226383227568406\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [53/500, 0/38] loss: 0.31342432\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32259276050787705\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [54/500, 0/38] loss: 0.31380558\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3223297962775597\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [55/500, 0/38] loss: 0.31353307\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3248140078324538\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [56/500, 0/38] loss: 0.31334278\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32243671784034145\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [57/500, 0/38] loss: 0.31359807\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_15-59-40\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 57\n",
      "  loss: 0.32191605751331037\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.663471221923828\n",
      "  time_this_iter_s: 0.10296845436096191\n",
      "  time_total_s: 10.663471221923828\n",
      "  timestamp: 1660748380\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 57\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32191605751331037\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [58/500, 0/38] loss: 0.31366253\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:40 (running for 00:00:15.35)\n",
      "Memory usage on this node: 92.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 256.000: None | Iter 128.000: None | Iter 64.000: None | Iter 32.000: -0.3240627921544589 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.36338866215485793 | Iter 4.000: -0.4332763438041394 | Iter 2.000: -0.5529582683856671 | Iter 1.000: -0.6616126445623545\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (12 PENDING, 2 RUNNING, 1 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.321838 |     0.9925 |                   58 | 0.985111 |\n",
      "| traindata_2f206_00002 | RUNNING    | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  |          |            |                      |          |\n",
      "| traindata_2f206_00003 | PENDING    |                        |            8 |  0.438603 |           128 | 0.000643721 |          |            |                      |          |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32183835827387297\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [59/500, 0/38] loss: 0.31349683\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32190031042465794\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [60/500, 0/38] loss: 0.31354427\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [1/500, 0/150] loss: 0.69674748\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32184273921526396\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [61/500, 0/38] loss: 0.31364542\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3215730281976553\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [62/500, 0/38] loss: 0.31359908\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [1/500, 100/150] loss: 0.61192364\n",
      "Result for traindata_2f206_00002:\n",
      "  accuracy: 0.845\n",
      "  date: 2022-08-17_15-59-40\n",
      "  done: false\n",
      "  experiment_id: c1afbab8bcdc409197a5bdfbe1cbd27b\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.5398776644468307\n",
      "  mcc: 0.6982270804501465\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931986\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6986396312713623\n",
      "  time_this_iter_s: 0.6986396312713623\n",
      "  time_total_s: 0.6986396312713623\n",
      "  timestamp: 1660748380\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00002\n",
      "  warmup_time: 0.003938913345336914\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32278446509287906\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [63/500, 0/38] loss: 0.31342047\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.5398776644468307\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [2/500, 0/150] loss: 0.54552925\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32182275561185986\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [64/500, 0/38] loss: 0.31336609\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3216813619320209\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [65/500, 0/38] loss: 0.31340441\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [2/500, 100/150] loss: 0.40016565\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32175463208785426\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [66/500, 0/38] loss: 0.31346753\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.42899625301361083\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [3/500, 0/150] loss: 0.4783369\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32192468643188477\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [67/500, 0/38] loss: 0.31349722\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3217080648128803\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [68/500, 0/38] loss: 0.31344309\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [3/500, 100/150] loss: 0.38185823\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32143961695524365\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [69/500, 0/38] loss: 0.31341946\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3897830992937088\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [4/500, 0/150] loss: 0.40531948\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.322191052711927\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [70/500, 0/38] loss: 0.31340149\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3224426553799556\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [71/500, 0/38] loss: 0.31336379\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [4/500, 100/150] loss: 0.31570104\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3219495484462151\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [72/500, 0/38] loss: 0.31350765\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3658917301893234\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3214634633981265\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [73/500, 0/38] loss: 0.31335041\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [5/500, 0/150] loss: 0.35228217\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.321223829801266\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [74/500, 0/38] loss: 0.31345528\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [5/500, 100/150] loss: 0.32102674\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.322317694242184\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [75/500, 0/38] loss: 0.313301\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3215387165546417\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [76/500, 0/38] loss: 0.31337127\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32132713152812076\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3555767124891281\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [6/500, 0/150] loss: 0.32612544\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [77/500, 0/38] loss: 0.31336588\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32157655633412874\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [6/500, 100/150] loss: 0.31639981\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [78/500, 0/38] loss: 0.31344497\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32122697738500744\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [79/500, 0/38] loss: 0.31335622\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3215579459300408\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3493291789293289\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [7/500, 0/150] loss: 0.31661457\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [80/500, 0/38] loss: 0.31341502\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32136396261361927\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [81/500, 0/38] loss: 0.31338811\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3213486327574803\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [82/500, 0/38] loss: 0.31335264\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [7/500, 100/150] loss: 0.3212603\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3216039767632118\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [83/500, 0/38] loss: 0.31329983\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3457822948694229\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [8/500, 0/150] loss: 0.31428185\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32172317229784453\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [84/500, 0/38] loss: 0.31335044\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3211519236748035\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [85/500, 0/38] loss: 0.31334615\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [8/500, 100/150] loss: 0.31620529\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32127029162186843\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [86/500, 0/38] loss: 0.31333989\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.34589595258235933\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [9/500, 0/150] loss: 0.32192099\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3213575344819289\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [87/500, 0/38] loss: 0.3133148\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32116830119719875\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [88/500, 0/38] loss: 0.31331602\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [9/500, 100/150] loss: 0.31905121\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32145764506780183\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [89/500, 0/38] loss: 0.3133162\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3401418077945709\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [10/500, 0/150] loss: 0.31344643\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32145284230892474\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [90/500, 0/38] loss: 0.31330991\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3250531554222107\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [91/500, 0/38] loss: 0.31333381\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [10/500, 100/150] loss: 0.31860876\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32147852732585025\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [92/500, 0/38] loss: 0.3133671\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3213931711820456\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [93/500, 0/38] loss: 0.31329536\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3401214039325714\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [11/500, 0/150] loss: 0.31429848\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32103475011312044\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [94/500, 0/38] loss: 0.3133156\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [11/500, 100/150] loss: 0.31459427\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3209717640509972\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [95/500, 0/38] loss: 0.31333199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3232571092935709\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [96/500, 0/38] loss: 0.31329593\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3379452168941498\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [12/500, 0/150] loss: 0.31460968\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3228451449137468\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [97/500, 0/38] loss: 0.31333148\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [12/500, 100/150] loss: 0.31421658\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3209574933235462\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [98/500, 0/38] loss: 0.31331947\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207971453666687\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [99/500, 0/38] loss: 0.31328788\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3373181855678558\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [13/500, 0/150] loss: 0.31372902\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3208716076153975\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [100/500, 0/38] loss: 0.31331354\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32077049062802243\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [101/500, 0/38] loss: 0.31335488\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [13/500, 100/150] loss: 0.31451535\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32110464572906494\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [102/500, 0/38] loss: 0.31333521\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3369577604532242\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [14/500, 0/150] loss: 0.31349432\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210168366248791\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [103/500, 0/38] loss: 0.31330812\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32107059084452116\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [14/500, 100/150] loss: 0.31378967\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [104/500, 0/38] loss: 0.31327564\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.33616979539394376\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [15/500, 0/150] loss: 0.31337619\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_15-59-45\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 104\n",
      "  loss: 0.3213327618745657\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 15.719033241271973\n",
      "  time_this_iter_s: 0.10544371604919434\n",
      "  time_total_s: 15.719033241271973\n",
      "  timestamp: 1660748385\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 104\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3213327618745657\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [105/500, 0/38] loss: 0.31327024\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:45 (running for 00:00:20.42)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 256.000: None | Iter 128.000: None | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3240627921544589 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.35464230736860863 | Iter 4.000: -0.3995840369967314 | Iter 2.000: -0.490977260699639 | Iter 1.000: -0.6337895806019123\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (12 PENDING, 2 RUNNING, 1 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.322351 |     0.9925 |                  105 | 0.985111 |\n",
      "| traindata_2f206_00002 | RUNNING    | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.33617  |     0.9775 |                   14 | 0.955005 |\n",
      "| traindata_2f206_00003 | PENDING    |                        |            8 |  0.438603 |           128 | 0.000643721 |          |            |                      |          |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.322350969681373\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [106/500, 0/38] loss: 0.31330881\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [15/500, 100/150] loss: 0.31381145\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210802972316742\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [107/500, 0/38] loss: 0.31328917\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.3363254714012146\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [16/500, 0/150] loss: 0.31372795\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32218393912682164\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [108/500, 0/38] loss: 0.31329331\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m [16/500, 100/150] loss: 0.31385511\n",
      "Result for traindata_2f206_00002:\n",
      "  accuracy: 0.9725\n",
      "  date: 2022-08-17_15-59-45\n",
      "  done: true\n",
      "  experiment_id: c1afbab8bcdc409197a5bdfbe1cbd27b\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.33708340585231783\n",
      "  mcc: 0.9453036136838198\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931986\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.705564737319946\n",
      "  time_this_iter_s: 0.32146191596984863\n",
      "  time_total_s: 5.705564737319946\n",
      "  timestamp: 1660748385\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: 2f206_00002\n",
      "  warmup_time: 0.003938913345336914\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32068954981290376\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [109/500, 0/38] loss: 0.31330124\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m The Current Loss: 0.33708340585231783\n",
      "\u001b[2m\u001b[36m(func pid=3931986)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32093139107410723\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [110/500, 0/38] loss: 0.31330198\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32077996547405535\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [111/500, 0/38] loss: 0.3133193\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3232162594795227\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [112/500, 0/38] loss: 0.31331071\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207982824398921\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [113/500, 0/38] loss: 0.31330392\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206609327059526\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [114/500, 0/38] loss: 0.31330445\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32144373655319214\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [115/500, 0/38] loss: 0.31330577\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32080435294371384\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [116/500, 0/38] loss: 0.31327108\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32113567223915684\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [117/500, 0/38] loss: 0.31328455\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32282856794504017\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [118/500, 0/38] loss: 0.31330138\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3208004029897543\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [119/500, 0/38] loss: 0.31329858\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32056394677895766\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [120/500, 0/38] loss: 0.31331137\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32094139089951146\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [121/500, 0/38] loss: 0.31328225\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3211564811376425\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [122/500, 0/38] loss: 0.31327501\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205337616113516\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [123/500, 0/38] loss: 0.31328827\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320929779456212\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [124/500, 0/38] loss: 0.31329119\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3208141051805936\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [125/500, 0/38] loss: 0.31328213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32035335439902085\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [126/500, 0/38] loss: 0.31328499\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3208434283733368\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [127/500, 0/38] loss: 0.31331643\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3204712202915779\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [128/500, 0/38] loss: 0.31328472\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3208131813085996\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [129/500, 0/38] loss: 0.31330442\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32244155957148624\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [130/500, 0/38] loss: 0.31328735\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32057108787389904\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [131/500, 0/38] loss: 0.31327078\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32039002501047575\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [132/500, 0/38] loss: 0.31327069\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205965826144585\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [133/500, 0/38] loss: 0.31328487\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32237353233190685\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [134/500, 0/38] loss: 0.31327483\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205718627342811\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [135/500, 0/38] loss: 0.31328058\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32086783189039964\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [136/500, 0/38] loss: 0.31326813\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3204577909066127\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [137/500, 0/38] loss: 0.31329235\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3204393134667323\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [138/500, 0/38] loss: 0.31328598\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.321167909182035\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [139/500, 0/38] loss: 0.31327584\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205019258535825\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [140/500, 0/38] loss: 0.31329179\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3204696338910323\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [141/500, 0/38] loss: 0.31326619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205031890135545\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [142/500, 0/38] loss: 0.31327933\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054672791407657\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [143/500, 0/38] loss: 0.31329256\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32050195794839126\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [144/500, 0/38] loss: 0.3132872\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32282532636935896\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [145/500, 0/38] loss: 0.31327382\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205051376269414\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [146/500, 0/38] loss: 0.31327203\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205307859640855\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [147/500, 0/38] loss: 0.31327847\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205419389101175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [148/500, 0/38] loss: 0.3132765\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320535646035121\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [149/500, 0/38] loss: 0.3132847\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205342499109415\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [150/500, 0/38] loss: 0.31328207\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206842564619504\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [151/500, 0/38] loss: 0.31328771\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_15-59-50\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 151\n",
      "  loss: 0.3210909893879524\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 20.80236554145813\n",
      "  time_this_iter_s: 0.10587286949157715\n",
      "  time_total_s: 20.80236554145813\n",
      "  timestamp: 1660748390\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 151\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210909893879524\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [152/500, 0/38] loss: 0.31327736\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206224533227774\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:50 (running for 00:00:25.49)\n",
      "Memory usage on this node: 91.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: None | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3240627921544589 | Iter 16.000: -0.3361530531598972 | Iter 8.000: -0.35464230736860863 | Iter 4.000: -0.3995840369967314 | Iter 2.000: -0.490977260699639 | Iter 1.000: -0.6337895806019123\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320622 |     0.9925 |                  152 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 |          |            |                      |          |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [153/500, 0/38] loss: 0.31326872\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054242262473476\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [154/500, 0/38] loss: 0.3132759\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205370261118962\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [155/500, 0/38] loss: 0.31328773\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054035250957197\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [156/500, 0/38] loss: 0.31330228\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [1/500, 0/150] loss: 0.68959266\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205394928271954\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [157/500, 0/38] loss: 0.31328902\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32088508285008943\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [158/500, 0/38] loss: 0.3132886\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [1/500, 100/150] loss: 0.70385969\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205302586922279\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.93\n",
      "  date: 2022-08-17_15-59-51\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.4154818135499954\n",
      "  mcc: 0.8600325083642456\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7293224334716797\n",
      "  time_this_iter_s: 0.7293224334716797\n",
      "  time_total_s: 0.7293224334716797\n",
      "  timestamp: 1660748391\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [159/500, 0/38] loss: 0.31327236\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205290161646329\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.4154818135499954\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [2/500, 0/150] loss: 0.40602371\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [160/500, 0/38] loss: 0.31327248\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054317456025344\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [161/500, 0/38] loss: 0.31327081\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206066351670485\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [2/500, 100/150] loss: 0.40076062\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [162/500, 0/38] loss: 0.31329232\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3223023804334494\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [163/500, 0/38] loss: 0.31328756\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053305552555966\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.354632078409195\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [3/500, 0/150] loss: 0.35020319\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [164/500, 0/38] loss: 0.31328529\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32071579648898196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [3/500, 100/150] loss: 0.33283272\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [165/500, 0/38] loss: 0.31326842\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205291491288405\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [166/500, 0/38] loss: 0.31328779\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3576673400402069\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [4/500, 0/150] loss: 0.31854677\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32104046986653256\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [167/500, 0/38] loss: 0.31328809\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320680891092007\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [168/500, 0/38] loss: 0.31330255\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32060643342825085\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [4/500, 100/150] loss: 0.31796229\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [169/500, 0/38] loss: 0.3132692\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205286103945512\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3557737797498703\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [5/500, 0/150] loss: 0.31513011\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [170/500, 0/38] loss: 0.31328735\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206255000371199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [171/500, 0/38] loss: 0.31328681\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205340321247394\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [5/500, 100/150] loss: 0.31493998\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [172/500, 0/38] loss: 0.31328347\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205333145765158\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.33005059123039243\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [6/500, 0/150] loss: 0.31362203\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [173/500, 0/38] loss: 0.31326985\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3224816643274747\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [174/500, 0/38] loss: 0.31327888\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054145061052763\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [6/500, 100/150] loss: 0.31569719\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [175/500, 0/38] loss: 0.31327993\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053001339618975\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3285260093212128\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [7/500, 0/150] loss: 0.3139739\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [176/500, 0/38] loss: 0.31327349\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205287433587588\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [177/500, 0/38] loss: 0.31328019\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32057867371118987\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [7/500, 100/150] loss: 0.31526044\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [178/500, 0/38] loss: 0.31328034\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210830115354978\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32673370480537417\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [8/500, 0/150] loss: 0.31343797\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [179/500, 0/38] loss: 0.31328356\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205464780330658\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [180/500, 0/38] loss: 0.31327415\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053804856080276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [8/500, 100/150] loss: 0.3158873\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [181/500, 0/38] loss: 0.31328982\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297268353976\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.34472739458084106\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [9/500, 0/150] loss: 0.3163439\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [182/500, 0/38] loss: 0.31327572\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053082952132594\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [183/500, 0/38] loss: 0.31328601\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205383809713217\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [9/500, 100/150] loss: 0.31371918\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [184/500, 0/38] loss: 0.31328157\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3218996547735654\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [185/500, 0/38] loss: 0.3132681\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32405663549900054\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [10/500, 0/150] loss: 0.31412756\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205316731562981\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [186/500, 0/38] loss: 0.31326768\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053844516093916\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [187/500, 0/38] loss: 0.3132776\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [10/500, 100/150] loss: 0.31350356\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205376106959123\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [188/500, 0/38] loss: 0.31329662\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3246558928489685\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32075390678185683\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [189/500, 0/38] loss: 0.31328595\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [11/500, 0/150] loss: 0.31399488\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205680847167969\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [190/500, 0/38] loss: 0.31328362\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [11/500, 100/150] loss: 0.31436908\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206828167805305\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [191/500, 0/38] loss: 0.31326979\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205334475407234\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [192/500, 0/38] loss: 0.31328797\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32626008331775663\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [12/500, 0/150] loss: 0.31355345\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205301601153154\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [12/500, 100/150] loss: 0.31336752\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [193/500, 0/38] loss: 0.31328204\n",
      "== Status ==\n",
      "Current time: 2022-08-17 15:59:55 (running for 00:00:30.53)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: None | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3240627921544589 | Iter 16.000: -0.3361530531598972 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.32053  |     0.9925 |                  192 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.323909 |     0.9925 |                   12 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_15-59-55\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 193\n",
      "  loss: 0.3205285164026114\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 25.95276951789856\n",
      "  time_this_iter_s: 0.1487140655517578\n",
      "  time_total_s: 25.95276951789856\n",
      "  timestamp: 1660748395\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 193\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205285164026114\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [194/500, 0/38] loss: 0.31327394\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3239086389541626\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [13/500, 0/150] loss: 0.31328285\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32284100697590756\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [195/500, 0/38] loss: 0.31329378\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32233110757974476\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [196/500, 0/38] loss: 0.31326801\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [13/500, 100/150] loss: 0.31380942\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053286754168\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [197/500, 0/38] loss: 0.31327742\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32320993959903715\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [14/500, 0/150] loss: 0.31347042\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32060025288508487\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [198/500, 0/38] loss: 0.31329441\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205386514847095\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [199/500, 0/38] loss: 0.31327817\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [14/500, 100/150] loss: 0.31334424\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3229373831015367\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [200/500, 0/38] loss: 0.31328762\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3248025393486023\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [15/500, 0/150] loss: 0.31335697\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206212314275595\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [201/500, 0/38] loss: 0.3132892\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053223023047817\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [202/500, 0/38] loss: 0.31326738\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [15/500, 100/150] loss: 0.31345674\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205381448452289\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [203/500, 0/38] loss: 0.31328127\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32527772068977356\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [16/500, 0/150] loss: 0.31328174\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205291055716001\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [204/500, 0/38] loss: 0.31329072\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205318863575275\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [205/500, 0/38] loss: 0.3132728\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [16/500, 100/150] loss: 0.31329432\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320529791025015\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [206/500, 0/38] loss: 0.31327593\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_15-59-57\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 16\n",
      "  loss: 0.3233336466550827\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.792171239852905\n",
      "  time_this_iter_s: 0.3858773708343506\n",
      "  time_total_s: 5.792171239852905\n",
      "  timestamp: 1660748397\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 16\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205348253250122\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [207/500, 0/38] loss: 0.31328613\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3233336466550827\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [17/500, 0/150] loss: 0.31328315\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207237491240868\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [208/500, 0/38] loss: 0.31328049\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205368152031532\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [209/500, 0/38] loss: 0.31327903\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [17/500, 100/150] loss: 0.31327343\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205292018560263\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [210/500, 0/38] loss: 0.31327352\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206170407625345\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [211/500, 0/38] loss: 0.31327519\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.324750235080719\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [18/500, 0/150] loss: 0.31332907\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052836739099944\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [212/500, 0/38] loss: 0.31327784\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206062385669121\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [213/500, 0/38] loss: 0.31327912\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [18/500, 100/150] loss: 0.31357834\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205457811172192\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [214/500, 0/38] loss: 0.3132664\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205293875474196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [215/500, 0/38] loss: 0.3132768\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206026003910945\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32302505671978\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [19/500, 0/150] loss: 0.31326979\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [216/500, 0/38] loss: 0.31328201\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205309258057521\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [217/500, 0/38] loss: 0.31328699\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053704215930057\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [19/500, 100/150] loss: 0.31334504\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [218/500, 0/38] loss: 0.31328571\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32077356714468735\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [219/500, 0/38] loss: 0.31327671\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052979331750137\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32300570368766784\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [20/500, 0/150] loss: 0.31331882\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [220/500, 0/38] loss: 0.3132771\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205362374965961\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [221/500, 0/38] loss: 0.31328368\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205435092632587\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [20/500, 100/150] loss: 0.31326818\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [222/500, 0/38] loss: 0.31327134\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207635214695564\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [223/500, 0/38] loss: 0.31327632\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205408797814296\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [224/500, 0/38] loss: 0.31327778\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.323721809387207\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [21/500, 0/150] loss: 0.3133963\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052993315916795\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [225/500, 0/38] loss: 0.31329176\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053109315725475\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [226/500, 0/38] loss: 0.31327152\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [21/500, 100/150] loss: 0.31332725\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205314553700961\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [227/500, 0/38] loss: 0.31327865\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3237955886125565\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205537933569688\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [228/500, 0/38] loss: 0.31327078\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [22/500, 0/150] loss: 0.31330639\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205433121094337\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [229/500, 0/38] loss: 0.31327847\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205537154124333\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [230/500, 0/38] loss: 0.31328425\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [22/500, 100/150] loss: 0.31331563\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205445110797882\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [231/500, 0/38] loss: 0.3132782\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32316301226615907\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053130177351147\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [232/500, 0/38] loss: 0.31327644\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [23/500, 0/150] loss: 0.31326741\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320529254583212\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [233/500, 0/38] loss: 0.31327337\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [23/500, 100/150] loss: 0.31327006\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207575266177838\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [234/500, 0/38] loss: 0.31328911\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205432456273299\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [235/500, 0/38] loss: 0.31329605\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32297717332839965\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [24/500, 0/150] loss: 0.31329459\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205421337714562\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [236/500, 0/38] loss: 0.31328163\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053414904154265\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [237/500, 0/38] loss: 0.31327882\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [24/500, 100/150] loss: 0.31329992\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32284154341771054\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [238/500, 0/38] loss: 0.3132841\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32315298736095427\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [25/500, 0/150] loss: 0.3133727\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054459131681\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [239/500, 0/38] loss: 0.31327286\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206387758255005\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [240/500, 0/38] loss: 0.31327653\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [25/500, 100/150] loss: 0.31339851\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32083706901623654\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [241/500, 0/38] loss: 0.31327409\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3236787527799606\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [26/500, 0/150] loss: 0.31326991\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:00 (running for 00:00:35.53)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: None | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3240627921544589 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320761 |     0.9925 |                  241 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.323679 |     0.9925 |                   25 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207607360986563\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [242/500, 0/38] loss: 0.31326687\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-00\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 242\n",
      "  loss: 0.3205289657299335\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 31.066117525100708\n",
      "  time_this_iter_s: 0.11099815368652344\n",
      "  time_total_s: 31.066117525100708\n",
      "  timestamp: 1660748400\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 242\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205289657299335\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [243/500, 0/38] loss: 0.31327581\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [26/500, 100/150] loss: 0.31328699\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205380898255568\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [244/500, 0/38] loss: 0.31328565\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3234120798110962\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [27/500, 0/150] loss: 0.31332886\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205777956889226\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [245/500, 0/38] loss: 0.31329444\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320529220195917\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [246/500, 0/38] loss: 0.31329393\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [27/500, 100/150] loss: 0.31331366\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205515444278717\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [247/500, 0/38] loss: 0.31327912\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3221659272909164\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [28/500, 0/150] loss: 0.31326666\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32076892256736755\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [248/500, 0/38] loss: 0.31328645\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205304489685939\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [249/500, 0/38] loss: 0.31328371\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [28/500, 100/150] loss: 0.31327066\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205385414453653\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [250/500, 0/38] loss: 0.31326544\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32283606350421906\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [29/500, 0/150] loss: 0.31332859\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205486031679007\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [251/500, 0/38] loss: 0.31326896\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205401072135338\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [252/500, 0/38] loss: 0.31330559\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [29/500, 100/150] loss: 0.31328648\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053905725479126\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [253/500, 0/38] loss: 0.31329077\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.323403337597847\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [30/500, 0/150] loss: 0.31328788\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3222986161708832\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [254/500, 0/38] loss: 0.31329313\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32230252027511597\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [255/500, 0/38] loss: 0.313274\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [30/500, 100/150] loss: 0.3132658\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-02\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 30\n",
      "  loss: 0.3225029271841049\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.916210412979126\n",
      "  time_this_iter_s: 0.3142111301422119\n",
      "  time_total_s: 10.916210412979126\n",
      "  timestamp: 1660748402\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052876399113583\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [256/500, 0/38] loss: 0.31326723\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3225029271841049\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [31/500, 0/150] loss: 0.31328076\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053314264004046\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [257/500, 0/38] loss: 0.31328484\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205382823944092\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [258/500, 0/38] loss: 0.31328011\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [31/500, 100/150] loss: 0.31327516\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053558184550357\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [259/500, 0/38] loss: 0.31328422\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3229963207244873\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [32/500, 0/150] loss: 0.31327525\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205293187728295\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [260/500, 0/38] loss: 0.31327677\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205294425670917\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [261/500, 0/38] loss: 0.31329271\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32073064950796276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [32/500, 100/150] loss: 0.31326687\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [262/500, 0/38] loss: 0.31327903\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32076881940548235\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32196231007575987\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [33/500, 0/150] loss: 0.31327814\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [263/500, 0/38] loss: 0.31328154\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205283811459175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [264/500, 0/38] loss: 0.31328231\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3228426300562345\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [33/500, 100/150] loss: 0.31327367\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [265/500, 0/38] loss: 0.31328589\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053531133211577\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [266/500, 0/38] loss: 0.31327471\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3218207061290741\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [34/500, 0/150] loss: 0.31327879\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205311642243312\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [267/500, 0/38] loss: 0.3132863\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32056512511693513\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [268/500, 0/38] loss: 0.31327423\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [34/500, 100/150] loss: 0.31328773\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205431562203627\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [269/500, 0/38] loss: 0.3132861\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3222669351100922\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [35/500, 0/150] loss: 0.31327248\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207542621172391\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [270/500, 0/38] loss: 0.31329021\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3229258931600131\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [271/500, 0/38] loss: 0.31329548\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [35/500, 100/150] loss: 0.31326702\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32229400827334476\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [272/500, 0/38] loss: 0.31328726\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32219249904155733\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [36/500, 0/150] loss: 0.31327826\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205288350582123\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [273/500, 0/38] loss: 0.31328133\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205978045096764\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [274/500, 0/38] loss: 0.31326878\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [36/500, 100/150] loss: 0.31327307\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205305544229654\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [275/500, 0/38] loss: 0.31327873\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32245600640773775\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [37/500, 0/150] loss: 0.3132647\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205309693629925\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [276/500, 0/38] loss: 0.31327432\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205295571914086\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [277/500, 0/38] loss: 0.3132861\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [37/500, 100/150] loss: 0.31328681\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205284613829393\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [278/500, 0/38] loss: 0.31327397\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32254319965839384\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [38/500, 0/150] loss: 0.31328097\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205305016957797\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [279/500, 0/38] loss: 0.31328255\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206946414250594\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [280/500, 0/38] loss: 0.31329009\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [38/500, 100/150] loss: 0.31327221\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32057291498551\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [281/500, 0/38] loss: 0.31327596\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32213226079940793\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [39/500, 0/150] loss: 0.31327254\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32116944973285383\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [282/500, 0/38] loss: 0.31327441\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205367647684537\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [283/500, 0/38] loss: 0.31326863\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [39/500, 100/150] loss: 0.3132782\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297314203702\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [284/500, 0/38] loss: 0.31327167\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32182838320732116\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [40/500, 0/150] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205293141878568\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [285/500, 0/38] loss: 0.31328732\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32068154215812683\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [286/500, 0/38] loss: 0.31328028\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [40/500, 100/150] loss: 0.31326336\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32065272560486424\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [287/500, 0/38] loss: 0.31328481\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32194960355758667\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [41/500, 0/150] loss: 0.31327319\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206457541539119\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [288/500, 0/38] loss: 0.31328529\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32055703493265003\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [289/500, 0/38] loss: 0.31328028\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [41/500, 100/150] loss: 0.31326556\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:05 (running for 00:00:40.56)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320539 |     0.9925 |                  289 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321631 |     0.9925 |                   41 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205389449229607\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [290/500, 0/38] loss: 0.313288\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3216306924819946\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [42/500, 0/150] loss: 0.31326339\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053545117378235\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [291/500, 0/38] loss: 0.31328079\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-05\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 291\n",
      "  loss: 0.32053000651873076\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 36.150763750076294\n",
      "  time_this_iter_s: 0.10370254516601562\n",
      "  time_total_s: 36.150763750076294\n",
      "  timestamp: 1660748405\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 291\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053000651873076\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [292/500, 0/38] loss: 0.3132664\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [42/500, 100/150] loss: 0.31328672\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052871584892273\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [293/500, 0/38] loss: 0.31328094\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.321844961643219\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [43/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052996296149033\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [294/500, 0/38] loss: 0.31327552\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205640040911161\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [295/500, 0/38] loss: 0.31327686\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [43/500, 100/150] loss: 0.31326893\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205285370349884\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [296/500, 0/38] loss: 0.31328312\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3214355802536011\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [44/500, 0/150] loss: 0.31326386\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32060526884519136\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [297/500, 0/38] loss: 0.31327099\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3230903698847844\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [298/500, 0/38] loss: 0.31328389\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [44/500, 100/150] loss: 0.31326666\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320536182476924\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [299/500, 0/38] loss: 0.31328192\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3215671133995056\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [45/500, 0/150] loss: 0.31326696\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052863102692825\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [300/500, 0/38] loss: 0.31328723\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320530137190452\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [301/500, 0/38] loss: 0.31327561\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [45/500, 100/150] loss: 0.31326759\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054519194823045\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [302/500, 0/38] loss: 0.31328422\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32216841220855713\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [46/500, 0/150] loss: 0.31329891\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320528323833759\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [303/500, 0/38] loss: 0.31329587\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32072290778160095\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [304/500, 0/38] loss: 0.31327522\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [46/500, 100/150] loss: 0.31326854\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-07\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 46\n",
      "  loss: 0.32153730511665346\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 16.01649785041809\n",
      "  time_this_iter_s: 0.3200042247772217\n",
      "  time_total_s: 16.01649785041809\n",
      "  timestamp: 1660748407\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 46\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32061453736745393\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [305/500, 0/38] loss: 0.31327319\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32153730511665346\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [47/500, 0/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052849577023435\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [306/500, 0/38] loss: 0.31327257\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32081358249370867\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [307/500, 0/38] loss: 0.31328052\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053303489318263\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [47/500, 100/150] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [308/500, 0/38] loss: 0.31326821\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210828464764815\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32198085069656374\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [48/500, 0/150] loss: 0.31327048\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [309/500, 0/38] loss: 0.31328508\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3218989991224729\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [310/500, 0/38] loss: 0.31326905\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052934628266555\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [48/500, 100/150] loss: 0.313263\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [311/500, 0/38] loss: 0.31328157\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207538907344525\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32182998418807984\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [49/500, 0/150] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [312/500, 0/38] loss: 0.31328207\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052897260739255\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [313/500, 0/38] loss: 0.31327927\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205283421736497\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [49/500, 100/150] loss: 0.31326261\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [314/500, 0/38] loss: 0.3132875\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3209566130087926\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.321798740029335\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [50/500, 0/150] loss: 0.31326777\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [315/500, 0/38] loss: 0.31327745\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205471749489124\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [316/500, 0/38] loss: 0.31327027\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054534554481506\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [317/500, 0/38] loss: 0.31328753\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [50/500, 100/150] loss: 0.31326509\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054372704946077\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [318/500, 0/38] loss: 0.31326744\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3215301024913788\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [51/500, 0/150] loss: 0.31326747\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205289703149062\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [319/500, 0/38] loss: 0.31328046\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207618502470163\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [320/500, 0/38] loss: 0.31328049\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [51/500, 100/150] loss: 0.31326467\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205324067519261\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [321/500, 0/38] loss: 0.31327567\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32191194117069244\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205283834384038\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [322/500, 0/38] loss: 0.31327716\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [52/500, 0/150] loss: 0.31326556\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32212144365677464\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [323/500, 0/38] loss: 0.31330565\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [52/500, 100/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297222504249\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [324/500, 0/38] loss: 0.31327015\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320538546030338\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [325/500, 0/38] loss: 0.31328115\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213387852907181\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [53/500, 0/150] loss: 0.31326327\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207611693785741\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [326/500, 0/38] loss: 0.31328171\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [53/500, 100/150] loss: 0.31326249\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205288304732396\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [327/500, 0/38] loss: 0.31329229\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32062541292263913\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [328/500, 0/38] loss: 0.31329229\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32175444066524506\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [54/500, 0/150] loss: 0.31326395\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205611270207625\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [329/500, 0/38] loss: 0.3132796\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [54/500, 100/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297360053429\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [330/500, 0/38] loss: 0.31327325\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052885110561663\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [331/500, 0/38] loss: 0.31330308\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32210037171840666\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [55/500, 0/150] loss: 0.31327417\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205364805001479\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [332/500, 0/38] loss: 0.3132787\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053051315821135\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [333/500, 0/38] loss: 0.31327483\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [55/500, 100/150] loss: 0.3132627\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205299973487854\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [334/500, 0/38] loss: 0.31327903\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32191411435604095\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [56/500, 0/150] loss: 0.3132638\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32076196716381955\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [335/500, 0/38] loss: 0.31329238\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054357803784883\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [336/500, 0/38] loss: 0.31328717\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [56/500, 100/150] loss: 0.31326255\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207645255785722\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [337/500, 0/38] loss: 0.31328091\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32150392651557924\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [57/500, 0/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205332182920896\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [338/500, 0/38] loss: 0.31328776\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:10 (running for 00:00:45.65)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216813619320209 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.322833 |     0.9925 |                  338 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321504 |     0.9925 |                   56 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32283294888643116\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [339/500, 0/38] loss: 0.31328619\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [57/500, 100/150] loss: 0.31326386\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-10\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 339\n",
      "  loss: 0.32283877638670117\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 41.18391251564026\n",
      "  time_this_iter_s: 0.11077523231506348\n",
      "  time_total_s: 41.18391251564026\n",
      "  timestamp: 1660748410\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 339\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32283877638670117\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [340/500, 0/38] loss: 0.31328136\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3214773070812225\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [58/500, 0/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207646837601295\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [341/500, 0/38] loss: 0.31327394\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053423615602344\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [342/500, 0/38] loss: 0.31327692\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [58/500, 100/150] loss: 0.31326285\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054394712814915\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [343/500, 0/38] loss: 0.31327704\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053102667515093\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [344/500, 0/38] loss: 0.31328064\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32146471679210664\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [59/500, 0/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207598351515256\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [345/500, 0/38] loss: 0.31328285\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [59/500, 100/150] loss: 0.31326506\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32076494510357195\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [346/500, 0/38] loss: 0.31329849\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32063741179612965\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [347/500, 0/38] loss: 0.31329232\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32137439012527463\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [60/500, 0/150] loss: 0.31326494\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297222504249\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [348/500, 0/38] loss: 0.31327835\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205297589302063\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [349/500, 0/38] loss: 0.31328699\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [60/500, 100/150] loss: 0.31326395\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32061490645775426\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [350/500, 0/38] loss: 0.31328145\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3215734165906906\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [61/500, 0/150] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052911244905913\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [351/500, 0/38] loss: 0.31327286\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205539630009578\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [352/500, 0/38] loss: 0.31326616\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [61/500, 100/150] loss: 0.313263\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3219124193374927\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [353/500, 0/38] loss: 0.31326464\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213862085342407\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [62/500, 0/150] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32128153626735395\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [354/500, 0/38] loss: 0.31329834\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205285622523381\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [355/500, 0/38] loss: 0.31328437\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [62/500, 100/150] loss: 0.31326342\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-12\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 62\n",
      "  loss: 0.3214064699411392\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 21.310381650924683\n",
      "  time_this_iter_s: 0.33643341064453125\n",
      "  time_total_s: 21.310381650924683\n",
      "  timestamp: 1660748412\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 62\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205281679446881\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [356/500, 0/38] loss: 0.31328654\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3214064699411392\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [63/500, 0/150] loss: 0.31326464\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32058279330913836\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [357/500, 0/38] loss: 0.31327942\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320540393774326\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [358/500, 0/38] loss: 0.31328982\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [63/500, 100/150] loss: 0.31326255\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052987813949585\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [359/500, 0/38] loss: 0.31327817\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3210997647047043\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053645757528454\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [360/500, 0/38] loss: 0.31328496\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [64/500, 0/150] loss: 0.31326321\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205306025651785\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [361/500, 0/38] loss: 0.31328493\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [64/500, 100/150] loss: 0.31326261\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205355520431812\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [362/500, 0/38] loss: 0.31327447\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205405588333423\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [363/500, 0/38] loss: 0.31327686\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3215651273727417\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [65/500, 0/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205529772318326\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [364/500, 0/38] loss: 0.31328902\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [65/500, 100/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053455251913804\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [365/500, 0/38] loss: 0.31327364\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053004319851214\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [366/500, 0/38] loss: 0.31327826\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212441468238831\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [66/500, 0/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207553510482495\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [367/500, 0/38] loss: 0.31328255\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [66/500, 100/150] loss: 0.31326267\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053060027269215\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [368/500, 0/38] loss: 0.31328216\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32140096843242644\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [67/500, 0/150] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32119107017150295\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [369/500, 0/38] loss: 0.31329253\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [67/500, 100/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205546851341541\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [370/500, 0/38] loss: 0.31328368\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053738832473755\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [371/500, 0/38] loss: 0.31328946\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32218522250652315\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [68/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205284017782945\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [372/500, 0/38] loss: 0.3132925\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [68/500, 100/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205288235957806\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [373/500, 0/38] loss: 0.31328684\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3209487016384418\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [374/500, 0/38] loss: 0.31328377\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3215513825416565\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [69/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053199181189906\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [375/500, 0/38] loss: 0.3132892\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [69/500, 100/150] loss: 0.31326315\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210810858469743\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [376/500, 0/38] loss: 0.31327844\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054529052514297\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [377/500, 0/38] loss: 0.31329459\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212739443778992\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [70/500, 0/150] loss: 0.31326279\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205389449229607\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [378/500, 0/38] loss: 0.31328127\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205292889705071\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [379/500, 0/38] loss: 0.31326759\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [70/500, 100/150] loss: 0.31326273\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32075300124975353\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [380/500, 0/38] loss: 0.31329161\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3214095836877823\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [71/500, 0/150] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052929126299345\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [381/500, 0/38] loss: 0.31327304\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205640476483565\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [382/500, 0/38] loss: 0.31329277\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [71/500, 100/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053162501408505\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [383/500, 0/38] loss: 0.31328356\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32075350559674776\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32158623039722445\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [72/500, 0/150] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [384/500, 0/38] loss: 0.31327957\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205321797957787\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [385/500, 0/38] loss: 0.31326988\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [72/500, 100/150] loss: 0.31326258\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:15 (running for 00:00:50.69)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320532 |     0.9925 |                  384 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321207 |     0.9925 |                   72 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205374272970053\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [386/500, 0/38] loss: 0.3132723\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.321207377910614\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [73/500, 0/150] loss: 0.31326222\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-15\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 386\n",
      "  loss: 0.3205290986941411\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 46.21915817260742\n",
      "  time_this_iter_s: 0.10437560081481934\n",
      "  time_total_s: 46.21915817260742\n",
      "  timestamp: 1660748415\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 386\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205290986941411\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [387/500, 0/38] loss: 0.31327951\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205367143337543\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [388/500, 0/38] loss: 0.31328019\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [73/500, 100/150] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3228334830357478\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [389/500, 0/38] loss: 0.31327406\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32142930626869204\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [74/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205298391672281\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [390/500, 0/38] loss: 0.31328344\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205319941043854\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [391/500, 0/38] loss: 0.31329221\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [74/500, 100/150] loss: 0.31326273\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205683964949388\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [392/500, 0/38] loss: 0.31327236\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3211813348531723\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [75/500, 0/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320528119802475\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [393/500, 0/38] loss: 0.31327897\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205769337140597\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [394/500, 0/38] loss: 0.3132807\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [75/500, 100/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32072841662627\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [395/500, 0/38] loss: 0.31326783\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212603324651718\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [76/500, 0/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3207883101243239\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [396/500, 0/38] loss: 0.31329876\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052833758867705\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [397/500, 0/38] loss: 0.31329814\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [76/500, 100/150] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205281037550706\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [398/500, 0/38] loss: 0.31328791\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213132464885712\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [77/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205281908695514\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [399/500, 0/38] loss: 0.31329238\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053056130042445\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [400/500, 0/38] loss: 0.31327796\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [77/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32073078476465666\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [401/500, 0/38] loss: 0.31327915\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212735390663147\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205289290501521\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [402/500, 0/38] loss: 0.31328559\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [78/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205446211191324\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [403/500, 0/38] loss: 0.31327936\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [78/500, 100/150] loss: 0.31326243\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205723166465759\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [404/500, 0/38] loss: 0.31327754\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32131375968456266Result for traindata_2f206_00003:\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-17\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 78\n",
      "  loss: 0.32131375968456266\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 26.514336585998535\n",
      "  time_this_iter_s: 0.32125115394592285\n",
      "  time_total_s: 26.514336585998535\n",
      "  timestamp: 1660748417\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 78\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205315080972818\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [405/500, 0/38] loss: 0.31327516\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [79/500, 0/150] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205276681826665\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [406/500, 0/38] loss: 0.3132849\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [79/500, 100/150] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205275329259726\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [407/500, 0/38] loss: 0.31327388\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213146185874939\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32058414358359116\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [408/500, 0/38] loss: 0.3132807\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [80/500, 0/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205282435967372\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [409/500, 0/38] loss: 0.31329179\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205637037754059\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [80/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [410/500, 0/38] loss: 0.31327108\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32056503800245434\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32133733689785005\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [411/500, 0/38] loss: 0.31327233\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052810604755694\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [81/500, 0/150] loss: 0.31326345\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [412/500, 0/38] loss: 0.31327572\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205309877028832\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [81/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [413/500, 0/38] loss: 0.3132813\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205365790770604\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [414/500, 0/38] loss: 0.31327939\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32283814824544466\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212586134672165\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [415/500, 0/38] loss: 0.31327111\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32056356164125294\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [416/500, 0/38] loss: 0.31328276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205274503964644\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [417/500, 0/38] loss: 0.3132689\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32190306599323565\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [418/500, 0/38] loss: 0.31329191\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3221202836586879\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [419/500, 0/38] loss: 0.31327277\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052902304209197\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [82/500, 0/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [420/500, 0/38] loss: 0.31328723\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32080135207909805\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [82/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [421/500, 0/38] loss: 0.31327274\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053443560233486\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [422/500, 0/38] loss: 0.31328332\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205346694359413\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [423/500, 0/38] loss: 0.31328389\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213057714700699\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [83/500, 0/150] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053688856271595\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [424/500, 0/38] loss: 0.31328458\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205359371808859\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [425/500, 0/38] loss: 0.31327486\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [83/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052796391340405\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [426/500, 0/38] loss: 0.31327152\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32126233041286467\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [84/500, 0/150] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32189709635881275\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [427/500, 0/38] loss: 0.3132714\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32189698631946856\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [428/500, 0/38] loss: 0.31326824\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [84/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32075267800917995\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [429/500, 0/38] loss: 0.31327888\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213347953557968\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [85/500, 0/150] loss: 0.31326249\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205278699214642\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [430/500, 0/38] loss: 0.31328934\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206466000813704\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [431/500, 0/38] loss: 0.3132861\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [85/500, 100/150] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052718905302197\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [432/500, 0/38] loss: 0.31328321\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213509702682495\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [86/500, 0/150] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210868308177361\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [433/500, 0/38] loss: 0.31327844\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:20 (running for 00:00:55.70)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320536 |     0.9925 |                  433 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321351 |     0.9925 |                   85 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320536154967088\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [434/500, 0/38] loss: 0.31327546\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [86/500, 100/150] loss: 0.31326216\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-20\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 434\n",
      "  loss: 0.3205330967903137\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 51.22985076904297\n",
      "  time_this_iter_s: 0.111328125\n",
      "  time_total_s: 51.22985076904297\n",
      "  timestamp: 1660748420\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 434\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205330967903137\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [435/500, 0/38] loss: 0.31327882\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3225040848438556\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [436/500, 0/38] loss: 0.31327561\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32134968519210816\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [87/500, 0/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32090463088108945\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [437/500, 0/38] loss: 0.31327164\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205312146590306\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [438/500, 0/38] loss: 0.31329143\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [87/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32076284289360046\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [439/500, 0/38] loss: 0.31330398\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32133745968341826\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3222940747554486\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [440/500, 0/38] loss: 0.31329694\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [88/500, 0/150] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32315373649963963\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [441/500, 0/38] loss: 0.31327659\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205357767068423\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [442/500, 0/38] loss: 0.31327438\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [88/500, 100/150] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3210838666329017\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [443/500, 0/38] loss: 0.31327921\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213272303342819\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [89/500, 0/150] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205339771050673\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [444/500, 0/38] loss: 0.31329781\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205354672211867\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [445/500, 0/38] loss: 0.31327975\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [89/500, 100/150] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205295961636763\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [446/500, 0/38] loss: 0.31328389\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205418311632596\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [447/500, 0/38] loss: 0.31327501\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213229846954346\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [90/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205335827974173\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [448/500, 0/38] loss: 0.31327441\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205638046448047\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [449/500, 0/38] loss: 0.31328222\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [90/500, 100/150] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052942422720104\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [450/500, 0/38] loss: 0.31327689\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052746644386876\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [451/500, 0/38] loss: 0.31327438\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32132733225822446\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [91/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052799142324007\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [452/500, 0/38] loss: 0.31326786\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052835592856777\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [453/500, 0/38] loss: 0.31327361\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [91/500, 100/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053523568006664\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [454/500, 0/38] loss: 0.31327584\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32131448209285735\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-22\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 91\n",
      "  loss: 0.32131448209285735\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 31.704716444015503\n",
      "  time_this_iter_s: 0.40067577362060547\n",
      "  time_total_s: 31.704716444015503\n",
      "  timestamp: 1660748422\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 91\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052945173703706\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [455/500, 0/38] loss: 0.31327915\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [92/500, 0/150] loss: 0.31326285\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052911015657276\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [456/500, 0/38] loss: 0.31329054\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32060797627155596\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [457/500, 0/38] loss: 0.31327677\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [92/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053911915192235\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [458/500, 0/38] loss: 0.3132818\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213169056177139\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [93/500, 0/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320528669999196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [459/500, 0/38] loss: 0.31328085\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205359876155853\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [460/500, 0/38] loss: 0.31327274\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [93/500, 100/150] loss: 0.313263\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054140246831453\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [461/500, 0/38] loss: 0.31328124\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205298070724194\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [462/500, 0/38] loss: 0.3132908\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130702257156374\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [94/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205272945073935\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [463/500, 0/38] loss: 0.31328052\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205351371031541\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [464/500, 0/38] loss: 0.31327593\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [94/500, 100/150] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053616872200597\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [465/500, 0/38] loss: 0.31326953\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205276865225572\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [466/500, 0/38] loss: 0.31329855\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213072991371155\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [95/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3236729410978464\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [467/500, 0/38] loss: 0.31328869\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205284269956442\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [468/500, 0/38] loss: 0.3132821\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [95/500, 100/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205948999294868\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [469/500, 0/38] loss: 0.31328481\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205280235180488\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [470/500, 0/38] loss: 0.31326896\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212909400463104\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [96/500, 0/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3213354211587172\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [471/500, 0/38] loss: 0.31327808\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205273953767923\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [472/500, 0/38] loss: 0.31329086\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [96/500, 100/150] loss: 0.31326261\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32072672706383926\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [473/500, 0/38] loss: 0.3132773\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213068962097168\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [97/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32057860035162705\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [474/500, 0/38] loss: 0.31329364\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053166169386643\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [475/500, 0/38] loss: 0.31328332\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [97/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205807896760794\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [476/500, 0/38] loss: 0.31327882\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206131343658154\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [477/500, 0/38] loss: 0.31329742\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213062536716461\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [98/500, 0/150] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32066285380950343\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [478/500, 0/38] loss: 0.31330571\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205265723741971\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [479/500, 0/38] loss: 0.31327718\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [98/500, 100/150] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205309464381291\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [480/500, 0/38] loss: 0.31327683\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130445301532745\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32054537305465114\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [481/500, 0/38] loss: 0.31327274\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [99/500, 0/150] loss: 0.31326228\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:25 (running for 00:01:00.76)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (11 PENDING, 2 RUNNING, 2 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | RUNNING    | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320534 |     0.9925 |                  481 | 0.985111 |\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321304 |     0.9925 |                   98 | 0.98501  |\n",
      "| traindata_2f206_00004 | PENDING    |                        |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053359425984895\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [482/500, 0/38] loss: 0.31327832\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-25\n",
      "  done: false\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 482\n",
      "  loss: 0.3205342407409961\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 56.29356122016907\n",
      "  time_this_iter_s: 0.11139273643493652\n",
      "  time_total_s: 56.29356122016907\n",
      "  timestamp: 1660748425\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 482\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205342407409961\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [483/500, 0/38] loss: 0.31327489\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [99/500, 100/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32230132588973415\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [484/500, 0/38] loss: 0.31327331\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130571603775027\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [100/500, 0/150] loss: 0.31326267\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052634541804975\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [485/500, 0/38] loss: 0.31327987\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320541833455746\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [486/500, 0/38] loss: 0.31327125\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [100/500, 100/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3224005401134491\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [487/500, 0/38] loss: 0.3132844\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130429208278655\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [101/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205262285012465\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [488/500, 0/38] loss: 0.31327808\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.320534898684575\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [489/500, 0/38] loss: 0.31328845\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [101/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206511162794553\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [490/500, 0/38] loss: 0.31329036\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213041305541992\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3228459381140195\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [491/500, 0/38] loss: 0.31327131\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [102/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32053115276189953\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [492/500, 0/38] loss: 0.31328738\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [102/500, 100/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32052616889660174\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [493/500, 0/38] loss: 0.31327686\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32189869422179\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [494/500, 0/38] loss: 0.31329542\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130364418029783\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [103/500, 0/150] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3206800612119528\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [495/500, 0/38] loss: 0.31327155\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [103/500, 100/150] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32103729706544143\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [496/500, 0/38] loss: 0.31329072\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205689856639275\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [497/500, 0/38] loss: 0.31327349\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213034933805466\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [104/500, 0/150] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205384566233708\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [498/500, 0/38] loss: 0.31329718\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32068525827847993\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [499/500, 0/38] loss: 0.31327471\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [104/500, 100/150] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.32190743547219497\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m [500/500, 0/38] loss: 0.31328577\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213029891252518\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [105/500, 0/150] loss: 0.31326193\n",
      "Result for traindata_2f206_00000:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-27\n",
      "  done: true\n",
      "  experiment_id: eb87ed09742440a1af4158ebc534f380\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 500\n",
      "  loss: 0.3205354053240556\n",
      "  mcc: 0.9851108312031162\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3931827\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.20078086853027\n",
      "  time_this_iter_s: 0.10422086715698242\n",
      "  time_total_s: 58.20078086853027\n",
      "  timestamp: 1660748427\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 500\n",
      "  trial_id: 2f206_00000\n",
      "  warmup_time: 0.003675699234008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m The Current Loss: 0.3205354053240556\n",
      "\u001b[2m\u001b[36m(func pid=3931827)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [105/500, 100/150] loss: 0.31326199\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-28\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 105\n",
      "  loss: 0.32130116581916807\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 36.844499826431274\n",
      "  time_this_iter_s: 0.3309593200683594\n",
      "  time_total_s: 36.844499826431274\n",
      "  timestamp: 1660748428\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 105\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130116581916807\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [106/500, 0/150] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [106/500, 100/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3212984263896942\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [107/500, 0/150] loss: 0.31326288\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [107/500, 100/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130235612392427\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [108/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [108/500, 100/150] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213021504878998\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [109/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [109/500, 100/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130200624465943\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [110/500, 0/150] loss: 0.31326249\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [110/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.321301965713501\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [111/500, 0/150] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [111/500, 100/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130134999752047\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [112/500, 0/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [112/500, 100/150] loss: 0.31326267\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130186319351195\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [113/500, 0/150] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [113/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130130887031555\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [114/500, 0/150] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [114/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213012856245041\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:31 (running for 00:01:05.97)\n",
      "Memory usage on this node: 90.7/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.5868336225243715\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (10 PENDING, 2 RUNNING, 3 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  114 | 0.98501  |\n",
      "| traindata_2f206_00004 | RUNNING    | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   |          |            |                      |          |\n",
      "| traindata_2f206_00005 | PENDING    |                        |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [115/500, 0/150] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [115/500, 100/150] loss: 0.3132619\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-33\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 115\n",
      "  loss: 0.32130114555358885\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.43229818344116\n",
      "  time_this_iter_s: 2.597268581390381\n",
      "  time_total_s: 42.43229818344116\n",
      "  timestamp: 1660748433\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 115\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130114555358885\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [116/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [116/500, 100/150] loss: 0.31326243\n",
      "\u001b[2m\u001b[36m(func pid=3933151)\u001b[0m [1/500, 0/75] loss: 0.67366892\n",
      "Result for traindata_2f206_00004:\n",
      "  accuracy: 0.7975\n",
      "  date: 2022-08-17_16-00-33\n",
      "  done: true\n",
      "  experiment_id: 6b2143a1ec6c436483d748346bcb684a\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6708784818649292\n",
      "  mcc: 0.6018897602811472\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933151\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6307995319366455\n",
      "  time_this_iter_s: 0.6307995319366455\n",
      "  time_total_s: 0.6307995319366455\n",
      "  timestamp: 1660748433\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00004\n",
      "  warmup_time: 0.003902435302734375\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213005667924881\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [117/500, 0/150] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933151)\u001b[0m The Current Loss: 0.6708784818649292\n",
      "\u001b[2m\u001b[36m(func pid=3933151)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [117/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213006180524826\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [118/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [118/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213010269403458\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [119/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [119/500, 100/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213010162115097\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [120/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [120/500, 100/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213010323047638\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [121/500, 0/150] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [121/500, 100/150] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213010185956955\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [122/500, 0/150] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [122/500, 100/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130097508430483\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [123/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [123/500, 100/150] loss: 0.31326249\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213009661436081\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:36 (running for 00:01:11.30)\n",
      "Memory usage on this node: 90.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.6337895806019123\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (9 PENDING, 2 RUNNING, 4 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00003 | RUNNING    | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  123 | 0.98501  |\n",
      "| traindata_2f206_00005 | RUNNING    | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  |          |            |                      |          |\n",
      "| traindata_2f206_00006 | PENDING    |                        |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | PENDING    |                        |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [124/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [124/500, 100/150] loss: 0.31326196\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-39\n",
      "  done: false\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 124\n",
      "  loss: 0.32130094289779665\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 48.42118430137634\n",
      "  time_this_iter_s: 3.2621710300445557\n",
      "  time_total_s: 48.42118430137634\n",
      "  timestamp: 1660748439\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 124\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130094289779665\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [125/500, 0/150] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933287)\u001b[0m [1/500, 0/150] loss: 0.740282\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [125/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933287)\u001b[0m [1/500, 100/150] loss: 0.68908316\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.3213009560108185\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [126/500, 0/150] loss: 0.31326225\n",
      "Result for traindata_2f206_00005:\n",
      "  accuracy: 0.515\n",
      "  date: 2022-08-17_16-00-40\n",
      "  done: true\n",
      "  experiment_id: ac06fe1c47934fe1afc253b980715bee\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6849408125877381\n",
      "  mcc: 0.08824300313883983\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933287\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6857128143310547\n",
      "  time_this_iter_s: 0.6857128143310547\n",
      "  time_total_s: 0.6857128143310547\n",
      "  timestamp: 1660748440\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00005\n",
      "  warmup_time: 0.0038983821868896484\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933287)\u001b[0m The Current Loss: 0.6849408125877381\n",
      "\u001b[2m\u001b[36m(func pid=3933287)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [126/500, 100/150] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130090177059173\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [127/500, 0/150] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [127/500, 100/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130091965198515\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [128/500, 0/150] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m [128/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00003:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-00-40\n",
      "  done: true\n",
      "  experiment_id: e06db0d8c6434640a8c6e8e79ec600b5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 128\n",
      "  loss: 0.32130091965198515\n",
      "  mcc: 0.9850100660598952\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3932223\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 49.721484899520874\n",
      "  time_this_iter_s: 0.32651257514953613\n",
      "  time_total_s: 49.721484899520874\n",
      "  timestamp: 1660748440\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 128\n",
      "  trial_id: 2f206_00003\n",
      "  warmup_time: 0.0038690567016601562\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m The Current Loss: 0.32130091965198515\n",
      "\u001b[2m\u001b[36m(func pid=3932223)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [1/500, 0/75] loss: 0.67838752\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.38644643425941466\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:42 (running for 00:01:17.70)\n",
      "Memory usage on this node: 88.8/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=6\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.42899625301361083 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (7 PENDING, 2 RUNNING, 6 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  |          |            |                      |          |\n",
      "| traindata_2f206_00007 | RUNNING    | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 |          |            |                      |          |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.925\n",
      "  date: 2022-08-17_16-00-45\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.38644643425941466\n",
      "  mcc: 0.8564048343012224\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5281059741973877\n",
      "  time_this_iter_s: 0.5281059741973877\n",
      "  time_total_s: 0.5281059741973877\n",
      "  timestamp: 1660748445\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [2/500, 0/75] loss: 0.42802602\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.341545889377594\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [3/500, 0/75] loss: 0.37690109\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.33834433794021607\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [4/500, 0/75] loss: 0.31337431\n",
      "\u001b[2m\u001b[36m(func pid=3933423)\u001b[0m [1/500, 0/38] loss: 0.68934417\n",
      "Result for traindata_2f206_00007:\n",
      "  accuracy: 0.4925\n",
      "  date: 2022-08-17_16-00-47\n",
      "  done: true\n",
      "  experiment_id: 1079dac156f941f6b8b28a8e83127dc8\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.693847853403825\n",
      "  mcc: 0.0\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933423\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.4767336845397949\n",
      "  time_this_iter_s: 0.4767336845397949\n",
      "  time_total_s: 0.4767336845397949\n",
      "  timestamp: 1660748447\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00007\n",
      "  warmup_time: 0.0038635730743408203\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:47 (running for 00:01:22.73)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.3230125511151094 | Iter 16.000: -0.3352227004674765 | Iter 8.000: -0.34589595258235933 | Iter 4.000: -0.3658917301893234 | Iter 2.000: -0.39181416571140293 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (7 PENDING, 2 RUNNING, 6 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.338344 |     0.97   |                    3 | 0.941207 |\n",
      "| traindata_2f206_00007 | RUNNING    | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | PENDING    |                        |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933423)\u001b[0m The Current Loss: 0.693847853403825\n",
      "\u001b[2m\u001b[36m(func pid=3933423)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3196658670902252\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [5/500, 0/75] loss: 0.31351417\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3231245684623718\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [6/500, 0/75] loss: 0.31336054\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.319616014957428\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [7/500, 0/75] loss: 0.31330553\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31947951555252074\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [8/500, 0/75] loss: 0.31335053\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31941957712173463\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [9/500, 0/75] loss: 0.31326473\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.319235657453537\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [10/500, 0/75] loss: 0.31329378\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31918301463127136\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [11/500, 0/75] loss: 0.31327569\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31913188576698304\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [12/500, 0/75] loss: 0.3132633\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31914293885231015\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [13/500, 0/75] loss: 0.31326556\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31908098340034485\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [14/500, 0/75] loss: 0.31327471\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3190838003158569\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [15/500, 0/75] loss: 0.3132695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31905520796775816\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [16/500, 0/75] loss: 0.31327099\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3190491700172424\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [17/500, 0/75] loss: 0.31327426\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3190009415149689\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [18/500, 0/75] loss: 0.31326362\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3189455533027649\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [19/500, 0/75] loss: 0.31326661\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31893757462501526\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [20/500, 0/75] loss: 0.31327114\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3189601445198059\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [21/500, 0/75] loss: 0.31327647\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3189193844795227\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [22/500, 0/75] loss: 0.31326377\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3189055395126343\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [23/500, 0/75] loss: 0.3132664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31889763593673703\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [24/500, 0/75] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188804948329926\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [25/500, 0/75] loss: 0.31326443\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188776683807373\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [26/500, 0/75] loss: 0.31326321\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188796055316925\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [27/500, 0/75] loss: 0.31326821\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31886823415756227\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [28/500, 0/75] loss: 0.31326786\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31885043263435364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [29/500, 0/75] loss: 0.31326243\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188387441635132\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [30/500, 0/75] loss: 0.31326416\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-00-52\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 30\n",
      "  loss: 0.3188227140903473\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.213489532470703\n",
      "  time_this_iter_s: 0.1904916763305664\n",
      "  time_total_s: 7.213489532470703\n",
      "  timestamp: 1660748452\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 30\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188227140903473\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [31/500, 0/75] loss: 0.31326675\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188177835941315\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [32/500, 0/75] loss: 0.3757672\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187961435317993\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:52 (running for 00:01:27.81)\n",
      "Memory usage on this node: 92.1/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3292781735612796 | Iter 8.000: -0.3453116735816002 | Iter 4.000: -0.3608327549695969 | Iter 2.000: -0.39181416571140293 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (6 PENDING, 2 RUNNING, 7 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318796 |     0.995  |                   32 | 0.989998 |\n",
      "| traindata_2f206_00008 | RUNNING    | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00009 | PENDING    |                        |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [33/500, 0/75] loss: 0.31326485\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3188030767440796\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [34/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31879557967185973\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [35/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933523)\u001b[0m [1/500, 0/75] loss: 0.69649231\n",
      "Result for traindata_2f206_00008:\n",
      "  accuracy: 0.54\n",
      "  date: 2022-08-17_16-00-53\n",
      "  done: true\n",
      "  experiment_id: 9bdbcd15dcb64ca48c510bc756141f7f\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6770060205459595\n",
      "  mcc: 0.18696707506424096\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933523\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5599002838134766\n",
      "  time_this_iter_s: 0.5599002838134766\n",
      "  time_total_s: 0.5599002838134766\n",
      "  timestamp: 1660748453\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00008\n",
      "  warmup_time: 0.0037078857421875\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187883949279785\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [36/500, 0/75] loss: 0.31326526\n",
      "\u001b[2m\u001b[36m(func pid=3933523)\u001b[0m The Current Loss: 0.6770060205459595\n",
      "\u001b[2m\u001b[36m(func pid=3933523)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187793564796448\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [37/500, 0/75] loss: 0.31326339\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187821578979492\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [38/500, 0/75] loss: 0.31326318\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31877565264701846\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [39/500, 0/75] loss: 0.31326386\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31875607252120974\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [40/500, 0/75] loss: 0.31326398\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31875781655311586\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [41/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31876572728157043\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [42/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187565267086029\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [43/500, 0/75] loss: 0.31326398\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187372040748596\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [44/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31873035430908203\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [45/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187300741672516\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [46/500, 0/75] loss: 0.31326622\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187334203720093\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [47/500, 0/75] loss: 0.31326446\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187235057353973\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [48/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31871426701545713\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [49/500, 0/75] loss: 0.31326377\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3187248861789703\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [50/500, 0/75] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31871310114860535\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [51/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31871828317642215\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [52/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186993336677551\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [53/500, 0/75] loss: 0.31326473\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31870236992836\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [54/500, 0/75] loss: 0.31326306\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186980545520782\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [55/500, 0/75] loss: 0.31326315\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186880445480347\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [56/500, 0/75] loss: 0.31326395\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186809742450714\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [57/500, 0/75] loss: 0.31326276\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-00-57\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 57\n",
      "  loss: 0.3186769211292267\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.398419380187988\n",
      "  time_this_iter_s: 0.18949055671691895\n",
      "  time_total_s: 12.398419380187988\n",
      "  timestamp: 1660748457\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 57\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186769211292267\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [58/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186794853210449\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [59/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186738777160645\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:00:58 (running for 00:01:32.98)\n",
      "Memory usage on this node: 91.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3216232446523813 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3292781735612796 | Iter 8.000: -0.3453116735816002 | Iter 4.000: -0.3608327549695969 | Iter 2.000: -0.39181416571140293 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (5 PENDING, 2 RUNNING, 8 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318674 |     0.995  |                   59 | 0.989998 |\n",
      "| traindata_2f206_00009 | RUNNING    | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 |          |            |                      |          |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [60/500, 0/75] loss: 0.31326243\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31867490530014037\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [61/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31867299795150755\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [62/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [1/500, 0/150] loss: 0.68898034\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186690926551819\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [63/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [1/500, 100/150] loss: 0.52779633\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31867385387420655\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.4979471242427826\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00009:\n",
      "  accuracy: 0.8275\n",
      "  date: 2022-08-17_16-01-00\n",
      "  done: false\n",
      "  experiment_id: ee502829a8ba43c3b78c90e667ef1d8b\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.4979471242427826\n",
      "  mcc: 0.6824536680489807\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933632\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7098147869110107\n",
      "  time_this_iter_s: 0.7098147869110107\n",
      "  time_total_s: 0.7098147869110107\n",
      "  timestamp: 1660748460\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00009\n",
      "  warmup_time: 0.0035848617553710938\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [64/500, 0/75] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [2/500, 0/150] loss: 0.54928958\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31865538835525514\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [65/500, 0/75] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [2/500, 100/150] loss: 0.56930006\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186586534976959\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [66/500, 0/75] loss: 0.3132627\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3880224198102951\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [3/500, 0/150] loss: 0.35905948\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31865242004394534\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [3/500, 100/150] loss: 0.38402584\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [67/500, 0/75] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31865452527999877\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [68/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3550905805826187\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [4/500, 0/150] loss: 0.32053831\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [4/500, 100/150] loss: 0.35488534\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31864811658859254\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [69/500, 0/75] loss: 0.31326261\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186446499824524\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [70/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.34480741202831267\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [5/500, 0/150] loss: 0.31565803\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [5/500, 100/150] loss: 0.32043114\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31863592982292177\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [71/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.33939932644367216\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [6/500, 0/150] loss: 0.31778467\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31864399433135987\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [72/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [6/500, 100/150] loss: 0.3146638\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186356317996979\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [73/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.33591542541980746\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [7/500, 0/150] loss: 0.32379115\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186275744438171\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [74/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [7/500, 100/150] loss: 0.31354704\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186317765712738\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [75/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.35365145742893217\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [8/500, 0/150] loss: 0.32406104\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186245906352997\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [76/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [8/500, 100/150] loss: 0.31536555\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862412095069886\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [77/500, 0/75] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.33084432542324066\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [9/500, 0/150] loss: 0.31345934\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862515211105347\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [78/500, 0/75] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [9/500, 100/150] loss: 0.31353688\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624974489212\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [79/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.33006534576416013\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [10/500, 0/150] loss: 0.31497702\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-02\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 79\n",
      "  loss: 0.31862558245658873\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 17.494374990463257\n",
      "  time_this_iter_s: 0.17295145988464355\n",
      "  time_total_s: 17.494374990463257\n",
      "  timestamp: 1660748462\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 79\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862558245658873\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [80/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [10/500, 100/150] loss: 0.31365314\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3302014225721359\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [11/500, 0/150] loss: 0.31389642\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862573623657225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [81/500, 0/75] loss: 0.31326202\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:03 (running for 00:01:38.07)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3292781735612796 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (5 PENDING, 2 RUNNING, 8 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318625 |     0.995  |                   81 | 0.989998 |\n",
      "| traindata_2f206_00009 | RUNNING    | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.330201 |     0.9825 |                   10 | 0.96501  |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862472534179687\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [82/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [11/500, 100/150] loss: 0.31360418\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32866484224796294\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [12/500, 0/150] loss: 0.31529146\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862597465515136\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [83/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [12/500, 100/150] loss: 0.31356937\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186254560947418\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [84/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32896833956241606\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [13/500, 0/150] loss: 0.31343555\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244475841522\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [85/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [13/500, 100/150] loss: 0.31373921\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862581968307496\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [86/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3279634094238281\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [14/500, 0/150] loss: 0.31387889\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862414002418515\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [87/500, 0/75] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [14/500, 100/150] loss: 0.3135893\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862423300743103\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [88/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.327578729391098\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [15/500, 0/150] loss: 0.31331557\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186241662502289\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [89/500, 0/75] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [15/500, 100/150] loss: 0.31351694\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624165058136\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [90/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32728382825851443\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [16/500, 0/150] loss: 0.31330884\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186241614818573\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [91/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [16/500, 100/150] loss: 0.31372726\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3269789707660675\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [17/500, 0/150] loss: 0.31399038\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862411022186277\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [92/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862406849861147\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [93/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [17/500, 100/150] loss: 0.31345332\n",
      "Result for traindata_2f206_00009:\n",
      "  accuracy: 0.99\n",
      "  date: 2022-08-17_16-01-05\n",
      "  done: false\n",
      "  experiment_id: ee502829a8ba43c3b78c90e667ef1d8b\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 17\n",
      "  loss: 0.32678875386714934\n",
      "  mcc: 0.9800490036753062\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933632\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.889561653137207\n",
      "  time_this_iter_s: 0.32332420349121094\n",
      "  time_total_s: 5.889561653137207\n",
      "  timestamp: 1660748465\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 17\n",
      "  trial_id: 2f206_00009\n",
      "  warmup_time: 0.0035848617553710938\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32678875386714934\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186241018772125\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [94/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [18/500, 0/150] loss: 0.31360865\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186240160465241\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [18/500, 100/150] loss: 0.31342942\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [95/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32620088577270506\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862412810325624\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [96/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [19/500, 0/150] loss: 0.3135516\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [19/500, 100/150] loss: 0.3135539\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862414002418515\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [97/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3259702253341675\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [20/500, 0/150] loss: 0.31348619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [98/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [20/500, 100/150] loss: 0.31347066\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243748664856\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [99/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32576411187648774\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [21/500, 0/150] loss: 0.31347036\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243772506714\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [100/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [21/500, 100/150] loss: 0.31365526\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243677139282\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [101/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.33131646633148193\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [22/500, 0/150] loss: 0.3134293\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243677139282\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [102/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [22/500, 100/150] loss: 0.31342953\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862436413764955\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [103/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3384240275621414\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [23/500, 0/150] loss: 0.3139742\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243760585785\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [104/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [23/500, 100/150] loss: 0.31339586\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438082695005\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [105/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3249796724319458\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [24/500, 0/150] loss: 0.31326705\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438082695005\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [106/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [24/500, 100/150] loss: 0.31327307\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243748664856\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [107/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32631585955619813\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [25/500, 0/150] loss: 0.31327906\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243629455566\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [108/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [25/500, 100/150] loss: 0.31329706\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3246171146631241\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [26/500, 0/150] loss: 0.31339484\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-07\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 108\n",
      "  loss: 0.31862435817718504\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 22.569194793701172\n",
      "  time_this_iter_s: 0.1983795166015625\n",
      "  time_total_s: 22.569194793701172\n",
      "  timestamp: 1660748467\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 108\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862435817718504\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [109/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862436056137083\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [110/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [26/500, 100/150] loss: 0.31340328\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3241936057806015\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:08 (running for 00:01:43.08)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.32105705048029237 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (5 PENDING, 2 RUNNING, 8 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  109 | 0.989998 |\n",
      "| traindata_2f206_00009 | RUNNING    | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.324194 |     0.9925 |                   26 | 0.985112 |\n",
      "| traindata_2f206_00010 | PENDING    |                        |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862436890602114\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [111/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [27/500, 0/150] loss: 0.3132745\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [27/500, 100/150] loss: 0.3133609\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862436890602114\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [112/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243772506714\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [113/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.3241724693775177\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [28/500, 0/150] loss: 0.31348535\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [28/500, 100/150] loss: 0.31326613\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243724822998\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [114/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.323753827214241\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [29/500, 0/150] loss: 0.31335801\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624370098114\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [115/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [29/500, 100/150] loss: 0.31340244\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243760585785\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [116/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32345715939998626\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [30/500, 0/150] loss: 0.31331125\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438082695005\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [117/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624382019043\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [30/500, 100/150] loss: 0.3132689\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [118/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32346185863018034\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [31/500, 0/150] loss: 0.3133336\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [119/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [31/500, 100/150] loss: 0.31335777\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 5\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [120/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32344073712825777\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [32/500, 0/150] loss: 0.31339115\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624382019043\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [121/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m [32/500, 100/150] loss: 0.31326455\n",
      "Result for traindata_2f206_00009:\n",
      "  accuracy: 0.9925\n",
      "  date: 2022-08-17_16-01-10\n",
      "  done: true\n",
      "  experiment_id: ee502829a8ba43c3b78c90e667ef1d8b\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 32\n",
      "  loss: 0.32321406781673434\n",
      "  mcc: 0.9851115701658352\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933632\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.841515064239502\n",
      "  time_this_iter_s: 0.33420538902282715\n",
      "  time_total_s: 10.841515064239502\n",
      "  timestamp: 1660748470\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 32\n",
      "  trial_id: 2f206_00009\n",
      "  warmup_time: 0.0035848617553710938\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [122/500, 0/75] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m The Current Loss: 0.32321406781673434\n",
      "\u001b[2m\u001b[36m(func pid=3933632)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [123/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [124/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [125/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [126/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [127/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438440322877\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [128/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439393997194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [129/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [130/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [131/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243796348572\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [132/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [133/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [134/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624382019043\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [135/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [136/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [137/500, 0/75] loss: 0.31326169\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-12\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 137\n",
      "  loss: 0.31862438797950743\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 27.58850932121277\n",
      "  time_this_iter_s: 0.1733231544494629\n",
      "  time_total_s: 27.58850932121277\n",
      "  timestamp: 1660748472\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 137\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [138/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [139/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:13 (running for 00:01:48.16)\n",
      "Memory usage on this node: 91.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6523340312334207\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (4 PENDING, 2 RUNNING, 9 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  139 | 0.989998 |\n",
      "| traindata_2f206_00010 | RUNNING    | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00011 | PENDING    |                        |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [140/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438440322877\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [141/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [142/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [143/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933939)\u001b[0m [1/500, 0/75] loss: 0.69144946\n",
      "Result for traindata_2f206_00010:\n",
      "  accuracy: 0.665\n",
      "  date: 2022-08-17_16-01-15\n",
      "  done: true\n",
      "  experiment_id: e1d39c7d21af4ca7a307e706666a8950\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6823769402503967\n",
      "  mcc: 0.36088818178897286\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933939\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6237921714782715\n",
      "  time_this_iter_s: 0.6237921714782715\n",
      "  time_total_s: 0.6237921714782715\n",
      "  timestamp: 1660748475\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00010\n",
      "  warmup_time: 0.0044193267822265625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933939)\u001b[0m The Current Loss: 0.6823769402503967\n",
      "\u001b[2m\u001b[36m(func pid=3933939)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439393997194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [144/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [145/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [146/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [147/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [148/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [149/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [150/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [151/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [152/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [153/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [154/500, 0/75] loss: 0.31326261\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [155/500, 0/75] loss: 0.37576166\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-18\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 155\n",
      "  loss: 0.31862439393997194\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 32.74511361122131\n",
      "  time_this_iter_s: 0.19373774528503418\n",
      "  time_total_s: 32.74511361122131\n",
      "  timestamp: 1660748478\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 155\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439393997194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [156/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [157/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:18 (running for 00:01:53.30)\n",
      "Memory usage on this node: 90.8/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (3 PENDING, 2 RUNNING, 10 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  157 | 0.989998 |\n",
      "| traindata_2f206_00011 | RUNNING    | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  |          |            |                      |          |\n",
      "| traindata_2f206_00012 | PENDING    |                        |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [158/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [159/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [160/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934072)\u001b[0m [1/500, 0/75] loss: 0.69089395\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00011:\n",
      "  accuracy: 0.495\n",
      "  date: 2022-08-17_16-01-21\n",
      "  done: true\n",
      "  experiment_id: 8dae70a7ec2f4efa94faccd577452da5\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.8182617497444152\n",
      "  mcc: 0.0\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934072\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5485138893127441\n",
      "  time_this_iter_s: 0.5485138893127441\n",
      "  time_total_s: 0.5485138893127441\n",
      "  timestamp: 1660748481\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00011\n",
      "  warmup_time: 0.0033195018768310547\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [161/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934072)\u001b[0m The Current Loss: 0.8182617497444152\n",
      "\u001b[2m\u001b[36m(func pid=3934072)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438321113584\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [162/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [163/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [164/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [165/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [166/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438440322877\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [167/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [168/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [169/500, 0/75] loss: 0.31326213\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-23\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 169\n",
      "  loss: 0.31862438678741456\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 37.89649963378906\n",
      "  time_this_iter_s: 0.170393705368042\n",
      "  time_total_s: 37.89649963378906\n",
      "  timestamp: 1660748483\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 169\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [170/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [171/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:23 (running for 00:01:58.46)\n",
      "Memory usage on this node: 90.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6739422512054443\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 PENDING, 2 RUNNING, 11 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  171 | 0.989998 |\n",
      "| traindata_2f206_00012 | RUNNING    | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00013 | PENDING    |                        |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [172/500, 0/75] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [173/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [174/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934157)\u001b[0m [1/500, 0/150] loss: 0.67718554\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438082695005\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [175/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934157)\u001b[0m [1/500, 100/150] loss: 0.66563106\n",
      "Result for traindata_2f206_00012:\n",
      "  accuracy: 0.515\n",
      "  date: 2022-08-17_16-01-26\n",
      "  done: true\n",
      "  experiment_id: 137e10c08dcc4b8cbe1ef9f1216e57f0\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6802591121196747\n",
      "  mcc: 0.08824300313883983\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934157\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6765584945678711\n",
      "  time_this_iter_s: 0.6765584945678711\n",
      "  time_total_s: 0.6765584945678711\n",
      "  timestamp: 1660748486\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00012\n",
      "  warmup_time: 0.003431558609008789\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [176/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934157)\u001b[0m The Current Loss: 0.6802591121196747\n",
      "\u001b[2m\u001b[36m(func pid=3934157)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [177/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [178/500, 0/75] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [179/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [180/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [181/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [182/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [183/500, 0/75] loss: 0.31326181\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-28\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 183\n",
      "  loss: 0.3186243999004364\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.96335315704346\n",
      "  time_this_iter_s: 0.17350220680236816\n",
      "  time_total_s: 42.96335315704346\n",
      "  timestamp: 1660748488\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 183\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243999004364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [184/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [185/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:28 (running for 00:02:03.54)\n",
      "Memory usage on this node: 91.0/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=12\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6770060205459595\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 PENDING, 2 RUNNING, 12 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  185 | 0.989998 |\n",
      "| traindata_2f206_00013 | RUNNING    | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 |          |            |                      |          |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [186/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [187/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [188/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438440322877\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m [1/500, 0/75] loss: 0.68796259\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [189/500, 0/75] loss: 0.31326205\n",
      "Result for traindata_2f206_00013:\n",
      "  accuracy: 0.535\n",
      "  date: 2022-08-17_16-01-32\n",
      "  done: false\n",
      "  experiment_id: 0f6fc83a869f43abb643b00d4cf1def1\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6645839476585388\n",
      "  mcc: 0.19647891728167047\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934261\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.617652416229248\n",
      "  time_this_iter_s: 0.617652416229248\n",
      "  time_total_s: 0.617652416229248\n",
      "  timestamp: 1660748492\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00013\n",
      "  warmup_time: 0.003692150115966797\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m The Current Loss: 0.6645839476585388\n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m [2/500, 0/75] loss: 0.68111908\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [190/500, 0/75] loss: 0.31326219\n",
      "Result for traindata_2f206_00013:\n",
      "  accuracy: 0.635\n",
      "  date: 2022-08-17_16-01-33\n",
      "  done: true\n",
      "  experiment_id: 0f6fc83a869f43abb643b00d4cf1def1\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6261396408081055\n",
      "  mcc: 0.38804963604607257\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934261\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7999439239501953\n",
      "  time_this_iter_s: 0.18229150772094727\n",
      "  time_total_s: 0.7999439239501953\n",
      "  timestamp: 1660748493\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 2f206_00013\n",
      "  warmup_time: 0.003692150115966797\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m The Current Loss: 0.6261396408081055\n",
      "\u001b[2m\u001b[36m(func pid=3934261)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [191/500, 0/75] loss: 0.31326166\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-33\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 191\n",
      "  loss: 0.318624392747879\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 48.027474880218506\n",
      "  time_this_iter_s: 0.1855309009552002\n",
      "  time_total_s: 48.027474880218506\n",
      "  timestamp: 1660748493\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 191\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [192/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [193/500, 0/75] loss: 0.31326196\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:33 (running for 00:02:08.63)\n",
      "Memory usage on this node: 90.7/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.408509336411953 | Iter 1.000: -0.6739422512054443\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 PENDING, 1 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  193 | 0.989998 |\n",
      "| traindata_2f206_00014 | PENDING    |                        |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [194/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [195/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [196/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [197/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [198/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [199/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [200/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [201/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [202/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [203/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [204/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [205/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [206/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [207/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [208/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [209/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [210/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624382019043\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [211/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439393997194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [212/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [213/500, 0/75] loss: 0.31326258\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [214/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [215/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [216/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [217/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [218/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438559532164\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [219/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [220/500, 0/75] loss: 0.31326222\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-38\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 220\n",
      "  loss: 0.3186243951320648\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 53.12860321998596\n",
      "  time_this_iter_s: 0.17338228225708008\n",
      "  time_total_s: 53.12860321998596\n",
      "  timestamp: 1660748498\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 220\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [221/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [222/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [1/500, 0/150] loss: 0.69365674\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:38 (running for 00:02:13.70)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.34472739458084106 | Iter 4.000: -0.3557737797498703 | Iter 2.000: -0.408509336411953 | Iter 1.000: -0.6739422512054443\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  222 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 |          |            |                      |          |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [223/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [1/500, 100/150] loss: 0.39394668\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.9575\n",
      "  date: 2022-08-17_16-01-39\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.3880030298233032\n",
      "  mcc: 0.915256502325232\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7718656063079834\n",
      "  time_this_iter_s: 0.7718656063079834\n",
      "  time_total_s: 0.7718656063079834\n",
      "  timestamp: 1660748499\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [224/500, 0/75] loss: 0.31326216\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3880030298233032\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [2/500, 0/150] loss: 0.4975951\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [225/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [2/500, 100/150] loss: 0.32734817\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [226/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3631923866271973\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [3/500, 0/150] loss: 0.36709976\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [227/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [3/500, 100/150] loss: 0.42293867\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [228/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.33224187672138217\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [4/500, 0/150] loss: 0.31430644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [229/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [4/500, 100/150] loss: 0.3141554\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [230/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32978655815124513\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [5/500, 0/150] loss: 0.31432837\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [5/500, 100/150] loss: 0.31347615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [231/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [232/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32571832716465\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [6/500, 0/150] loss: 0.31393403\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [6/500, 100/150] loss: 0.31533647\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438797950743\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [233/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439155578615\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3244891506433487\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [7/500, 0/150] loss: 0.31364217\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [234/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [235/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [7/500, 100/150] loss: 0.31473225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [236/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3245051342248917\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [8/500, 0/150] loss: 0.31356585\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [237/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [8/500, 100/150] loss: 0.31362465\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438678741456\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [238/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [239/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32564359188079833\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [9/500, 0/150] loss: 0.31354365\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243951320648\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [240/500, 0/75] loss: 0.31326264\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [9/500, 100/150] loss: 0.31338432\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32306579887866976\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [241/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [10/500, 0/150] loss: 0.31384698\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [242/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [10/500, 100/150] loss: 0.31389788\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862438917160035\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [243/500, 0/75] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32250142872333526\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [11/500, 0/150] loss: 0.31328008\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439632415773\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [244/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [11/500, 100/150] loss: 0.31338194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [245/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862439393997194\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [246/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.322434663772583\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [12/500, 0/150] loss: 0.31352481\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624392747879\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [247/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [12/500, 100/150] loss: 0.31334558\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [248/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.32210156381130217\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [13/500, 0/150] loss: 0.31349277\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [249/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [13/500, 100/150] loss: 0.31332248\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243903636932\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [250/500, 0/75] loss: 0.31326178\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-43\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 250\n",
      "  loss: 0.3186243999004364\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.25939869880676\n",
      "  time_this_iter_s: 0.1700725555419922\n",
      "  time_total_s: 58.25939869880676\n",
      "  timestamp: 1660748503\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 250\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243999004364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.34558006763458254\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [14/500, 0/150] loss: 0.31338084\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [251/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244070529938\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [252/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [14/500, 100/150] loss: 0.31342059\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:43 (running for 00:02:18.82)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.32053314264004046 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3269789707660675 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  251 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.32066  |     0.995  |                   14 | 0.990048 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243999004364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [253/500, 0/75] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3206604504585266\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [15/500, 0/150] loss: 0.31339821\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [254/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [15/500, 100/150] loss: 0.31334019\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [255/500, 0/75] loss: 0.31326202\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-44\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 15\n",
      "  loss: 0.3199175465106964\n",
      "  mcc: 0.9900495037128093\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.0950398445129395\n",
      "  time_this_iter_s: 0.42972517013549805\n",
      "  time_total_s: 6.0950398445129395\n",
      "  timestamp: 1660748504\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 15\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3199175465106964\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [16/500, 0/150] loss: 0.31328967\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [256/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [257/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [16/500, 100/150] loss: 0.31379646\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244022846222\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [258/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3195202827453613\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [17/500, 0/150] loss: 0.31335658\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440943717957\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 5\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [259/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [17/500, 100/150] loss: 0.3133283\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [260/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3195787477493286\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [18/500, 0/150] loss: 0.31337157\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [261/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [262/500, 0/75] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [18/500, 100/150] loss: 0.31327039\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3195468205213547\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [263/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [19/500, 0/150] loss: 0.3132737\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440943717957\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [264/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [19/500, 100/150] loss: 0.31327653\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244070529938\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [265/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31946499943733214\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [20/500, 0/150] loss: 0.31341106\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [266/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [267/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [20/500, 100/150] loss: 0.31327718\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.319440593123436\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [21/500, 0/150] loss: 0.3134042\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244034767151\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [268/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [269/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [21/500, 100/150] loss: 0.31333622\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [270/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.319411798119545\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [22/500, 0/150] loss: 0.31335655\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244058609009\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [271/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243987083435\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [22/500, 100/150] loss: 0.31333339\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [272/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3193878591060638\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [23/500, 0/150] loss: 0.31326786\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [273/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [23/500, 100/150] loss: 0.31327236\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441062927244\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [274/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244034767151\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [275/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.319408221244812\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [24/500, 0/150] loss: 0.31326473\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244058609009\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [276/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [24/500, 100/150] loss: 0.31326619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [277/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31926555693149566\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [25/500, 0/150] loss: 0.31327266\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243975162506\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [278/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [25/500, 100/150] loss: 0.31328458\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441062927244\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [279/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.319254075884819\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [26/500, 0/150] loss: 0.31326312\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-48\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 279\n",
      "  loss: 0.3186243999004364\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.31006622314453\n",
      "  time_this_iter_s: 0.17507076263427734\n",
      "  time_total_s: 63.31006622314453\n",
      "  timestamp: 1660748508\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 279\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243999004364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [280/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [26/500, 100/150] loss: 0.31326804\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [281/500, 0/75] loss: 0.31326196\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:48 (running for 00:02:23.83)\n",
      "Memory usage on this node: 92.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.3225881889462471 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  280 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.31915  |     0.9925 |                   26 | 0.985012 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [282/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3191504979133606\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [27/500, 0/150] loss: 0.31327617\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244058609009\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [283/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [27/500, 100/150] loss: 0.31328326\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244022846222\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [284/500, 0/75] loss: 0.31326258\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31911999106407163\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [28/500, 0/150] loss: 0.31326544\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [285/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [28/500, 100/150] loss: 0.31330907\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-49\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 28\n",
      "  loss: 0.31912717640399935\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 11.469220399856567\n",
      "  time_this_iter_s: 0.38771796226501465\n",
      "  time_total_s: 11.469220399856567\n",
      "  timestamp: 1660748509\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 28\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186243999004364\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [286/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31912717640399935\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [29/500, 0/150] loss: 0.31328699\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244034767151\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [287/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [29/500, 100/150] loss: 0.31329188\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244058609009\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [288/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.319082470536232\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [30/500, 0/150] loss: 0.31326351\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624415397644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [289/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [30/500, 100/150] loss: 0.31327021\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244070529938\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [290/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31897239506244657\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [31/500, 0/150] loss: 0.31326616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [291/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [31/500, 100/150] loss: 0.31326532\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [292/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3189299613237381\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [32/500, 0/150] loss: 0.31328559\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441301345823\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [293/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [32/500, 100/150] loss: 0.31328216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [294/500, 0/75] loss: 0.37576178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31884957730770114\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [33/500, 0/150] loss: 0.31326419\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440943717957\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [295/500, 0/75] loss: 0.31326237\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [33/500, 100/150] loss: 0.31326464\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [296/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31882657051086427\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [34/500, 0/150] loss: 0.31326407\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [297/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [34/500, 100/150] loss: 0.31328255\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3187689006328583\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [35/500, 0/150] loss: 0.31328315\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [298/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862440824508664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [299/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [35/500, 100/150] loss: 0.31326991\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3187405502796173\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [36/500, 0/150] loss: 0.31326413\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441062927244\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [300/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [36/500, 100/150] loss: 0.31326479\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441420555115\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [301/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [302/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31874017596244814\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [37/500, 0/150] loss: 0.31326345\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [37/500, 100/150] loss: 0.31326395\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [303/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.318685507774353\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [38/500, 0/150] loss: 0.31328207\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441301345823\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [304/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [38/500, 100/150] loss: 0.31326613\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [305/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3186573499441147\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [39/500, 0/150] loss: 0.31326765\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [306/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [307/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [39/500, 100/150] loss: 0.31326646\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31854499876499176\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [40/500, 0/150] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624415397644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [308/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [40/500, 100/150] loss: 0.31326234\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-53\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 308\n",
      "  loss: 0.31862441658973695\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 68.36505508422852\n",
      "  time_this_iter_s: 0.1735379695892334\n",
      "  time_total_s: 68.36505508422852\n",
      "  timestamp: 1660748513\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 308\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [309/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31853388726711274\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [41/500, 0/150] loss: 0.31326476\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [310/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [41/500, 100/150] loss: 0.3132658\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:54 (running for 00:02:28.94)\n",
      "Memory usage on this node: 92.5/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  310 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.318534 |     0.995  |                   40 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [311/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31849122285842896\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [42/500, 0/150] loss: 0.31326309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862442135810853\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [312/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [42/500, 100/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441420555115\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [313/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31846828818321227\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [43/500, 0/150] loss: 0.31326255\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [314/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [43/500, 100/150] loss: 0.31326517\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-54\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 43\n",
      "  loss: 0.3184069633483887\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 16.47959041595459\n",
      "  time_this_iter_s: 0.32845258712768555\n",
      "  time_total_s: 16.47959041595459\n",
      "  timestamp: 1660748514\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 43\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [315/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3184069633483887\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [44/500, 0/150] loss: 0.31326297\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [316/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [44/500, 100/150] loss: 0.31326473\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31836917996406555\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [45/500, 0/150] loss: 0.31326702\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441301345823\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [317/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624404668808\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [318/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [45/500, 100/150] loss: 0.31326458\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31838419258594514\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [46/500, 0/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624415397644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [319/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244070529938\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [46/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [320/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3183001488447189\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [47/500, 0/150] loss: 0.31326514\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [321/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [47/500, 100/150] loss: 0.31326306\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244070529938\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [322/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3182873886823654\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [48/500, 0/150] loss: 0.31326681\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441301345823\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [323/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [48/500, 100/150] loss: 0.31326354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624415397644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [324/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31820154309272763\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [49/500, 0/150] loss: 0.31327254\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [325/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [49/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [326/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3182203906774521\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [50/500, 0/150] loss: 0.31326404\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [327/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [50/500, 100/150] loss: 0.31326404\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [328/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31815807402133944\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [51/500, 0/150] loss: 0.31326392\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [329/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [51/500, 100/150] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3181974357366562\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [330/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [52/500, 0/150] loss: 0.31326559\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [331/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [52/500, 100/150] loss: 0.31326416\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3181015622615814\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441897392274\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [332/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [53/500, 0/150] loss: 0.31326449\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [333/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [53/500, 100/150] loss: 0.31326708\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [334/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3180959939956665\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [54/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [54/500, 100/150] loss: 0.31326479\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [335/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441897392274\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [336/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3180396568775177\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [55/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [337/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [55/500, 100/150] loss: 0.3132638\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31801902115345\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [56/500, 0/150] loss: 0.31326187\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-01-58\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 337\n",
      "  loss: 0.31862442135810853\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 73.43547582626343\n",
      "  time_this_iter_s: 0.17564082145690918\n",
      "  time_total_s: 73.43547582626343\n",
      "  timestamp: 1660748518\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 337\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862442135810853\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [338/500, 0/75] loss: 0.31326255\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [339/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [56/500, 100/150] loss: 0.3132658\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:01:59 (running for 00:02:33.95)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3215651273727417 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  338 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.317971 |     0.995  |                   56 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3179713332653046\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [57/500, 0/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624415397644\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [340/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [57/500, 100/150] loss: 0.31326491\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [341/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31795023679733275\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244261264801\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [342/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [58/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [58/500, 100/150] loss: 0.31326422\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [343/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m 0.3179220497608185\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [59/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [344/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [59/500, 100/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441420555115\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [345/500, 0/75] loss: 0.31326208\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-00\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 59\n",
      "  loss: 0.31789205014705657\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 21.78721022605896\n",
      "  time_this_iter_s: 0.32529449462890625\n",
      "  time_total_s: 21.78721022605896\n",
      "  timestamp: 1660748520\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 59\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31789205014705657\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [60/500, 0/150] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244201660156\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [346/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [60/500, 100/150] loss: 0.31326288\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244177818298\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [347/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31788512885570525\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [61/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [348/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [349/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [61/500, 100/150] loss: 0.31326327\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31785150587558747\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [62/500, 0/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862442135810853\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [350/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [62/500, 100/150] loss: 0.31326306\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244261264801\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [351/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31779961824417113\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [63/500, 0/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441658973695\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [352/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [63/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [353/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3178002274036407\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [64/500, 0/150] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244332790375\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [354/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [64/500, 100/150] loss: 0.31326619\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [355/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31782459020614623\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [65/500, 0/150] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [356/500, 0/75] loss: 0.31326264\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [65/500, 100/150] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [357/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31774441301822665\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [66/500, 0/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244237422943\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [358/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [66/500, 100/150] loss: 0.31326276\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3177459442615509\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244225502014\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [67/500, 0/150] loss: 0.31326306\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [359/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862442135810853\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [360/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [67/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3177258789539337\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [361/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [68/500, 0/150] loss: 0.31326309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862441182136536\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [362/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [68/500, 100/150] loss: 0.3132638\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [363/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31772623777389525\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [69/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [69/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244261264801\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [364/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [365/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31771251738071443\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [70/500, 0/150] loss: 0.31326258\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [70/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624427318573\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [366/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31768216490745543\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [71/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [367/500, 0/75] loss: 0.31326175\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-03\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 367\n",
      "  loss: 0.3186244297027588\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 78.59783458709717\n",
      "  time_this_iter_s: 0.17190980911254883\n",
      "  time_total_s: 78.59783458709717\n",
      "  timestamp: 1660748523\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 367\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [368/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [71/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3176569890975952\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [72/500, 0/150] loss: 0.31326273\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:04 (running for 00:02:39.00)\n",
      "Memory usage on this node: 93.0/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  368 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.317657 |     0.995  |                   71 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244261264801\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [369/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244332790375\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [370/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [72/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3175733506679535\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [73/500, 0/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [371/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [73/500, 100/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443685531616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [372/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.317607199549675\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [74/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244237422943\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [373/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [74/500, 100/150] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [374/500, 0/75] loss: 0.31326234\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.317579385638237\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244308948517\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [75/500, 0/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [375/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [75/500, 100/150] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244356632233\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [376/500, 0/75] loss: 0.31326175\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-05\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 75\n",
      "  loss: 0.3175583851337433\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 27.1081326007843\n",
      "  time_this_iter_s: 0.33081698417663574\n",
      "  time_total_s: 27.1081326007843\n",
      "  timestamp: 1660748525\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 75\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3175583851337433\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [76/500, 0/150] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244249343872\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [377/500, 0/75] loss: 0.31326249\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [76/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [378/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.317538201212883\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [77/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [379/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [77/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443447113037\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [380/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3175318670272827\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [78/500, 0/150] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244404315948\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [381/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [78/500, 100/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244308948517\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [382/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3174699664115906\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [79/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [383/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [79/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624427318573\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [384/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31746466815471647\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [80/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244332790375\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [385/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [80/500, 100/150] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [386/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3174154496192932\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [81/500, 0/150] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443923950196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [387/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [81/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244285106659\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [388/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3174386984109879\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [82/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443447113037\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [389/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [82/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3174152010679245\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [83/500, 0/150] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443923950196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [390/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443685531616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [391/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [83/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.317433403134346\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [84/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244332790375\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [392/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244404315948\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [84/500, 100/150] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [393/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443685531616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31736966788768767\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [394/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [85/500, 0/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443685531616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [395/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [85/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244356632233\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [396/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3173940187692642\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [86/500, 0/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-08\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 396\n",
      "  loss: 0.31862444639205934\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 83.66557145118713\n",
      "  time_this_iter_s: 0.171980619430542\n",
      "  time_total_s: 83.66557145118713\n",
      "  timestamp: 1660748528\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 396\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444639205934\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [397/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [86/500, 100/150] loss: 0.31326187\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:09 (running for 00:02:44.07)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  397 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.317394 |     0.995  |                   85 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244428157806\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [398/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.317322256565094\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [87/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244356632233\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [399/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244297027588\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [87/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [400/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443447113037\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [401/500, 0/75] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31732347667217253\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [88/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443804740903\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [402/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [88/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244320869446\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [403/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31727528750896455\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [89/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443923950196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [404/500, 0/75] loss: 0.31326246\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [89/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3173087823390961\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [90/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444162368775\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [405/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444162368775\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [406/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [90/500, 100/150] loss: 0.31326172\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-10\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 90\n",
      "  loss: 0.31728593111038206\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 32.4042444229126\n",
      "  time_this_iter_s: 0.33315157890319824\n",
      "  time_total_s: 32.4042444229126\n",
      "  timestamp: 1660748530\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 90\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31728593111038206\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [91/500, 0/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443804740903\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [407/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443804740903\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [91/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [408/500, 0/75] loss: 0.31326225\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31730142176151277\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [92/500, 0/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444400787354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [409/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [92/500, 100/150] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244332790375\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [410/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31724517047405243\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [93/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244451999664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [411/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [93/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443685531616\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [412/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3172326761484146\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [94/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244356632233\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [413/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [94/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244428157806\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [414/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3172235453128815\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [95/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244404315948\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [415/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [95/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244451999664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3172388207912445\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [416/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [96/500, 0/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244451999664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [417/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [96/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3172296303510666\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444400787354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [418/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [97/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244404315948\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [419/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [97/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244428157806\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [420/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31718226671218874\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [98/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [98/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444162368775\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [421/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244451999664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [422/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171681523323059\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [99/500, 0/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [99/500, 100/150] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443447113037\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [423/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444639205934\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171724385023117\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [100/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [424/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443923950196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [425/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [100/500, 100/150] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171622264385223\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [101/500, 0/150] loss: 0.31326169\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-14\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 425\n",
      "  loss: 0.31862444639205934\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 88.7006185054779\n",
      "  time_this_iter_s: 0.17435503005981445\n",
      "  time_total_s: 88.7006185054779\n",
      "  timestamp: 1660748534\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 425\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444639205934\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [426/500, 0/75] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:14 (running for 00:02:49.10)\n",
      "Memory usage on this node: 92.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  426 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.317162 |     0.995  |                  100 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [427/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [101/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171326446533203\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [102/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444400787354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [428/500, 0/75] loss: 0.31326252\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [102/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862443804740903\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [429/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31714131832122805\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [103/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624449968338\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [430/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [103/500, 100/150] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244559288025\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [431/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171659630537033\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444877624513\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [104/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [432/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [104/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244451999664\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [433/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31711903512477874\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [105/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [434/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444877624513\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [435/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [105/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3170934051275253\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [106/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244571208954\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [436/500, 0/75] loss: 0.31326208\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [106/500, 100/150] loss: 0.31326169\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-15\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 106\n",
      "  loss: 0.3171238613128662\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 37.72188353538513\n",
      "  time_this_iter_s: 0.3255481719970703\n",
      "  time_total_s: 37.72188353538513\n",
      "  timestamp: 1660748535\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 106\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444400787354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [437/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171238613128662\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [107/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [438/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [107/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244475841522\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [439/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31706223368644715\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [108/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244475841522\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [440/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [108/500, 100/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244511604309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [441/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3171377784013748\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [109/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444162368775\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [442/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [109/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444400787354\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [443/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3170465987920761\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [110/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [444/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [110/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244428157806\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [445/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3170725005865097\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [111/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244475841522\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [446/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [111/500, 100/150] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31704565525054934\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [447/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [112/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [448/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [112/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.318624449968338\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [449/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31698355853557586\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [113/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [113/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [450/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [451/500, 0/75] loss: 0.31326193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31697099924087524\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [114/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [114/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [452/500, 0/75] loss: 0.31326222\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31696575284004214\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [115/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [453/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [115/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [454/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169761824607849\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [116/500, 0/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-19\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 454\n",
      "  loss: 0.3186244523525238\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 93.74758672714233\n",
      "  time_this_iter_s: 0.17017459869384766\n",
      "  time_total_s: 93.74758672714233\n",
      "  timestamp: 1660748539\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 454\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [455/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [116/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:19 (running for 00:02:54.15)\n",
      "Memory usage on this node: 92.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.3208131813085996 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  455 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316976 |     0.995  |                  115 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862444639205934\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [456/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169919937849045\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [117/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [457/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [117/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244559288025\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [458/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3170242840051651\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [118/500, 0/150] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [459/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [118/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169435799121857\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [119/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [460/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [461/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [119/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31696115791797635\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [120/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244511604309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [462/500, 0/75] loss: 0.31326199\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [463/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [120/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169404131174087\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [121/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [464/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [121/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244559288025\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [465/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169513213634491\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [122/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [466/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [122/500, 100/150] loss: 0.31326169\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-21\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 122\n",
      "  loss: 0.31696798264980314\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 42.96403503417969\n",
      "  time_this_iter_s: 0.32864856719970703\n",
      "  time_total_s: 42.96403503417969\n",
      "  timestamp: 1660748541\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 122\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244571208954\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [467/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31696798264980314\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [123/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [468/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [123/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [469/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31690354883670807\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [124/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [470/500, 0/75] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [124/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [471/500, 0/75] loss: 0.31326202\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169535291194916\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [125/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244523525238\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [472/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [125/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244511604309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [473/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169177824258804\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [126/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244571208954\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [474/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [126/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244678497314\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [475/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31690934479236604\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [127/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446188926696\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [476/500, 0/75] loss: 0.3132624\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [127/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446188926696\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [477/500, 0/75] loss: 0.31326228\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31688363730907443\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [128/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [478/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [128/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [479/500, 0/75] loss: 0.31326181\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3169411104917526\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [129/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [480/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [129/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31685912668704985\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [130/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244535446167\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [481/500, 0/75] loss: 0.31326213\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446188926696\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [482/500, 0/75] loss: 0.3132619\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [130/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31687084555625916\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [131/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244511604309\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [483/500, 0/75] loss: 0.31326196\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [131/500, 100/150] loss: 0.31326169\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-24\n",
      "  done: false\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 483\n",
      "  loss: 0.3186244583129883\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 98.7771246433258\n",
      "  time_this_iter_s: 0.17305874824523926\n",
      "  time_total_s: 98.7771246433258\n",
      "  timestamp: 1660748544\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 483\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [484/500, 0/75] loss: 0.31326216\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3168659633398056\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:24 (running for 00:02:59.17)\n",
      "Memory usage on this node: 92.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=13\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 4.0/64 CPUs, 4.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (2 RUNNING, 13 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00006 | RUNNING    | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  484 | 0.989998 |\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316866 |     0.995  |                  131 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244678497314\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [485/500, 0/75] loss: 0.31326205\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [132/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [132/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244654655457\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [486/500, 0/75] loss: 0.313263\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [487/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31690082311630247\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [133/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [488/500, 0/75] loss: 0.31326231\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [133/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316875159740448\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [134/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244630813599\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [489/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446665763855\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [490/500, 0/75] loss: 0.31326187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [134/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3168713933229446\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [135/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446665763855\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [491/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [135/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244654655457\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [492/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31686886966228484\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [136/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244583129883\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [493/500, 0/75] loss: 0.31326172\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [136/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [494/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3168912237882614\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [137/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862446427345276\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [495/500, 0/75] loss: 0.31326178\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [137/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244571208954\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [496/500, 0/75] loss: 0.31326175\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3168640738725662\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [138/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244571208954\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [497/500, 0/75] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [138/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-26\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 138\n",
      "  loss: 0.31683306515216825\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 48.26483368873596\n",
      "  time_this_iter_s: 0.3258671760559082\n",
      "  time_total_s: 48.26483368873596\n",
      "  timestamp: 1660748546\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 138\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [498/500, 0/75] loss: 0.31326184\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31683306515216825\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [139/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.31862445950508117\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [499/500, 0/75] loss: 0.31326219\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [139/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244547367096\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m [500/500, 0/75] loss: 0.3132621\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31683449387550355\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [140/500, 0/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00006:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-27\n",
      "  done: true\n",
      "  experiment_id: 7cac16520aaf4c4c8b0777fab9923525\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 500\n",
      "  loss: 0.3186244606971741\n",
      "  mcc: 0.9899977494936361\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3933384\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 101.7056999206543\n",
      "  time_this_iter_s: 0.17305874824523926\n",
      "  time_total_s: 101.7056999206543\n",
      "  timestamp: 1660748547\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 500\n",
      "  trial_id: 2f206_00006\n",
      "  warmup_time: 0.00397491455078125\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m The Current Loss: 0.3186244606971741\n",
      "\u001b[2m\u001b[36m(func pid=3933384)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [140/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31681370973587036\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [141/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [141/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31683812618255613\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [142/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [142/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31680436730384826\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [143/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [143/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31682041108608244\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [144/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [144/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167888641357422\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [145/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [145/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31677406013011933\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [146/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [146/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:29 (running for 00:03:04.36)\n",
      "Memory usage on this node: 90.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316777 |     0.995  |                  146 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316776841878891\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [147/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [147/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316791233420372\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [148/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [148/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31677682101726534\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [149/500, 0/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [149/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167814368009567\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [150/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [150/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167929220199585\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [151/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [151/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167747575044632\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [152/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [152/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-31\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 152\n",
      "  loss: 0.3167490804195404\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 53.41407895088196\n",
      "  time_this_iter_s: 0.3426215648651123\n",
      "  time_total_s: 53.41407895088196\n",
      "  timestamp: 1660748551\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 152\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167490804195404\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [153/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [153/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31675087988376616\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [154/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [154/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31675556540489197\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [155/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [155/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31679800868034363\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [156/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [156/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167535102367401\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [157/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [157/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31675425589084627\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [158/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [158/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167505258321762\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [159/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [159/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167500710487366\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [160/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [160/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167514604330063\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [161/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [161/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:34 (running for 00:03:09.68)\n",
      "Memory usage on this node: 91.2/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316752 |     0.995  |                  161 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31675223529338836\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [162/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [162/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167467260360718\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [163/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [163/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167501360177994\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [164/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [164/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674783289432523\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [165/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [165/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674667179584504\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [166/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [166/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167480367422104\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [167/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [167/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-36\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 167\n",
      "  loss: 0.316746621131897\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 58.530168771743774\n",
      "  time_this_iter_s: 0.3277442455291748\n",
      "  time_total_s: 58.530168771743774\n",
      "  timestamp: 1660748556\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 167\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316746621131897\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [168/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [168/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167465329170227\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [169/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [169/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167463940382004\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [170/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [170/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167466926574707\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [171/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [171/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316746312379837\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [172/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [172/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167460185289383\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [173/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [173/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167463773488998\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [174/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [174/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167456513643265\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [175/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [175/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167457240819931\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [176/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [176/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674584209918977\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [177/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [177/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:40 (running for 00:03:14.99)\n",
      "Memory usage on this node: 91.1/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  177 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167454606294632\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [178/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [178/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167451453208923\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [179/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [179/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674513876438143\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [180/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [180/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674508571624754\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [181/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [181/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674510300159453\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [182/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [182/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167451047897339\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [183/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [183/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674504160881045\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-42\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 183\n",
      "  loss: 0.31674504160881045\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 63.8116569519043\n",
      "  time_this_iter_s: 0.33059024810791016\n",
      "  time_total_s: 63.8116569519043\n",
      "  timestamp: 1660748562\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 183\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [184/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [184/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167450201511383\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [185/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [185/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167450827360153\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [186/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [186/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167450112104416\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [187/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [187/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167450928688049\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [188/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [188/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488306045534\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [189/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [189/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493849277496\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [190/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [190/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449444532394\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [191/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [191/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449462413788\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [192/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [192/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494564533234\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [193/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [193/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:45 (running for 00:03:20.27)\n",
      "Memory usage on this node: 91.0/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  193 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744949221611\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [194/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [194/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449522018433\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [195/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [195/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744954586029\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [196/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [196/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449617385864\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 4\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [197/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [197/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449641227722\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 5\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [198/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [198/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674498319625854\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 6\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [199/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [199/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-47\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 199\n",
      "  loss: 0.31674498081207275\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 69.0955286026001\n",
      "  time_this_iter_s: 0.3259727954864502\n",
      "  time_total_s: 69.0955286026001\n",
      "  timestamp: 1660748567\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 199\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674498081207275\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [200/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [200/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449867725372\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [201/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [201/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449897527695\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [202/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [202/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449849843979\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [203/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [203/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674498558044434\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [204/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [204/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449849843979\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [205/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [205/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449867725372\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [206/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [206/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449849843979\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [207/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [207/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449814081192\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [208/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [208/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449861764908\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [209/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [209/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:50 (running for 00:03:25.58)\n",
      "Memory usage on this node: 90.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  209 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449796199799\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [210/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [210/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674498081207275\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [211/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [211/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449814081192\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [212/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [212/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449814081192\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [213/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [213/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449772357941\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [214/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [214/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449766397476\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [215/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [215/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-52\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 215\n",
      "  loss: 0.3167449766397476\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 74.4016706943512\n",
      "  time_this_iter_s: 0.3288600444793701\n",
      "  time_total_s: 74.4016706943512\n",
      "  timestamp: 1660748572\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 215\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449766397476\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [216/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [216/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674497604370117\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [217/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [217/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674498081207275\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [218/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [218/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449766397476\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [219/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [219/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674497604370117\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [220/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [220/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674497306346894\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [221/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [221/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674497365951537\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [222/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [222/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449724674225\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [223/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [223/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674497067928314\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [224/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [224/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449688911438\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [225/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [225/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:02:55 (running for 00:03:30.88)\n",
      "Memory usage on this node: 90.9/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  225 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449671030045\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [226/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [226/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496829509735\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [227/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [227/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496829509735\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [228/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [228/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449676990509\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [229/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [229/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744966506958\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [230/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [230/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496293067933\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [231/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [231/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-02-57\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 231\n",
      "  loss: 0.3167449647188187\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 79.69094276428223\n",
      "  time_this_iter_s: 0.3285794258117676\n",
      "  time_total_s: 79.69094276428223\n",
      "  timestamp: 1660748577\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 231\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449647188187\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [232/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [232/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449617385864\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [233/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [233/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449623346329\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [234/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [234/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496054649354\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [235/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [235/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449575662613\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [236/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [236/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496293067933\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [237/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [237/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674496114253997\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [238/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [238/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449599504471\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [239/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [239/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449575662613\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [240/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [240/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449593544006\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [241/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [241/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:01 (running for 00:03:36.22)\n",
      "Memory usage on this node: 91.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.319578770674192 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  241 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449587583542\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [242/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [242/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674495816230774\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [243/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [243/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449569702148\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [244/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [244/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449527978897\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [245/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [245/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449569702148\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [246/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [246/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-02\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 246\n",
      "  loss: 0.3167449539899826\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 84.72364234924316\n",
      "  time_this_iter_s: 0.32591867446899414\n",
      "  time_total_s: 84.72364234924316\n",
      "  timestamp: 1660748582\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 246\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449539899826\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [247/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [247/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449516057968\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [248/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [248/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449522018433\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [249/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [249/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449474334717\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [250/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [250/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449498176575\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [251/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [251/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449498176575\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [252/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [252/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494862556457\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [253/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [253/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494862556457\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [254/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [254/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449462413788\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [255/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [255/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494326114655\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [256/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [256/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494564533234\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [257/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [257/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:06 (running for 00:03:41.49)\n",
      "Memory usage on this node: 91.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  257 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744943857193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [258/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [258/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744943857193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [259/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [259/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674494326114655\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [260/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [260/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449426651001\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [261/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [261/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449420690536\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [262/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [262/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-08\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 262\n",
      "  loss: 0.3167449420690536\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 89.98958396911621\n",
      "  time_this_iter_s: 0.33092284202575684\n",
      "  time_total_s: 89.98958396911621\n",
      "  timestamp: 1660748588\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 262\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449420690536\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [263/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [263/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449402809143\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [264/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [264/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493789672853\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [265/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [265/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449390888214\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [266/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [266/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493610858917\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [267/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [267/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493789672853\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [268/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [268/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493968486783\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [269/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [269/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449373006821\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [270/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [270/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449349164963\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [271/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [271/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449343204498\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [272/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [272/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:11 (running for 00:03:46.54)\n",
      "Memory usage on this node: 91.2/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  272 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449313402176\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [273/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [273/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493312835694\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [274/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [274/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493074417115\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [275/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [275/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744931936264\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [276/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [276/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449313402176\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [277/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [277/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449289560318\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-13\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 277\n",
      "  loss: 0.3167449289560318\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 95.14118385314941\n",
      "  time_this_iter_s: 0.36550259590148926\n",
      "  time_total_s: 95.14118385314941\n",
      "  timestamp: 1660748593\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 277\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [278/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [278/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674493074417115\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [279/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [279/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492716789243\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [280/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [280/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744926571846\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [281/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [281/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744926571846\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [282/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [282/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492716789243\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [283/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [283/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492537975313\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [284/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [284/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492061138154\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [285/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [285/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449241876602\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [286/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [286/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492061138154\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [287/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [287/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492478370664\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:16 (running for 00:03:51.57)\n",
      "Memory usage on this node: 91.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  287 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [288/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [288/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492359161377\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [289/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [289/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492061138154\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [290/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [290/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449200153351\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [291/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [291/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674492299556734\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [292/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [292/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449164390564\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [293/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [293/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-18\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 293\n",
      "  loss: 0.3167449188232422\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 100.39487195014954\n",
      "  time_this_iter_s: 0.33101367950439453\n",
      "  time_total_s: 100.39487195014954\n",
      "  timestamp: 1660748598\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 293\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449188232422\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [294/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [294/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449176311493\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [295/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [295/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449164390564\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [296/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [296/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449152469635\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [297/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [297/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449128627777\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [298/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [298/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449170351028\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [299/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [299/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449128627777\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [300/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [300/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449140548706\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [301/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [301/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674491047859193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [302/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [302/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:21 (running for 00:03:56.61)\n",
      "Memory usage on this node: 91.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  302 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674491226673124\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [303/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [303/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674491047859193\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [304/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [304/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490988254544\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [305/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [305/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490809440614\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [306/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [306/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744909286499\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [307/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [307/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449063062668\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [308/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [308/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-23\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 308\n",
      "  loss: 0.3167449086904526\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 105.43136167526245\n",
      "  time_this_iter_s: 0.32483506202697754\n",
      "  time_total_s: 105.43136167526245\n",
      "  timestamp: 1660748603\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 308\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449086904526\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [309/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [309/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490571022035\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [310/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [310/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744903922081\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [311/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [311/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490332603455\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [312/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [312/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167449027299881\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [313/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [313/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490332603455\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [314/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [314/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490213394163\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [315/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [315/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674490332603455\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [316/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [316/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489736557004\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [317/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [317/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489855766297\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [318/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [318/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:27 (running for 00:04:01.92)\n",
      "Memory usage on this node: 91.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  318 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489736557004\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [319/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [319/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448967695236\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [320/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [320/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489855766297\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [321/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [321/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489557743074\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [322/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [322/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489498138425\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [323/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [323/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448961734772\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [324/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [324/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-29\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 324\n",
      "  loss: 0.3167448914051056\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 110.75987958908081\n",
      "  time_this_iter_s: 0.3303053379058838\n",
      "  time_total_s: 110.75987958908081\n",
      "  timestamp: 1660748609\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 324\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448914051056\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [325/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [325/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744892001152\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [326/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [326/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489319324495\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [327/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [327/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489080905915\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [328/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [328/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448925971985\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [329/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [329/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489080905915\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [330/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [330/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674489080905915\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [331/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [331/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488723278044\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [332/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [332/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488544464113\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [333/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [333/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488842487336\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [334/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [334/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:32 (running for 00:04:07.24)\n",
      "Memory usage on this node: 91.2/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  334 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488842487336\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [335/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [335/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744886636734\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [336/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [336/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488306045534\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [337/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [337/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488604068757\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [338/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [338/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488544464113\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [339/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [339/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488484859464\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [340/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [340/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-34\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 340\n",
      "  loss: 0.3167448836565018\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 116.05035591125488\n",
      "  time_this_iter_s: 0.32315850257873535\n",
      "  time_total_s: 116.05035591125488\n",
      "  timestamp: 1660748614\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 340\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448836565018\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [341/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [341/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488246440885\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [342/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [342/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448788881302\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [343/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [343/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488008022306\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [344/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [344/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488008022306\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [345/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [345/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487829208375\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [346/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [346/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448818683624\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [347/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [347/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448794841766\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [348/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [348/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674488008022306\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [349/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [349/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448765039444\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [350/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [350/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:37 (running for 00:04:12.51)\n",
      "Memory usage on this node: 91.2/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  350 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487292766573\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [351/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [351/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487471580504\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [352/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [352/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487292766573\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [353/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [353/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487233161924\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [354/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [354/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448711395264\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [355/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [355/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487233161924\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [356/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [356/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-39\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 356\n",
      "  loss: 0.31674487292766573\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 121.31600856781006\n",
      "  time_this_iter_s: 0.32636451721191406\n",
      "  time_total_s: 121.31600856781006\n",
      "  timestamp: 1660748619\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 356\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674487292766573\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [357/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [357/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486994743345\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [358/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [358/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448669672012\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [359/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [359/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448711395264\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [360/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [360/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448669672012\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [361/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [361/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486577510835\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [362/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [362/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448663711548\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [363/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [363/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486458301543\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [364/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [364/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486577510835\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [365/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [365/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:43 (running for 00:04:17.92)\n",
      "Memory usage on this node: 91.5/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  365 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486339092256\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [366/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [366/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448627948761\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [367/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [367/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486339092256\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [368/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [368/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486100673677\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [369/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [369/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-44\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 369\n",
      "  loss: 0.3167448592185974\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 126.40614295005798\n",
      "  time_this_iter_s: 0.40616536140441895\n",
      "  time_total_s: 126.40614295005798\n",
      "  timestamp: 1660748624\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 369\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448592185974\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [370/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [370/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674486041069033\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [371/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [371/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448616027832\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [372/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [372/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674485564231875\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [373/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [373/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448562383652\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [374/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [374/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448568344116\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [375/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [375/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674485802650454\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 3\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [376/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [376/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448568344116\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [377/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [377/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448568344116\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [378/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [378/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448538541794\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [379/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [379/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:48 (running for 00:04:23.04)\n",
      "Memory usage on this node: 91.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  379 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448514699936\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [380/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [380/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674485266208646\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [381/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [381/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674485027790067\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [382/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [382/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448514699936\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [383/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [383/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674485325813295\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [384/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [384/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-49\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 384\n",
      "  loss: 0.3167448514699936\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 131.52855968475342\n",
      "  time_this_iter_s: 0.3371148109436035\n",
      "  time_total_s: 131.52855968475342\n",
      "  timestamp: 1660748629\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 384\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448514699936\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [385/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [385/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448514699936\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [386/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [386/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674484968185423\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [387/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [387/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448514699936\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [388/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [388/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674484968185423\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [389/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [389/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744846701622\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [390/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [390/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744846701622\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [391/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [391/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674484491348265\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [392/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [392/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448461055756\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [393/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [393/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448443174362\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [394/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [394/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:53 (running for 00:04:28.15)\n",
      "Memory usage on this node: 91.3/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  394 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448395490646\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [395/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [395/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448389530182\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [396/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [396/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674484014511106\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [397/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [397/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744841337204\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [398/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [398/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448395490646\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [399/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [399/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483776092527\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-03-54\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 399\n",
      "  loss: 0.31674483776092527\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 136.6484603881836\n",
      "  time_this_iter_s: 0.3314664363861084\n",
      "  time_total_s: 136.6484603881836\n",
      "  timestamp: 1660748634\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 399\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [400/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [400/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674484014511106\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [401/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [401/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483776092527\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [402/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [402/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448318004608\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [403/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [403/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483358860017\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [404/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [404/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483835697176\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [405/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [405/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483239650725\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [406/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [406/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483239650725\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [407/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [407/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483358860017\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [408/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [408/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483299255374\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [409/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [409/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448312044144\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [410/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [410/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:03:58 (running for 00:04:33.41)\n",
      "Memory usage on this node: 91.7/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  410 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483299255374\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [411/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [411/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674483060836794\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [412/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [412/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482822418215\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [413/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [413/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482822418215\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [414/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [414/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448264360428\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [415/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [415/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-00\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 415\n",
      "  loss: 0.31674482762813566\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 141.87884068489075\n",
      "  time_this_iter_s: 0.32447218894958496\n",
      "  time_total_s: 141.87884068489075\n",
      "  timestamp: 1660748640\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 415\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482762813566\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [416/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [416/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482583999636\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [417/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [417/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744824051857\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [418/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [418/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482583999636\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [419/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [419/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744824051857\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [420/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [420/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481987953185\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [421/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [421/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482345581056\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [422/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [422/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481987953185\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [423/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [423/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448228597641\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [424/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [424/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482226371764\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [425/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [425/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482226371764\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [426/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [426/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:03 (running for 00:04:38.70)\n",
      "Memory usage on this node: 91.6/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  426 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482107162477\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [427/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [427/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674482107162477\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [428/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [428/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448204755783\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [429/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [429/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.316744818687439\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [430/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [430/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481809139254\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [431/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [431/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448163032532\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-05\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 431\n",
      "  loss: 0.3167448163032532\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 147.18766975402832\n",
      "  time_this_iter_s: 0.3270857334136963\n",
      "  time_total_s: 147.18766975402832\n",
      "  timestamp: 1660748645\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 431\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [432/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [432/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448163032532\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [433/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [433/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448168992996\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [434/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [434/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481511116026\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [435/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [435/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481511116026\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [436/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [436/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448115348816\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [437/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [437/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481332302096\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [438/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [438/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674481213092803\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [439/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [439/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448103427887\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [440/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [440/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448079586029\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [441/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [441/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480855464937\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [442/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [442/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:09 (running for 00:04:43.99)\n",
      "Memory usage on this node: 91.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  442 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448055744171\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [443/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [443/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448079586029\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [444/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [444/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480855464937\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [445/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [445/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480497837065\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [446/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [446/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480319023135\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [447/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [447/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-10\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 447\n",
      "  loss: 0.3167448055744171\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 152.4827446937561\n",
      "  time_this_iter_s: 0.32762575149536133\n",
      "  time_total_s: 152.4827446937561\n",
      "  timestamp: 1660748650\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 447\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448055744171\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [448/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [448/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448037862778\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [449/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [449/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480259418486\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [450/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [450/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167448019981384\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [451/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [451/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674480259418486\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [452/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [452/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447990179062\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [453/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [453/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674479961395263\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [454/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [454/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447978258133\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [455/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [455/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674479722976684\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [456/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [456/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674479842185976\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [457/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [457/500, 100/150] loss: 0.31326169\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:14 (running for 00:04:49.01)\n",
      "Memory usage on this node: 91.5/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  457 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447978258133\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [458/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [458/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674479484558105\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [459/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [459/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447936534882\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [460/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [460/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447930574417\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [461/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [461/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447918653488\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [462/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [462/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-15\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 462\n",
      "  loss: 0.3167447936534882\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 157.61927223205566\n",
      "  time_this_iter_s: 0.3417811393737793\n",
      "  time_total_s: 157.61927223205566\n",
      "  timestamp: 1660748655\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 462\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447936534882\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [463/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [463/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478828907016\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [464/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [464/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447888851166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [465/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [465/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447888851166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [466/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [466/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478769302367\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [467/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [467/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478769302367\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [468/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [468/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478828907016\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [469/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [469/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478590488436\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [470/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [470/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478769302367\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [471/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [471/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447853088379\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [472/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [472/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:19 (running for 00:04:54.22)\n",
      "Memory usage on this node: 93.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  472 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478232860565\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [473/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [473/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478352069857\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [474/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [474/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674478352069857\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [475/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [475/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447805404663\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [476/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [476/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447817325592\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [477/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [477/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-20\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 477\n",
      "  loss: 0.3167447817325592\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 162.7175350189209\n",
      "  time_this_iter_s: 0.32738351821899414\n",
      "  time_total_s: 162.7175350189209\n",
      "  timestamp: 1660748660\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 477\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447817325592\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [478/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [478/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447793483734\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [479/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [479/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447781562805\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [480/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [480/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674477994441985\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [481/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [481/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447763681412\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [482/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [482/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674477458000183\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [483/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [483/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447757720947\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [484/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [484/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447763681412\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [485/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [485/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674477517604827\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [486/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [486/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447763681412\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [487/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [487/500, 100/150] loss: 0.31326166\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:24 (running for 00:04:59.40)\n",
      "Memory usage on this node: 92.4/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 2.0/64 CPUs, 2.0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (1 RUNNING, 14 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00014 | RUNNING    | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  487 | 0.989999 |\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447757720947\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [488/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [488/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447692155838\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [489/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [489/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447692155838\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [490/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [490/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674477100372317\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 2\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [491/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [491/500, 100/150] loss: 0.31326169\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674476981163024\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [492/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [492/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-26\n",
      "  done: false\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 492\n",
      "  loss: 0.31674476742744445\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 167.8956162929535\n",
      "  time_this_iter_s: 0.32702136039733887\n",
      "  time_total_s: 167.8956162929535\n",
      "  timestamp: 1660748666\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 492\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674476742744445\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [493/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [493/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447662353516\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [494/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [494/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447644472122\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [495/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [495/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447638511658\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [496/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [496/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447692155838\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [497/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [497/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447686195374\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [498/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [498/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447638511658\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [499/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [499/500, 100/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.31674476146698\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger times: 0\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [500/500, 0/150] loss: 0.31326166\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m [500/500, 100/150] loss: 0.31326166\n",
      "Result for traindata_2f206_00014:\n",
      "  accuracy: 0.995\n",
      "  date: 2022-08-17_16-04-28\n",
      "  done: true\n",
      "  experiment_id: fb918cfdd1fe4ee08df1ec144f4d9788\n",
      "  hostname: tesla\n",
      "  iterations_since_restore: 500\n",
      "  loss: 0.3167447644472122\n",
      "  mcc: 0.98999899989999\n",
      "  node_ip: 192.168.85.249\n",
      "  pid: 3934350\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 170.68252635002136\n",
      "  time_this_iter_s: 0.3418099880218506\n",
      "  time_total_s: 170.68252635002136\n",
      "  timestamp: 1660748668\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 500\n",
      "  trial_id: 2f206_00014\n",
      "  warmup_time: 0.004093170166015625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m The Current Loss: 0.3167447644472122\n",
      "\u001b[2m\u001b[36m(func pid=3934350)\u001b[0m trigger Times: 1\n",
      "== Status ==\n",
      "Current time: 2022-08-17 16:04:29 (running for 00:05:03.90)\n",
      "Memory usage on this node: 92.8/251.3 GiB\n",
      "Using AsyncHyperBand: num_stopped=15\n",
      "Bracket: Iter 256.000: -0.3186243987083435 | Iter 128.000: -0.31971878762428574 | Iter 64.000: -0.3201102578639984 | Iter 32.000: -0.32196231007575987 | Iter 16.000: -0.3251563087105751 | Iter 8.000: -0.33778586000204086 | Iter 4.000: -0.3502905958890915 | Iter 2.000: -0.3880224198102951 | Iter 1.000: -0.6708784818649292\n",
      "Resources requested: 0/64 CPUs, 0/4 GPUs, 0.0/122.97 GiB heap, 0.0/56.69 GiB objects (0.0/1.0 accelerator_type:T4)\n",
      "Result logdir: /home/jabreu/ray_results/traindata_2022-08-17_15-59-25\n",
      "Number of trials: 15/15 (15 TERMINATED)\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "| Trial name            | status     | loc                    |   batch_size |   dropout |   hidden_size |          lr |     loss |   accuracy |   training_iteration |      mcc |\n",
      "|-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------|\n",
      "| traindata_2f206_00000 | TERMINATED | 192.168.85.249:3931827 |           32 |  0.415247 |           256 | 0.000170935 | 0.320535 |     0.9925 |                  500 | 0.985111 |\n",
      "| traindata_2f206_00001 | TERMINATED | 192.168.85.249:3931883 |           16 |  0.376144 |            32 | 2.13793e-05 | 0.689436 |     0.615  |                    1 | 0.230258 |\n",
      "| traindata_2f206_00002 | TERMINATED | 192.168.85.249:3931986 |            8 |  0.331023 |           128 | 0.00030504  | 0.337083 |     0.9725 |                   16 | 0.945304 |\n",
      "| traindata_2f206_00003 | TERMINATED | 192.168.85.249:3932223 |            8 |  0.438603 |           128 | 0.000643721 | 0.321301 |     0.9925 |                  128 | 0.98501  |\n",
      "| traindata_2f206_00004 | TERMINATED | 192.168.85.249:3933151 |           16 |  0.499694 |           256 | 4.533e-05   | 0.670878 |     0.7975 |                    1 | 0.60189  |\n",
      "| traindata_2f206_00005 | TERMINATED | 192.168.85.249:3933287 |            8 |  0.332402 |            32 | 0.00010607  | 0.684941 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00006 | TERMINATED | 192.168.85.249:3933384 |           16 |  0.354435 |            64 | 0.00465713  | 0.318624 |     0.995  |                  500 | 0.989998 |\n",
      "| traindata_2f206_00007 | TERMINATED | 192.168.85.249:3933423 |           32 |  0.461969 |            32 | 0.000114137 | 0.693848 |     0.4925 |                    1 | 0        |\n",
      "| traindata_2f206_00008 | TERMINATED | 192.168.85.249:3933523 |           16 |  0.338075 |           128 | 6.63477e-05 | 0.677006 |     0.54   |                    1 | 0.186967 |\n",
      "| traindata_2f206_00009 | TERMINATED | 192.168.85.249:3933632 |            8 |  0.337134 |           128 | 0.000387222 | 0.323214 |     0.9925 |                   32 | 0.985112 |\n",
      "| traindata_2f206_00010 | TERMINATED | 192.168.85.249:3933939 |           16 |  0.426184 |           256 | 1.65834e-05 | 0.682377 |     0.665  |                    1 | 0.360888 |\n",
      "| traindata_2f206_00011 | TERMINATED | 192.168.85.249:3934072 |           16 |  0.432872 |           128 | 0.00862223  | 0.818262 |     0.495  |                    1 | 0        |\n",
      "| traindata_2f206_00012 | TERMINATED | 192.168.85.249:3934157 |            8 |  0.366441 |            64 | 8.55378e-05 | 0.680259 |     0.515  |                    1 | 0.088243 |\n",
      "| traindata_2f206_00013 | TERMINATED | 192.168.85.249:3934261 |           16 |  0.394065 |           256 | 6.21042e-05 | 0.62614  |     0.635  |                    2 | 0.38805  |\n",
      "| traindata_2f206_00014 | TERMINATED | 192.168.85.249:3934350 |            8 |  0.420891 |           256 | 0.000670263 | 0.316745 |     0.995  |                  500 | 0.989999 |\n",
      "+-----------------------+------------+------------------------+--------------+-----------+---------------+-------------+----------+------------+----------------------+----------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-17 16:04:29,108\tINFO tune.py:748 -- Total run time: 304.09 seconds (303.84 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'hidden_size': 256, 'lr': 0.0006702634531750633, 'batch_size': 8, 'dropout': 0.42089114402459704}\n",
      "Best trial final validation loss: 0.3167447644472122\n",
      "Best trial final validation accuracy: 0.995\n",
      "Best trial final validation mcc: 0.98999899989999\n",
      "Results in test set:\n",
      "--------------------\n",
      "- model:   cnn\n",
      "- mode:    one_hot\n",
      "- dataset: primer\n",
      "--------------------\n",
      "Accuracy: 1.000\n",
      "MCC: 1.000\n",
      "[[203   0]\n",
      " [  0 197]]\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "sys.path.append(os.getcwd())\n",
    "from src.hyperparameter_tuning import hyperparameter_tuning\n",
    "config['do_tuning'] = True\n",
    "hyperparameter_tuning(device, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've reached the end of the deep learning pipeline. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dna-conda': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba449ea13c29f64a91968d8f927cecceedd6e605eda30388903386e6cd94168d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
