{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Get the directory path of the current script\n",
    "current_script_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "# Construct the path to the src directory\n",
    "src_directory = os.path.join(current_script_directory, \"..\", \"src\")\n",
    "srcpro_directory = os.path.join(current_script_directory, \"..\", \"src/propythia\")\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "sys.path.append(src_directory)\n",
    "sys.path.append(srcpro_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart building and using Word Embeddings with Propythia and application to ML and DL models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook intends to go over the building and application of Word embedding vectors to describe biological sequences and their use with ML and DL. The notebook uses protein sequences but the same principle may be used for DNA sequences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python module Bumblebee was developed for processing biological sequences aiming to search for semantic\n",
    "meaning in sequence ”words” (such as nucleotides and amino\n",
    "acids). This module was then integrated in ProPythia. It is organized in sub-modules so that\n",
    "the user can use them in different specific tasks and adapt\n",
    "them to fit the problem that is working on. The user can set\n",
    "specific values for the majority of the parameters, but default\n",
    "values are established. \n",
    "\n",
    "\n",
    "This include: \n",
    "\n",
    "    1) Read sequence sub-module: To read and/or change sequences. This is especially important to replace nonrelevant/not-common AAs simplifying the vocabulary.\n",
    "    \n",
    "    2) Sequence processing sub-module: To generate subsequences; Implements the segmentation of sequences by grams of size n and overlapping (or not) method.\n",
    "    \n",
    "    3) Create vocabulary list sub-module: To get all the vocabulary in the dataset, necessary to train the WE.\n",
    "    It allows to fetch a list of n-grams from pre-existing JSON file or create the list if it is not present.\n",
    "    \n",
    "    4) Training word embedding models sub-module: To train and save WE models; It is possible to train W2V\n",
    "    and FastText models with both CBOW or SG algorithms (based on gensim library). \n",
    "    \n",
    "    5) Load models list sub-module: To load a pre-trained embedding model;\n",
    "    \n",
    "    6) Protein Vector representation sub-module: To get a vector representation of a sequence or the matrix of\n",
    "    vectors accordingly to a model. It obtains a vector for a given n-gram and the number of occurrences of that\n",
    "    n-gram. Three methods of representing sequences as vectors are implemented as described above.\n",
    "    \n",
    "    7) Interpretability sub-module: To visualize WE in space and get similarities between vectors. It uses t-SNE to\n",
    "    create plots related to physicochemical properties of individual AA, including charge, volume, mass, Van der Waals Volume, polarity and hydrophobicity. For ngrams larger than 1, mean values of these properties are presented as described for Asgari et al. The sub-module also includes binding free energy values for trigrams, based on experimental data. If needed, users can define additional characteristics. Additionally, the models can also retrieve scores of similarity and neighborhood of the n-grams to aid in understanding vector similarities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important decisions to take are: \n",
    "\n",
    "    Either use a pretrained WE model or train your own model. \n",
    "    \n",
    "    Choose the size of the biological 'words' and the way to represent the final sequence\n",
    "    \n",
    "    \n",
    "For a more detailed explanation of the several modes please check the Quickstart_WordEmbedding jupyter.\n",
    "We will use the pretrained protvec model in this tutorial. But, as explained in the Quickstart_WordEmbedding jupyter one can train a model with different data and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets get the data. \n",
    "\n",
    "We will use the Antimicrobial peptides case study using Veltri study.\n",
    "\n",
    "The collection of data is available at\n",
    "https://www.dveltri.com/ascan/v2/news.html\n",
    "\n",
    "D. Veltri, U. Kamath, A. Shehu, Deep learning improves antimicrobial\n",
    "peptide recognition, Bioinformatics 34 (16) (2018) 2740{2747. doi:10.1093/bioinformatics/bty179.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID                                          Sequence  label\n",
      "0  AP02484                             GMASKAGSVLGKITKIALGAL      1\n",
      "1  AP02630       NIGLFTSTCFSSQCFSSKCFTDTCFSSNCFTGRHQCGYTHGSC      1\n",
      "2  AP01427                    GAIKDALKGAAKTVAVELLKKAQCKLEKTC      1\n",
      "3  AP02983                             FFGRLKAVFRGARQGWKEHRY      1\n",
      "4  AP01815  DFGCARGMIFVCMRRCARMYPGSTGYCQGFRCMCDTMIPIRRPPFIMG      1\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "amps_file = './AMP_Scan2_Feb2020_Dataset/AMPS_02182020.fasta'\n",
    "non_amps_file = './AMP_Scan2_Feb2020_Dataset/DECOYS_02182020.fasta'\n",
    "\n",
    "\n",
    "sequences = SeqIO.parse(amps_file, \"fasta\")\n",
    "data = []\n",
    "\n",
    "for record in sequences:\n",
    "    data.append([record.id, str(record.seq), 1])\n",
    "\n",
    "sequences = SeqIO.parse(non_amps_file, \"fasta\")\n",
    "for record in sequences:\n",
    "    data.append([record.id, str(record.seq), 0])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"ID\", \"Sequence\", 'label'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check some dataset characteristics\n",
    "\n",
    "First we will see the number of positve and negative sequences\n",
    "Then we will plot the different length sequences from positive and negative sequences. this is important as protein sequences have different sequence lengths and some methods require a same length input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2021\n",
      "0    2021\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate string lengths for each label\n",
    "df['Length'] = df['Sequence'].apply(len)\n",
    "\n",
    "# Split the DataFrame by label\n",
    "label_0_lengths = df[df['label'] == 0]['Length']\n",
    "label_1_lengths = df[df['label'] == 1]['Length']\n",
    "\n",
    "# Create histograms\n",
    "plt.hist(label_0_lengths, alpha=0.5, label='Label 0', bins=10)\n",
    "plt.hist(label_1_lengths, alpha=0.5, label='Label 1', bins=10)\n",
    "\n",
    "plt.xlabel('String Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of String Lengths by Label')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       max  min\n",
      "label          \n",
      "0      155   11\n",
      "1      183   11\n"
     ]
    }
   ],
   "source": [
    "# Group by label and calculate maximum and minimum lengths\n",
    "grouped = df.groupby('label')['Length'].agg(['max', 'min'])\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Preprocess sequences\n",
    "After, we will replace not common aminoacids. Furthermore, protein sequences are of different length. Depending of the method of WE you are using, you may need to use the same length for all sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_seq(seq, max_len):\n",
    "        seq1 = seq.replace('B', 'N')  # asparagine N / aspartic acid  D - asx - B\n",
    "        seq2 = seq1.replace('Z', 'Q')  # glutamine Q / glutamic acid  E - glx - Z\n",
    "        seq3 = seq2.replace('U',\n",
    "                            'C')  # selenocisteina, the closest is the cisteine. but it is a different aminoacid . take care.\n",
    "        seq4 = seq3.replace('O', 'K')  # Pyrrolysine to lysine\n",
    "        seq = seq4.replace('X', '')  # unknown character eliminated\n",
    "        if max_len:\n",
    "            seq = seq[0:max_len]\n",
    "        return seq\n",
    "\n",
    "\n",
    "seqs = df['Sequence']\n",
    "max_len = 200\n",
    "seqs_new = list(map(lambda seq:transform_seq(seq, max_len),seqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3 load the WE model\n",
    "Here we will use the Protvec model. This means that we will open the WordEmbedding class with a matrix file ( Protvec). The ngram len will be 3, used in Ptotvec and the vector dim is 100. \n",
    "\n",
    "protvec file can be obtained at https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/JMFHTN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 11:10:04.398807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordEmbedding is running..\n",
      "--MATRIX LOADED--\n"
     ]
    }
   ],
   "source": [
    "from propythia.wordembedding.word_embedding import WordEmbedding as wv\n",
    "\n",
    "protvec_file = '/home/martinha/propythia/propythia/src/propythia/wordembedding/protVec_100d_3grams.csv'\n",
    "\n",
    "w2v = wv(emb_matrix_file=protvec_file,\n",
    "         ngram_len=3 , sequence_max_len= max_len , vectordim=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 get protein vectors representations\n",
    "With the WE model loaded now we will transform the sequences into vectors. \n",
    "Three methods can be used: \n",
    "\n",
    "    • Method 1: Substitute directly the n-grams presented in the sequence by the WE vector. Being K the dimension of the word and N the dimension of the WE vector, a sequence of size L will be represented by a final vector of\n",
    "    (L − k − 1) ∗ N elements. \n",
    "    This method preserves the spatial information of the location of biological words.\n",
    "    \n",
    "    • Method 2: k-mer word frequencies are calculated and multiplied by the corresponding WE vectors. A sequence,\n",
    "    independent of the size, will be represented by a matrix of dimensions Number of words ∗ N.\n",
    "    \n",
    "    • Method 3: All the vectors of Method 2 are summed to reproduce a single vector of dimension N.\n",
    "    \n",
    "The method choosed will also impact the model choice. Deep learning architectures such as LSTM make more sense with method 1, where the sequence order is maintained. Method 3, for simplicity is suitable for ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Protein representations with method 3 for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method3: Each sequence will be represented by a vector of 100 dimension. This will be indepedent of the differences in the sequence length. This method, does not maintain the spatial relationships between aminoacids. Also, the fact that generates low dimensional features are better suited for shallow machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042, 100)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty numpy array\n",
    "num_sequences = len(seqs_new)  # Number of sequences\n",
    "result_array = np.zeros((num_sequences, 100))\n",
    "\n",
    "# Loop through the sequences and append vectors to the array\n",
    "for idx, i in enumerate(seqs_new):\n",
    "    vector = w2v.convert_seq2vec(method=3, sequence=i, padding = True)\n",
    "    result_array[idx] = vector\n",
    "\n",
    "print(result_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the data with sklearn train_test_split. We will define the X and y and create a test split with 0.33 size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (2708, 100)\n",
      "test_x (1334, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = result_array\n",
    "y = df['label']\n",
    "\n",
    "df_x_train, df_x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "print('train_x', df_x_train.shape)\n",
    "print('test_x', df_x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and open Shallow ML propythia class.\n",
    "\n",
    "\n",
    "We will keep the report name as None to avoid create unnecassary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'numpy.ndarray' object has no attribute 'columns'\n",
      "no features names listed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martinha/miniconda3/envs/propythia/lib/python3.9/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from propythia.ml.shallow_ml import ShallowML\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "# define ml class\n",
    "# create Machine learning object\n",
    "\n",
    "report = None\n",
    "ml = ShallowML(x_train=df_x_train, x_test=df_x_test, y_train=y_train, y_test=y_test,\n",
    "               report_name=report, columns_names= None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try a RF model. In Propythia, and when using the train best model, a grid search parameter optimization will be run. If a  param grid is not given, a default one is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'numpy.ndarray' object has no attribute 'columns'\n",
      "no features names listed\n",
      "performing gridSearch...\n",
      "GridSearchCV took 16.29 seconds for 6 candidate parameter settings.\n",
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scl', None),\n",
      "                                       ('clf',\n",
      "                                        RandomForestClassifier(random_state=1))]),\n",
      "             n_jobs=40,\n",
      "             param_grid=[{'clf__bootstrap': [True], 'clf__criterion': ['gini'],\n",
      "                          'clf__max_features': ['sqrt', 'log2'],\n",
      "                          'clf__n_estimators': [10, 100, 500]}],\n",
      "             scoring=make_scorer(matthews_corrcoef))\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.711 (std: 0.032)\n",
      " Parameters: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 500}\n",
      " \n",
      "\n",
      "Model with rank: 2\n",
      " Mean validation score: 0.710 (std: 0.028)\n",
      " Parameters: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      " \n",
      "\n",
      "Model with rank: 3\n",
      " Mean validation score: 0.697 (std: 0.030)\n",
      " Parameters: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      " \n",
      "\n",
      "make_scorer(matthews_corrcoef)\n",
      "5\n",
      "Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 5-fold cross validation:\n",
      " MCC score:\t0.711\n",
      " Parameters:\t{'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 500}\n",
      "\n",
      "0.613411 (0.031926) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 10}\n",
      "0.696675 (0.030097) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 100}\n",
      "0.710190 (0.027743) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 500}\n",
      "0.573399 (0.021778) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 10}\n",
      "0.695647 (0.038413) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n",
      "0.710671 (0.032000) with: {'clf__bootstrap': True, 'clf__criterion': 'gini', 'clf__max_features': 'log2', 'clf__n_estimators': 500}\n",
      "   clf__bootstrap clf__criterion clf__max_features  clf__n_estimators  \\\n",
      "0            True           gini              sqrt                 10   \n",
      "1            True           gini              sqrt                100   \n",
      "2            True           gini              sqrt                500   \n",
      "3            True           gini              log2                 10   \n",
      "4            True           gini              log2                100   \n",
      "5            True           gini              log2                500   \n",
      "\n",
      "      means      stds  \n",
      "0  0.613411  0.031926  \n",
      "1  0.696675  0.030097  \n",
      "2  0.710190  0.027743  \n",
      "3  0.573399  0.021778  \n",
      "4  0.695647  0.038413  \n",
      "5  0.710671  0.032000  \n"
     ]
    }
   ],
   "source": [
    "ml = ShallowML(x_train=df_x_train, x_test=df_x_test, y_train=y_train, y_test=y_test,\n",
    "               report_name=None, columns_names= None)\n",
    "\n",
    "# TRAIN BEST MODEL\n",
    "best_model = ml.train_best_model(model = 'rf', scaler=None,\n",
    "                                     score=make_scorer(matthews_corrcoef),\n",
    "                                     cv=5, optType='gridSearch',\n",
    "                                     param_grid=None,\n",
    "                                     n_jobs=40, random_state=1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86       667\n",
      "           1       0.88      0.82      0.85       667\n",
      "\n",
      "    accuracy                           0.85      1334\n",
      "   macro avg       0.85      0.85      0.85      1334\n",
      "weighted avg       0.85      0.85      0.85      1334\n",
      "\n",
      "[[589  78]\n",
      " [120 547]]\n",
      "Accuracy: 0.8515742128935532\n",
      "MCC: 0.7045465886849815\n",
      "log_loss: 0.41786503814772324\n",
      "f1 score: 0.846749226006192\n",
      "roc_auc: 0.8515742128935532\n",
      "Precision: [0.5    0.8752 1.    ]\n",
      "Recall: [1.         0.82008996 0.        ]\n",
      "fdr: 0.1248\n",
      "sn: 0.8200899550224887\n",
      "sp: 0.8830584707646177\n"
     ]
    }
   ],
   "source": [
    "scores, report, cm, cm2 = ml.score_testset(classifier=best_model)\n",
    "print(report)\n",
    "print(cm)\n",
    "for key, value in scores.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try a SVC model with a defined paramgrid and a Logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing gridSearch...\n",
      "GridSearchCV took 15.60 seconds for 12 candidate parameter settings.\n",
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scl', None),\n",
      "                                       ('clf', SVC(random_state=1))]),\n",
      "             n_jobs=40,\n",
      "             param_grid={'clf__C': [0.1, 1.0, 10],\n",
      "                         'clf__gamma': [0.001, 0.0001],\n",
      "                         'clf__kernel': ['rbf', 'linear']},\n",
      "             scoring=make_scorer(matthews_corrcoef))\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.730 (std: 0.018)\n",
      " Parameters: {'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      " \n",
      "\n",
      "Model with rank: 2\n",
      " Mean validation score: 0.701 (std: 0.020)\n",
      " Parameters: {'clf__C': 1.0, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      " \n",
      "\n",
      "Model with rank: 3\n",
      " Mean validation score: 0.672 (std: 0.023)\n",
      " Parameters: {'clf__C': 10, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}\n",
      " \n",
      "\n",
      "make_scorer(matthews_corrcoef)\n",
      "5\n",
      "Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 5-fold cross validation:\n",
      " MCC score:\t0.730\n",
      " Parameters:\t{'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      "\n",
      "0.533641 (0.030358) with: {'clf__C': 0.1, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      "0.664367 (0.014304) with: {'clf__C': 0.1, 'clf__gamma': 0.001, 'clf__kernel': 'linear'}\n",
      "0.346429 (0.026808) with: {'clf__C': 0.1, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}\n",
      "0.664367 (0.014304) with: {'clf__C': 0.1, 'clf__gamma': 0.0001, 'clf__kernel': 'linear'}\n",
      "0.701064 (0.020024) with: {'clf__C': 1.0, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      "0.656291 (0.023245) with: {'clf__C': 1.0, 'clf__gamma': 0.001, 'clf__kernel': 'linear'}\n",
      "0.520179 (0.016819) with: {'clf__C': 1.0, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}\n",
      "0.656291 (0.023245) with: {'clf__C': 1.0, 'clf__gamma': 0.0001, 'clf__kernel': 'linear'}\n",
      "0.730032 (0.018263) with: {'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'rbf'}\n",
      "0.659309 (0.025515) with: {'clf__C': 10, 'clf__gamma': 0.001, 'clf__kernel': 'linear'}\n",
      "0.671896 (0.023078) with: {'clf__C': 10, 'clf__gamma': 0.0001, 'clf__kernel': 'rbf'}\n",
      "0.659309 (0.025515) with: {'clf__C': 10, 'clf__gamma': 0.0001, 'clf__kernel': 'linear'}\n",
      "    clf__C  clf__gamma clf__kernel     means      stds\n",
      "0      0.1      0.0010         rbf  0.533641  0.030358\n",
      "1      0.1      0.0010      linear  0.664367  0.014304\n",
      "2      0.1      0.0001         rbf  0.346429  0.026808\n",
      "3      0.1      0.0001      linear  0.664367  0.014304\n",
      "4      1.0      0.0010         rbf  0.701064  0.020024\n",
      "5      1.0      0.0010      linear  0.656291  0.023245\n",
      "6      1.0      0.0001         rbf  0.520179  0.016819\n",
      "7      1.0      0.0001      linear  0.656291  0.023245\n",
      "8     10.0      0.0010         rbf  0.730032  0.018263\n",
      "9     10.0      0.0010      linear  0.659309  0.025515\n",
      "10    10.0      0.0001         rbf  0.671896  0.023078\n",
      "11    10.0      0.0001      linear  0.659309  0.025515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       667\n",
      "           1       0.87      0.86      0.86       667\n",
      "\n",
      "    accuracy                           0.86      1334\n",
      "   macro avg       0.86      0.86      0.86      1334\n",
      "weighted avg       0.86      0.86      0.86      1334\n",
      "\n",
      "[[578  89]\n",
      " [ 92 575]]\n",
      "Accuracy: 0.8643178410794603\n",
      "MCC: 0.7286430523351184\n",
      "f1 score: 0.8640120210368144\n",
      "roc_auc: 0.8643178410794603\n",
      "Precision: [0.5        0.86596386 1.        ]\n",
      "Recall: [1.         0.86206897 0.        ]\n",
      "fdr: 0.13403614457831325\n",
      "sn: 0.8620689655172413\n",
      "sp: 0.8665667166416792\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "param_grid = {'clf__C': [0.1, 1.0, 10],\n",
    "                        'clf__kernel': ['rbf', 'linear'],\n",
    "                        'clf__gamma': [0.001,0.0001]}\n",
    "# TRAIN BEST MODEL\n",
    "\n",
    "# we will use as score the MCC\n",
    "best_model = ml.train_best_model(model = 'svc', scaler=None,\n",
    "                                     score=make_scorer(matthews_corrcoef),\n",
    "                                     cv=5, optType='gridSearch',\n",
    "                                     param_grid=param_grid,\n",
    "                                     n_jobs=40, random_state=1, n_iter=15, refit=True)\n",
    "\n",
    "scores, report, cm, cm2 = ml.score_testset(classifier=best_model)\n",
    "print(report)\n",
    "print(cm)\n",
    "for key, value in scores.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing gridSearch...\n",
      "GridSearchCV took 0.60 seconds for 24 candidate parameter settings.\n",
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('scl', None),\n",
      "                                       ('clf', KNeighborsClassifier())]),\n",
      "             n_jobs=40,\n",
      "             param_grid=[{'clf__leaf_size': [15, 30, 60],\n",
      "                          'clf__n_neighbors': [2, 5, 10, 15],\n",
      "                          'clf__weights': ['uniform', 'distance']}],\n",
      "             scoring=make_scorer(matthews_corrcoef))\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.681 (std: 0.039)\n",
      " Parameters: {'clf__leaf_size': 15, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      " \n",
      "\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.681 (std: 0.039)\n",
      " Parameters: {'clf__leaf_size': 30, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      " \n",
      "\n",
      "Model with rank: 1\n",
      " Mean validation score: 0.681 (std: 0.039)\n",
      " Parameters: {'clf__leaf_size': 60, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      " \n",
      "\n",
      "make_scorer(matthews_corrcoef)\n",
      "5\n",
      "Best score (scorer: make_scorer(matthews_corrcoef)) and parameters from a 5-fold cross validation:\n",
      " MCC score:\t0.681\n",
      " Parameters:\t{'clf__leaf_size': 15, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      "\n",
      "0.647241 (0.033475) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 2, 'clf__weights': 'uniform'}\n",
      "0.604904 (0.044870) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 2, 'clf__weights': 'distance'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 5, 'clf__weights': 'uniform'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 5, 'clf__weights': 'distance'}\n",
      "0.678027 (0.036675) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 10, 'clf__weights': 'uniform'}\n",
      "0.680532 (0.038998) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      "0.666974 (0.044680) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 15, 'clf__weights': 'uniform'}\n",
      "0.669234 (0.043737) with: {'clf__leaf_size': 15, 'clf__n_neighbors': 15, 'clf__weights': 'distance'}\n",
      "0.647241 (0.033475) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 2, 'clf__weights': 'uniform'}\n",
      "0.604904 (0.044870) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 2, 'clf__weights': 'distance'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 5, 'clf__weights': 'uniform'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 5, 'clf__weights': 'distance'}\n",
      "0.678027 (0.036675) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 10, 'clf__weights': 'uniform'}\n",
      "0.680532 (0.038998) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      "0.666974 (0.044680) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 15, 'clf__weights': 'uniform'}\n",
      "0.669234 (0.043737) with: {'clf__leaf_size': 30, 'clf__n_neighbors': 15, 'clf__weights': 'distance'}\n",
      "0.647241 (0.033475) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 2, 'clf__weights': 'uniform'}\n",
      "0.604904 (0.044870) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 2, 'clf__weights': 'distance'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 5, 'clf__weights': 'uniform'}\n",
      "0.650501 (0.026121) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 5, 'clf__weights': 'distance'}\n",
      "0.678027 (0.036675) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 10, 'clf__weights': 'uniform'}\n",
      "0.680532 (0.038998) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 10, 'clf__weights': 'distance'}\n",
      "0.666974 (0.044680) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 15, 'clf__weights': 'uniform'}\n",
      "0.669234 (0.043737) with: {'clf__leaf_size': 60, 'clf__n_neighbors': 15, 'clf__weights': 'distance'}\n",
      "    clf__leaf_size  clf__n_neighbors clf__weights     means      stds\n",
      "0               15                 2      uniform  0.647241  0.033475\n",
      "1               15                 2     distance  0.604904  0.044870\n",
      "2               15                 5      uniform  0.650501  0.026121\n",
      "3               15                 5     distance  0.650501  0.026121\n",
      "4               15                10      uniform  0.678027  0.036675\n",
      "5               15                10     distance  0.680532  0.038998\n",
      "6               15                15      uniform  0.666974  0.044680\n",
      "7               15                15     distance  0.669234  0.043737\n",
      "8               30                 2      uniform  0.647241  0.033475\n",
      "9               30                 2     distance  0.604904  0.044870\n",
      "10              30                 5      uniform  0.650501  0.026121\n",
      "11              30                 5     distance  0.650501  0.026121\n",
      "12              30                10      uniform  0.678027  0.036675\n",
      "13              30                10     distance  0.680532  0.038998\n",
      "14              30                15      uniform  0.666974  0.044680\n",
      "15              30                15     distance  0.669234  0.043737\n",
      "16              60                 2      uniform  0.647241  0.033475\n",
      "17              60                 2     distance  0.604904  0.044870\n",
      "18              60                 5      uniform  0.650501  0.026121\n",
      "19              60                 5     distance  0.650501  0.026121\n",
      "20              60                10      uniform  0.678027  0.036675\n",
      "21              60                10     distance  0.680532  0.038998\n",
      "22              60                15      uniform  0.666974  0.044680\n",
      "23              60                15     distance  0.669234  0.043737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83       667\n",
      "           1       0.82      0.88      0.85       667\n",
      "\n",
      "    accuracy                           0.84      1334\n",
      "   macro avg       0.84      0.84      0.84      1334\n",
      "weighted avg       0.84      0.84      0.84      1334\n",
      "\n",
      "[[536 131]\n",
      " [ 82 585]]\n",
      "Accuracy: 0.8403298350824587\n",
      "MCC: 0.6825038477787718\n",
      "log_loss: 0.4965570519372392\n",
      "f1 score: 0.8459869848156182\n",
      "roc_auc: 0.8403298350824588\n",
      "Precision: [0.5        0.81703911 1.        ]\n",
      "Recall: [1.         0.87706147 0.        ]\n",
      "fdr: 0.1829608938547486\n",
      "sn: 0.8770614692653673\n",
      "sp: 0.8035982008995503\n"
     ]
    }
   ],
   "source": [
    "# we will use as score the MCC\n",
    "best_model = ml.train_best_model(model = 'knn', scaler=None,\n",
    "                                     score=make_scorer(matthews_corrcoef),\n",
    "                                     cv=5, optType='gridSearch',\n",
    "                                     param_grid=None,\n",
    "                                     n_jobs=40, random_state=1, n_iter=15, refit=True)\n",
    "\n",
    "scores, report, cm, cm2 = ml.score_testset(classifier=best_model)\n",
    "print(report)\n",
    "print(cm)\n",
    "for key, value in scores.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embeddings can be retrieved as solo features. Therefore, using scikit learn (or any other library of interest) directly, instead of Propythia, is also possible. Lets see how a SVC model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7286430523351184\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(C=10,gamma=0.001,kernel='rbf')\n",
    "best_model = clf.fit(df_x_train, y_train)\n",
    "y_pred = clf.predict(df_x_test)\n",
    "score = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Protein representations with method 1 for DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In method 1, each sequence will be represented by a vector of N trigrams with 100 len, this is, N * 100 size. \n",
    "This vector can be then flat if necessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042, 198, 100)\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty numpy array\n",
    "num_sequences = len(seqs_new)  # Number of sequences\n",
    "result_array = np.zeros((num_sequences, 198, 100))\n",
    "\n",
    "# Loop through the sequences and append vectors to the array\n",
    "for idx, i in enumerate(seqs_new):\n",
    "    vector = w2v.convert_seq2vec(method=1, sequence=i, padding = True)\n",
    "    result_array[idx] = vector\n",
    "\n",
    "print(result_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x (2708, 198, 100)\n",
      "test_x (1334, 198, 100)\n"
     ]
    }
   ],
   "source": [
    "X = result_array\n",
    "y = df['label']\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "print('train_x', X_train.shape)\n",
    "print('test_x', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a DL model. \n",
    "Convolutional and RNN are good choices for this problem. \n",
    "\n",
    "Besides that, adding callbacks such as early stopping and modelCheckpoint may be very beneficial\n",
    "\n",
    "We first will use the tensorfow library as example and then a DL model train with Propythia will be made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D,Conv2D, Flatten, MaxPool1D,MaxPool2D, Dropout, Input,GRU\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets first try a CNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 11:10:47.049474: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-20 11:10:47.050005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-08-20 11:10:47.109235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.109383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-20 11:10:47.109442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.109560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-20 11:10:47.109586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-20 11:10:47.110763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-20 11:10:47.110804: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-20 11:10:47.111768: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-20 11:10:47.111944: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-20 11:10:47.112862: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-20 11:10:47.113324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-20 11:10:47.115443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-20 11:10:47.115524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.115696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.115846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.115985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.116087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-08-20 11:10:47.116461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-20 11:10:47.116934: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-20 11:10:47.245050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-20 11:10:47.245237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2023-08-20 11:10:47.245359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-20 11:10:47.245376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-20 11:10:47.245390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-08-20 11:10:47.245403: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-08-20 11:10:47.245416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-08-20 11:10:47.245429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-08-20 11:10:47.245443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-08-20 11:10:47.245457: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-20 11:10:47.245495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.245989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1\n",
      "2023-08-20 11:10:47.246014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-08-20 11:10:47.799468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-08-20 11:10:47.799488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 \n",
      "2023-08-20 11:10:47.799491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N \n",
      "2023-08-20 11:10:47.799493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N \n",
      "2023-08-20 11:10:47.799683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.799854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.799981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.800104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.800212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10065 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2023-08-20 11:10:47.800453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.800577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-20 11:10:47.800669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10065 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 11:10:48.083318: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-08-20 11:10:48.101996: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 11:10:48.438782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-08-20 11:10:48.576664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-08-20 11:10:49.240652: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2023-08-20 11:10:49.311154: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 9s 144ms/step - loss: 0.6643 - accuracy: 0.5562 - val_loss: 0.4670 - val_accuracy: 0.7528\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8148 - val_loss: 0.3953 - val_accuracy: 0.8284\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8804 - val_loss: 0.3714 - val_accuracy: 0.8524\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2299 - accuracy: 0.9163 - val_loss: 0.4215 - val_accuracy: 0.8487\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1510 - accuracy: 0.9504 - val_loss: 0.4424 - val_accuracy: 0.8579\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9790 - val_loss: 0.4795 - val_accuracy: 0.8542\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9861 - val_loss: 0.6097 - val_accuracy: 0.8450\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9955 - val_loss: 0.6264 - val_accuracy: 0.8579\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9988 - val_loss: 0.6491 - val_accuracy: 0.8561\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.7331 - val_accuracy: 0.8690\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.8616\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.8653\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 9.1818e-04 - accuracy: 1.0000 - val_loss: 0.8901 - val_accuracy: 0.8635\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6.4942e-04 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.8506\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.8076 - val_accuracy: 0.8653\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.8088 - val_accuracy: 0.8376\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.8603 - val_accuracy: 0.8469\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.9415 - val_accuracy: 0.8524\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9983 - val_loss: 1.1224 - val_accuracy: 0.8044\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2375 - accuracy: 0.9291 - val_loss: 0.5301 - val_accuracy: 0.8598\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.8629 - val_accuracy: 0.8395\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.9068 - val_accuracy: 0.8506\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9210 - val_accuracy: 0.8487\n",
      "42/42 [==============================] - 3s 36ms/step - loss: 0.4091 - accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(198, 100)),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.2,callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Mean Training Accuracy: 0.9615400018899337\n",
      "Mean Validation Accuracy: 0.8464623793311741\n",
      "Mean Training Loss: 0.0900860324669022\n",
      "Mean Validation Loss: 0.7195863114750903\n",
      "===================================\n",
      "Test Loss: 0.4091\n",
      "Test Accuracy: 0.8448\n"
     ]
    }
   ],
   "source": [
    "# Test Loss: 1.6535\n",
    "# Test Accuracy: 0.8508\n",
    "# DR 0.5\n",
    "\n",
    "# Print training and validation accuracy and loss\n",
    "# print(\"Training Accuracy:\", history.history['accuracy'])\n",
    "# print(\"Validation Accuracy:\", history.history['val_accuracy'])\n",
    "# print(\"Training Loss:\", history.history['loss'])\n",
    "# print(\"Validation Loss:\", history.history['val_loss'])\n",
    "\n",
    "print('===================================')\n",
    "print(\"Mean Training Accuracy:\", np.mean(history.history['accuracy']))\n",
    "print(\"Mean Validation Accuracy:\", np.mean(history.history['val_accuracy']))\n",
    "print(\"Mean Training Loss:\", np.mean(history.history['loss']))\n",
    "print(\"Mean Validation Loss:\", np.mean(history.history['val_loss']))\n",
    "\n",
    "print('===================================')\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a RNN - GRU based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 2s 32ms/step - loss: 0.7149 - accuracy: 0.5225 - val_loss: 0.6863 - val_accuracy: 0.5233\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6841 - accuracy: 0.5345 - val_loss: 0.6773 - val_accuracy: 0.5379\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6738 - accuracy: 0.5670 - val_loss: 0.6765 - val_accuracy: 0.5471\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6745 - accuracy: 0.5504 - val_loss: 0.6638 - val_accuracy: 0.5507\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.8227 - accuracy: 0.5550 - val_loss: 0.6856 - val_accuracy: 0.5101\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6825 - accuracy: 0.5232 - val_loss: 0.6792 - val_accuracy: 0.5404\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6752 - accuracy: 0.5353 - val_loss: 0.6725 - val_accuracy: 0.5416\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6683 - accuracy: 0.5470 - val_loss: 0.6586 - val_accuracy: 0.5704\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6472 - accuracy: 0.5926 - val_loss: 0.6788 - val_accuracy: 0.5349\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6761 - accuracy: 0.5393 - val_loss: 0.6726 - val_accuracy: 0.5494\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6718 - accuracy: 0.5477 - val_loss: 0.6677 - val_accuracy: 0.5458\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6622 - accuracy: 0.5688 - val_loss: 0.6572 - val_accuracy: 0.5813\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6439 - accuracy: 0.6081 - val_loss: 0.7380 - val_accuracy: 0.5417\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6988 - accuracy: 0.5250 - val_loss: 0.6759 - val_accuracy: 0.5575\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 1s 26ms/step - loss: 0.6723 - accuracy: 0.5533 - val_loss: 0.6647 - val_accuracy: 0.5657\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6550 - accuracy: 0.5955 - val_loss: 0.6636 - val_accuracy: 0.5778\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6634 - accuracy: 0.5895 - val_loss: 0.6500 - val_accuracy: 0.5745\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.6072 - accuracy: 0.6598 - val_loss: 0.4728 - val_accuracy: 0.7984\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4486 - accuracy: 0.8068 - val_loss: 0.4237 - val_accuracy: 0.8196\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4324 - accuracy: 0.8270 - val_loss: 0.4503 - val_accuracy: 0.8150\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4166 - accuracy: 0.8374 - val_loss: 0.4515 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4586 - accuracy: 0.8114 - val_loss: 0.9477 - val_accuracy: 0.7526\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.7288 - accuracy: 0.6118 - val_loss: 0.6777 - val_accuracy: 0.5413\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.6694 - accuracy: 0.5379 - val_loss: 0.6624 - val_accuracy: 0.5455\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6609 - accuracy: 0.5597 - val_loss: 0.6781 - val_accuracy: 0.5624\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.6578 - accuracy: 0.6054 - val_loss: 0.5794 - val_accuracy: 0.6822\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.5532 - accuracy: 0.7182 - val_loss: 0.5472 - val_accuracy: 0.7118\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.4776 - accuracy: 0.7797 - val_loss: 0.4858 - val_accuracy: 0.7517\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.4311 - accuracy: 0.8153 - val_loss: 0.4036 - val_accuracy: 0.8187\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3674 - accuracy: 0.8480 - val_loss: 0.4365 - val_accuracy: 0.8073\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.3558 - accuracy: 0.8505 - val_loss: 0.3793 - val_accuracy: 0.8387\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3449 - accuracy: 0.8591 - val_loss: 0.3430 - val_accuracy: 0.8593\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.3164 - accuracy: 0.8768 - val_loss: 0.3409 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.2771 - accuracy: 0.8891 - val_loss: 0.3253 - val_accuracy: 0.8590\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.2806 - accuracy: 0.8883 - val_loss: 0.3759 - val_accuracy: 0.8307\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.2684 - accuracy: 0.8908 - val_loss: 0.3371 - val_accuracy: 0.8622\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.2432 - accuracy: 0.9122 - val_loss: 0.3631 - val_accuracy: 0.8513\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.2727 - accuracy: 0.8894 - val_loss: 0.3363 - val_accuracy: 0.8561\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.2496 - accuracy: 0.9043 - val_loss: 0.3591 - val_accuracy: 0.8600\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.2215 - accuracy: 0.9173 - val_loss: 0.3476 - val_accuracy: 0.8651\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.2437 - accuracy: 0.9139 - val_loss: 0.3596 - val_accuracy: 0.8650\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.2233 - accuracy: 0.9172 - val_loss: 0.3624 - val_accuracy: 0.8603\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.2133 - accuracy: 0.9256 - val_loss: 0.4290 - val_accuracy: 0.8529\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.2297 - accuracy: 0.9181 - val_loss: 0.4427 - val_accuracy: 0.8132\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.3624 - accuracy: 0.8670 - val_loss: 0.4553 - val_accuracy: 0.8113\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.2367 - accuracy: 0.9091 - val_loss: 0.3683 - val_accuracy: 0.8597\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.1731 - accuracy: 0.9392 - val_loss: 0.4287 - val_accuracy: 0.8436\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.1682 - accuracy: 0.9362 - val_loss: 0.3937 - val_accuracy: 0.8615\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.1632 - accuracy: 0.9428 - val_loss: 0.3974 - val_accuracy: 0.8486\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.1494 - accuracy: 0.9482 - val_loss: 0.4022 - val_accuracy: 0.8618\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.1544 - accuracy: 0.9475 - val_loss: 0.4234 - val_accuracy: 0.8583\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.1228 - accuracy: 0.9584 - val_loss: 0.4638 - val_accuracy: 0.8648\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 1s 27ms/step - loss: 0.1162 - accuracy: 0.9641 - val_loss: 0.5346 - val_accuracy: 0.8220\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.1431 - accuracy: 0.9517 - val_loss: 0.4860 - val_accuracy: 0.8501\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.8506\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(198, 100)),\n",
    "    GRU(units=512, return_sequences=True),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=64,epochs = 100,validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Mean Training Accuracy: 0.7550637490219541\n",
      "Mean Validation Accuracy: 0.7255374601593724\n",
      "Mean Training Loss: 0.44529645752023767\n",
      "Mean Validation Loss: 0.5211031492109652\n",
      "===================================\n",
      "Test Loss: 0.3607\n",
      "Test Accuracy: 0.8506\n"
     ]
    }
   ],
   "source": [
    "# Print training and validation accuracy and loss\n",
    "# print(\"Training Accuracy:\", history.history['accuracy'])\n",
    "# print(\"Validation Accuracy:\", history.history['val_accuracy'])\n",
    "# print(\"Training Loss:\", history.history['loss'])\n",
    "# print(\"Validation Loss:\", history.history['val_loss'])\n",
    "\n",
    "print('===================================')\n",
    "print(\"Mean Training Accuracy:\", np.mean(history.history['accuracy']))\n",
    "print(\"Mean Validation Accuracy:\", np.mean(history.history['val_accuracy']))\n",
    "print(\"Mean Training Loss:\", np.mean(history.history['loss']))\n",
    "print(\"Mean Validation Loss:\", np.mean(history.history['val_loss']))\n",
    "\n",
    "print('===================================')\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network with CONV and LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 8s 228ms/step - loss: 0.6806 - accuracy: 0.5401 - val_loss: 0.6280 - val_accuracy: 0.6089\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.5929 - accuracy: 0.6535 - val_loss: 0.5056 - val_accuracy: 0.7445\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.7658 - val_loss: 0.4394 - val_accuracy: 0.8084\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4135 - accuracy: 0.8267 - val_loss: 0.3977 - val_accuracy: 0.8432\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3540 - accuracy: 0.8557 - val_loss: 0.3730 - val_accuracy: 0.8511\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3179 - accuracy: 0.8817 - val_loss: 0.4850 - val_accuracy: 0.8255\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3202 - accuracy: 0.8822 - val_loss: 0.4777 - val_accuracy: 0.8418\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2902 - accuracy: 0.9016 - val_loss: 0.4242 - val_accuracy: 0.8502\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2418 - accuracy: 0.9233 - val_loss: 0.3731 - val_accuracy: 0.8485\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2221 - accuracy: 0.9312 - val_loss: 0.3982 - val_accuracy: 0.8486\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2029 - accuracy: 0.9344 - val_loss: 0.4276 - val_accuracy: 0.8520\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1502 - accuracy: 0.9584 - val_loss: 0.4159 - val_accuracy: 0.8524\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1592 - accuracy: 0.9528 - val_loss: 0.4950 - val_accuracy: 0.8394\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1909 - accuracy: 0.9382 - val_loss: 0.4676 - val_accuracy: 0.8590\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1512 - accuracy: 0.9523 - val_loss: 0.5252 - val_accuracy: 0.8558\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1208 - accuracy: 0.9667 - val_loss: 0.7231 - val_accuracy: 0.8252\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1394 - accuracy: 0.9613 - val_loss: 0.5620 - val_accuracy: 0.8587\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1067 - accuracy: 0.9683 - val_loss: 0.7793 - val_accuracy: 0.7978\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1672 - accuracy: 0.9469 - val_loss: 0.6848 - val_accuracy: 0.8234\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1062 - accuracy: 0.9725 - val_loss: 0.5119 - val_accuracy: 0.8542\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0988 - accuracy: 0.9724 - val_loss: 0.4336 - val_accuracy: 0.8626\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.9751 - val_loss: 0.7000 - val_accuracy: 0.8422\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0705 - accuracy: 0.9827 - val_loss: 0.7389 - val_accuracy: 0.8438\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.0670 - accuracy: 0.9820 - val_loss: 0.6906 - val_accuracy: 0.8366\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9821 - val_loss: 0.6701 - val_accuracy: 0.8548\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(198, 100)),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    LSTM(units=128, return_sequences=True),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=100, validation_split=0.2, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "Mean Training Accuracy: 0.9085580062866211\n",
      "Mean Validation Accuracy: 0.8291436171531678\n",
      "Mean Training Loss: 0.23052928060293199\n",
      "Mean Validation Loss: 0.533099365234375\n",
      "===================================\n",
      "Test Loss: 0.4218\n",
      "Test Accuracy: 0.8275\n"
     ]
    }
   ],
   "source": [
    "# Print training and validation accuracy and loss\n",
    "# print(\"Training Accuracy:\", history.history['accuracy'])\n",
    "# print(\"Validation Accuracy:\", history.history['val_accuracy'])\n",
    "# print(\"Training Loss:\", history.history['loss'])\n",
    "# print(\"Validation Loss:\", history.history['val_loss'])\n",
    "\n",
    "print('===================================')\n",
    "print(\"Mean Training Accuracy:\", np.mean(history.history['accuracy']))\n",
    "print(\"Mean Validation Accuracy:\", np.mean(history.history['val_accuracy']))\n",
    "print(\"Mean Training Loss:\", np.mean(history.history['loss']))\n",
    "print(\"Mean Validation Loss:\", np.mean(history.history['val_loss']))\n",
    "\n",
    "print('===================================')\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the netwroks achieved good result. These models can also be optimized to search for a better combination of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also do the DL using propythia functions if wanted. \n",
    "All the models performed similary. We wil use the GRU network as an example of the use with ProPythia\n",
    "Lets also try to increase the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.6680 - accuracy: 0.5717 - val_loss: 0.5707 - val_accuracy: 0.7306\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57067, saving model to weights.hdf5\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.5464 - accuracy: 0.7447 - val_loss: 0.4683 - val_accuracy: 0.8007\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57067 to 0.46835, saving model to weights.hdf5\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.4555 - accuracy: 0.8153 - val_loss: 0.3912 - val_accuracy: 0.8266\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46835 to 0.39117, saving model to weights.hdf5\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.3915 - accuracy: 0.8249 - val_loss: 0.3709 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.39117 to 0.37095, saving model to weights.hdf5\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.3458 - accuracy: 0.8617 - val_loss: 0.3646 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37095 to 0.36462, saving model to weights.hdf5\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3038 - accuracy: 0.8914 - val_loss: 0.3694 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.36462\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.3281 - accuracy: 0.8801 - val_loss: 0.3827 - val_accuracy: 0.8450\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.36462\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.3003 - accuracy: 0.8915 - val_loss: 0.3762 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.36462\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2775 - accuracy: 0.9001 - val_loss: 0.3802 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36462\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.3013 - accuracy: 0.8928 - val_loss: 0.3941 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36462\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2764 - accuracy: 0.8978 - val_loss: 0.4081 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36462\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2562 - accuracy: 0.9115 - val_loss: 0.4232 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36462\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2556 - accuracy: 0.9124 - val_loss: 0.4649 - val_accuracy: 0.8303\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36462\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.2489 - accuracy: 0.9094 - val_loss: 0.4206 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36462\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9115 - val_loss: 0.4313 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.36462\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.2312 - accuracy: 0.9295 - val_loss: 0.4531 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.36462\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2176 - accuracy: 0.9290 - val_loss: 0.4282 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36462\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2103 - accuracy: 0.9297 - val_loss: 0.4685 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36462\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2075 - accuracy: 0.9384 - val_loss: 0.5152 - val_accuracy: 0.8303\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36462\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1998 - accuracy: 0.9375 - val_loss: 0.4604 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.36462\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2117 - accuracy: 0.9448 - val_loss: 0.4730 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.36462\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1860 - accuracy: 0.9422 - val_loss: 0.5245 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.36462\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1707 - accuracy: 0.9475 - val_loss: 0.4541 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.36462\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1905 - accuracy: 0.9376 - val_loss: 0.5116 - val_accuracy: 0.8524\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.36462\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1691 - accuracy: 0.9518 - val_loss: 0.5090 - val_accuracy: 0.8303\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.36462\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1662 - accuracy: 0.9569 - val_loss: 0.5666 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.36462\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1552 - accuracy: 0.9533 - val_loss: 0.5539 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.36462\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1716 - accuracy: 0.9514 - val_loss: 0.5715 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.36462\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1592 - accuracy: 0.9583 - val_loss: 0.5843 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.36462\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1646 - accuracy: 0.9515 - val_loss: 0.5836 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.36462\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1688 - accuracy: 0.9553 - val_loss: 0.5788 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.36462\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1613 - accuracy: 0.9491 - val_loss: 0.5808 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.36462\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.1491 - accuracy: 0.9577 - val_loss: 0.5945 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.36462\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.9510 - val_loss: 0.5733 - val_accuracy: 0.8339\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.36462\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1496 - accuracy: 0.9553 - val_loss: 0.5866 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.36462\n",
      "Epoch 00035: early stopping\n",
      "('loss mean: ', 0.24964182036263602) \n",
      " ('val_loss mean: ', 0.47965388298034667) \n",
      " ('accuracy mean: ', 0.9086112924984523) \n",
      " ('val_accuracy mean: ', 0.8362677948815482)\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 198, 16)           5664      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3168)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 25352     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 31,025\n",
      "Trainable params: 31,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from propythia.ml.deep_ml import DeepML\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def model_gru():\n",
    "    model = Sequential([\n",
    "        Input(shape=(198, 100)),\n",
    "        GRU(units=16, return_sequences=True),\n",
    "        Flatten(),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model \n",
    "\n",
    "\n",
    "dl=DeepML(X_train, y_train, x_test, y_test, number_classes=2, problem_type='binary',\n",
    "          x_dval=None, y_dval=None, epochs=100, batch_size=64,\n",
    "          path='', report_name=None, verbose=1,\n",
    "         early_stopping_patience=30, reduce_lr_patience=20, reduce_lr_factor=0.2, reduce_lr_min=0.00001,\n",
    "                 )\n",
    "\n",
    "model = KerasClassifier(build_fn=model_gru)\n",
    "\n",
    "# run the model in Propythia\n",
    "history = dl.run_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.8710644677661169,\n",
       " 'MCC': 0.7422123556738972,\n",
       " 'log_loss': 0.4256619883165948,\n",
       " 'f1 score': 0.8700906344410877,\n",
       " 'roc_auc': 0.8710644677661169,\n",
       " 'Precision': array([0.5       , 0.87671233, 1.        ]),\n",
       " 'Recall': array([1.        , 0.86356822, 0.        ]),\n",
       " 'fdr': 0.1232876712328767,\n",
       " 'sn': 0.863568215892054,\n",
       " 'sp': 0.8785607196401799}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate on propythia\n",
    "scores, report, cm, cm2 = dl.score_testset_classification()\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even reducing the model architecture, the model is overfitting. One can now try and try to optimize these models in order to improve the accuracy and reduce the loss. other WE models and other vector representations may also be tested. for example, try to train a digram WE model. Other aspects may be try other protein representations such as physicochemical features or one hot encodings."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}